#!/usr/bin/env python3
"""
News Publisher - Sistema de publica√ß√£o baseado em scraping
Pega not√≠cias reais do Perplexity AI e cria artigos jornal√≠sticos
"""

import os
import sys
import re
import json
import hashlib
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime, timezone, timedelta
import subprocess
from dotenv import load_dotenv

from tech_news_scraper import TechNewsScraper

# Configura√ß√µes
POSTS_DIR = Path("content/posts")
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)
PUBLISHED_CACHE = CACHE_DIR / "published_articles.json"

# Configura√ß√µes do Hugo
HUGO_AUTHOR = "Alphaworks"
HUGO_CATEGORY = "Tecnologia"
TIMEZONE_OFFSET = -3  # Bras√≠lia (UTC-3)

class NewsPublisher:
    def __init__(self):
        self.scraper = TechNewsScraper()
        self.published_articles = self.load_published_cache()
        
        # Mapeamento de fontes com links
        self.source_links = {
            'Perplexity AI': 'https://www.perplexity.ai/',
            'TechCrunch': 'https://techcrunch.com/',
            'The Verge': 'https://www.theverge.com/',
            'Ars Technica': 'https://arstechnica.com/',
            'Wired': 'https://www.wired.com/',
            'Engadget': 'https://www.engadget.com/',
            'Tecmundo': 'https://www.tecmundo.com.br/',
            'Olhar Digital': 'https://olhardigital.com.br/',
            'Canaltech': 'https://canaltech.com.br/',
            'Tecnoblog': 'https://tecnoblog.net/',
        }

    def get_fresh_news(self) -> Optional[Dict]:
        """
        Obt√©m uma not√≠cia ainda n√£o publicada
        """
        print("üì∞ Buscando not√≠cias n√£o publicadas...")
        
        articles = self.scraper.get_tech_news(max_articles=20)
        
        if not articles:
            print("‚ùå Nenhuma not√≠cia encontrada")
            return None
        
        # Filtra artigos j√° publicados
        for article in articles:
            article_id = self.generate_article_id(article['title'])
            
            if article_id not in self.published_articles:
                print(f"‚úÖ Nova not√≠cia encontrada: {article['title'][:60]}...")
                return article
        
        print("‚ö†Ô∏è Todas as not√≠cias j√° foram publicadas")
        return None

    def generate_article_id(self, title: str) -> str:
        """
        Gera ID √∫nico para o artigo baseado no t√≠tulo
        """
        clean_title = re.sub(r'[^\w\s]', '', title.lower()).strip()
        return hashlib.md5(clean_title.encode()).hexdigest()[:12]

    def create_journalistic_article(self, news_data: Dict) -> str:
        """
        Cria um artigo jornal√≠stico baseado na not√≠cia real
        """
        title = news_data['title']
        description = news_data.get('description', '')
        url = news_data.get('url', '')
        keywords = news_data.get('keywords', [])
        
        print(f"‚úçÔ∏è Criando artigo jornal√≠stico para: {title}")
        
        # Tenta obter conte√∫do completo se h√° URL
        full_content = ""
        if url:
            print("üìñ Obtendo conte√∫do completo...")
            full_content = self.scraper.get_article_content(url)
        
        # Cria o artigo jornal√≠stico
        article_content = self.write_journalistic_content(
            title=title,
            description=description,
            full_content=full_content,
            keywords=keywords,
            source_url=url
        )
        
        return article_content

    def write_journalistic_content(self, title: str, description: str, 
                                 full_content: str, keywords: List[str], 
                                 source_url: str) -> str:
        """
        Escreve conte√∫do jornal√≠stico baseado nas informa√ß√µes reais
        """
        # An√°lise do conte√∫do para extrair informa√ß√µes
        main_topic = self.identify_main_topic(title, keywords)
        companies = self.extract_companies(title, description)
        tech_areas = self.extract_tech_areas(title, description, keywords)
        
        # Estrutura do artigo jornal√≠stico
        article = f"""A {main_topic} est√° em destaque no cen√°rio tecnol√≥gico atual. """
        
        if companies:
            article += f"Empresas como {', '.join(companies)} est√£o na vanguarda deste desenvolvimento. "
        
        article += f"{description}\n\n"
        
        # Se√ß√£o de contexto
        article += "## Contexto e Relev√¢ncia\n\n"
        article += self.generate_context_section(main_topic, tech_areas, companies)
        
        # Se√ß√£o de an√°lise t√©cnica
        article += "\n## An√°lise T√©cnica\n\n"
        article += self.generate_technical_analysis(main_topic, tech_areas, keywords)
        
        # Se√ß√£o de impacto no mercado
        article += "\n## Impacto no Mercado\n\n"
        article += self.generate_market_impact(main_topic, companies, tech_areas)
        
        # Se√ß√£o de perspectivas futuras
        article += "\n## Perspectivas Futuras\n\n"
        article += self.generate_future_perspectives(main_topic, tech_areas)
        
        # Se h√° conte√∫do completo, adiciona insights adicionais
        if full_content and len(full_content) > 200:
            article += "\n## Detalhes Adicionais\n\n"
            article += self.extract_key_insights(full_content)
        
        return article

    def identify_main_topic(self, title: str, keywords: List[str]) -> str:
        """
        Identifica o t√≥pico principal da not√≠cia
        """
        title_lower = title.lower()
        
        topic_mapping = {
            'intelig√™ncia artificial': ['ai', 'artificial intelligence', 'machine learning', 'deep learning'],
            'ciberseguran√ßa': ['security', 'cybersecurity', 'privacy', 'breach', 'hack'],
            'blockchain': ['blockchain', 'cryptocurrency', 'bitcoin', 'ethereum', 'crypto'],
            'computa√ß√£o em nuvem': ['cloud', 'aws', 'azure', 'google cloud'],
            'dispositivos m√≥veis': ['iphone', 'android', 'smartphone', 'mobile', 'app'],
            'startups': ['startup', 'funding', 'investment', 'ipo', 'acquisition'],
            'big tech': ['apple', 'google', 'microsoft', 'meta', 'amazon', 'tesla'],
            'software': ['software', 'programming', 'development', 'code'],
            'hardware': ['hardware', 'chip', 'processor', 'semiconductor'],
            'inova√ß√£o tecnol√≥gica': ['innovation', 'technology', 'tech', 'digital']
        }
        
        for topic, indicators in topic_mapping.items():
            if any(indicator in title_lower for indicator in indicators):
                return topic
        
        # Se n√£o encontrou, usa palavras-chave
        if keywords:
            return keywords[0].replace('_', ' ').title()
        
        return "tecnologia"

    def extract_companies(self, title: str, description: str) -> List[str]:
        """
        Extrai nomes de empresas mencionadas
        """
        text = f"{title} {description}".lower()
        
        companies = [
            'Apple', 'Google', 'Microsoft', 'Amazon', 'Meta', 'Tesla',
            'NVIDIA', 'Intel', 'AMD', 'IBM', 'Oracle', 'Salesforce',
            'OpenAI', 'Anthropic', 'SpaceX', 'Netflix', 'Uber', 'Airbnb'
        ]
        
        found_companies = []
        for company in companies:
            if company.lower() in text:
                found_companies.append(company)
        
        return found_companies[:3]  # M√°ximo 3 empresas

    def extract_tech_areas(self, title: str, description: str, keywords: List[str]) -> List[str]:
        """
        Extrai √°reas tecnol√≥gicas relevantes
        """
        text = f"{title} {description} {' '.join(keywords)}".lower()
        
        tech_areas = [
            'intelig√™ncia artificial', 'machine learning', 'blockchain',
            'computa√ß√£o em nuvem', 'ciberseguran√ßa', 'internet das coisas',
            'realidade virtual', 'realidade aumentada', 'automa√ß√£o',
            'rob√≥tica', 'computa√ß√£o qu√¢ntica', 'biotecnologia'
        ]
        
        found_areas = []
        for area in tech_areas:
            if any(word in text for word in area.split()):
                found_areas.append(area)
        
        return found_areas[:3]  # M√°ximo 3 √°reas

    def generate_context_section(self, main_topic: str, tech_areas: List[str], companies: List[str]) -> str:
        """
        Gera se√ß√£o de contexto
        """
        context = f"O desenvolvimento em {main_topic} representa uma tend√™ncia significativa no mercado tecnol√≥gico atual. "
        
        if tech_areas:
            context += f"Esta evolu√ß√£o est√° conectada com avan√ßos em {', '.join(tech_areas)}, "
            context += "demonstrando a interconex√£o entre diferentes √°reas da tecnologia.\n\n"
        
        if companies:
            context += f"A participa√ß√£o de empresas estabelecidas como {', '.join(companies)} "
            context += "indica a import√¢ncia estrat√©gica deste desenvolvimento para o setor.\n\n"
        
        context += "Para o mercado brasileiro, essas inova√ß√µes podem representar novas oportunidades "
        context += "de crescimento e moderniza√ß√£o tecnol√≥gica."
        
        return context

    def generate_technical_analysis(self, main_topic: str, tech_areas: List[str], keywords: List[str]) -> str:
        """
        Gera an√°lise t√©cnica
        """
        analysis = f"Do ponto de vista t√©cnico, os avan√ßos em {main_topic} envolvem "
        analysis += "m√∫ltiplas camadas de inova√ß√£o tecnol√≥gica.\n\n"
        
        if 'ai' in keywords or 'artificial intelligence' in keywords:
            analysis += "Os algoritmos de intelig√™ncia artificial est√£o se tornando mais "
            analysis += "sofisticados, permitindo aplica√ß√µes mais precisas e eficientes. "
        
        if 'cloud' in keywords:
            analysis += "A integra√ß√£o com plataformas de computa√ß√£o em nuvem oferece "
            analysis += "escalabilidade e acessibilidade ampliadas. "
        
        if 'security' in keywords or 'cybersecurity' in keywords:
            analysis += "Aspectos de seguran√ßa s√£o fundamentais, exigindo implementa√ß√£o "
            analysis += "de protocolos robustos de prote√ß√£o de dados. "
        
        analysis += "\n\nA implementa√ß√£o dessas tecnologias requer considera√ß√£o cuidadosa "
        analysis += "de fatores como infraestrutura, custos operacionais e capacita√ß√£o t√©cnica."
        
        return analysis

    def generate_market_impact(self, main_topic: str, companies: List[str], tech_areas: List[str]) -> str:
        """
        Gera an√°lise de impacto no mercado
        """
        impact = f"O impacto no mercado de {main_topic} pode ser observado em diferentes dimens√µes.\n\n"
        
        impact += "**Competitividade Empresarial**: Empresas que adotam essas tecnologias "
        impact += "tendem a obter vantagens competitivas significativas, melhorando "
        impact += "efici√™ncia operacional e capacidade de inova√ß√£o.\n\n"
        
        impact += "**Transforma√ß√£o Setorial**: Diversos setores da economia podem ser "
        impact += "impactados, desde servi√ßos financeiros at√© manufatura e sa√∫de.\n\n"
        
        impact += "**Oportunidades de Investimento**: O desenvolvimento cria novas "
        impact += "oportunidades para investidores e empreendedores interessados "
        impact += "em tecnologias emergentes.\n\n"
        
        if companies:
            impact += f"A participa√ß√£o de empresas como {', '.join(companies)} "
            impact += "demonstra o potencial de mercado e a viabilidade comercial "
            impact += "dessas inova√ß√µes."
        
        return impact

    def generate_future_perspectives(self, main_topic: str, tech_areas: List[str]) -> str:
        """
        Gera perspectivas futuras
        """
        perspectives = f"As perspectivas futuras para {main_topic} s√£o promissoras, "
        perspectives += "com potencial para transforma√ß√µes significativas.\n\n"
        
        perspectives += "**Evolu√ß√£o Tecnol√≥gica**: Espera-se continuidade no desenvolvimento "
        perspectives += "de solu√ß√µes mais avan√ßadas e acess√≠veis.\n\n"
        
        perspectives += "**Ado√ß√£o Ampliada**: A tend√™ncia √© de maior ado√ß√£o por empresas "
        perspectives += "de diferentes portes e setores.\n\n"
        
        perspectives += "**Regulamenta√ß√£o**: Desenvolvimento de frameworks regulat√≥rios "
        perspectives += "adequados para acompanhar a evolu√ß√£o tecnol√≥gica.\n\n"
        
        perspectives += "**Capacita√ß√£o**: Crescente necessidade de capacita√ß√£o profissional "
        perspectives += "especializada para aproveitar essas oportunidades."
        
        return perspectives

    def extract_key_insights(self, full_content: str) -> str:
        """
        Extrai insights principais do conte√∫do completo
        """
        # Pega os primeiros par√°grafos mais informativos
        paragraphs = [p.strip() for p in full_content.split('\n') if len(p.strip()) > 50]
        
        insights = "Com base nas informa√ß√µes dispon√≠veis:\n\n"
        
        # Pega at√© 3 par√°grafos mais relevantes
        for i, paragraph in enumerate(paragraphs[:3]):
            if len(paragraph) > 100:
                insights += f"‚Ä¢ {paragraph[:200]}...\n\n"
        
        return insights

    def generate_tags(self, title: str, keywords: List[str], companies: List[str]) -> List[str]:
        """
        Gera tags relevantes para o post
        """
        tags = set()
        
        # Tags baseadas em keywords
        keyword_mapping = {
            'ai': 'inteligencia-artificial',
            'artificial intelligence': 'inteligencia-artificial',
            'machine learning': 'machine-learning',
            'blockchain': 'blockchain',
            'cloud': 'cloud-computing',
            'security': 'ciberseguranca',
            'cybersecurity': 'ciberseguranca',
            'startup': 'startups',
            'mobile': 'mobile',
            'software': 'software',
            'hardware': 'hardware'
        }
        
        for keyword in keywords:
            if keyword in keyword_mapping:
                tags.add(keyword_mapping[keyword])
        
        # Tags baseadas em empresas
        company_tags = {
            'Apple': 'apple',
            'Google': 'google',
            'Microsoft': 'microsoft',
            'Amazon': 'amazon',
            'Meta': 'meta',
            'Tesla': 'tesla',
            'NVIDIA': 'nvidia'
        }
        
        for company in companies:
            if company in company_tags:
                tags.add(company_tags[company])
        
        # Tags gen√©ricas sempre inclu√≠das
        tags.update(['tecnologia', 'inovacao'])
        
        return list(tags)[:6]  # M√°ximo 6 tags

    def create_hugo_post(self, news_data: Dict, article_content: str) -> Optional[Path]:
        """
        Cria arquivo Hugo com o artigo
        """
        print("üìù Criando post Hugo...")
        
        title = news_data['title']
        keywords = news_data.get('keywords', [])
        companies = self.extract_companies(title, news_data.get('description', ''))
        
        # Gera metadados
        tags = self.generate_tags(title, keywords, companies)
        
        # Calcula tempo de leitura
        word_count = len(article_content.split())
        reading_time = max(1, round(word_count / 200))
        
        # Gera slug para o arquivo
        slug = re.sub(r'[^\w\s-]', '', title.lower()).strip()
        slug = re.sub(r'[\s_]+', '-', slug)
        
        now = datetime.now()
        tz_offset = timezone(timedelta(hours=TIMEZONE_OFFSET))
        iso_timestamp = now.astimezone(tz_offset).isoformat()
        
        filename = POSTS_DIR / f"{now.strftime('%Y-%m-%d')}-{slug[:80]}.md"
        
        # Gera descri√ß√£o
        description = news_data.get('description', '')
        if not description:
            # Usa primeiras frases do artigo
            sentences = article_content.split('.')[:2]
            description = '. '.join(sentences) + '.'
        
        # Limita descri√ß√£o
        if len(description) > 160:
            description = description[:157] + "..."
        
        # Cria tags YAML
        tags_yaml = '\n'.join([f"  - {tag}" for tag in tags])
        keywords_yaml = '\n'.join([f"  - {kw}" for kw in keywords[:5]])
        
        # Escapa caracteres especiais
        escaped_title = title.replace('"', '\\"')
        escaped_description = description.replace('"', '\\"')
        
        # Frontmatter
        frontmatter = f"""---
title: "{escaped_title}"
date: {iso_timestamp}
draft: false
description: "{escaped_description}"
summary: "{escaped_description}"
tags:
{tags_yaml}
keywords:
{keywords_yaml}
categories:
  - {HUGO_CATEGORY}
author: "{HUGO_AUTHOR}"
readingTime: {reading_time}
wordCount: {word_count}
source_url: "{news_data.get('url', '')}"
seo:
  title: "{escaped_title}"
  description: "{escaped_description}"
  canonical: ""
  noindex: false
---

"""
        
        # Conte√∫do completo
        full_content = frontmatter + article_content
        
        # Adiciona se√ß√£o de fontes
        full_content += "\n\n---\n\n## üìö Fontes e Refer√™ncias\n\n"
        full_content += f"1. **[Perplexity AI](https://www.perplexity.ai/)**\n"
        
        if news_data.get('url'):
            domain = news_data['url'].split('/')[2] if '/' in news_data['url'] else 'Fonte Original'
            full_content += f"2. **[{domain}]({news_data['url']})**\n"
        
        # Salva arquivo
        try:
            filename.write_text(full_content, encoding="utf-8")
            print(f"‚úÖ Post salvo: {filename}")
            return filename
        except Exception as e:
            print(f"‚ùå Erro ao salvar post: {e}")
            return None

    def commit_and_push(self, filename: Path, title: str):
        """
        Faz commit e push do novo post
        """
        try:
            print("üöÄ Fazendo commit do novo post...")
            
            # Git add
            subprocess.run(['git', 'add', str(filename)], check=True)
            
            # Git commit
            commit_message = f'feat: Add news article "{title[:50]}..."'
            subprocess.run(['git', 'commit', '-m', commit_message], check=True)
            
            print("‚úÖ Commit local realizado!")
            
            # Git push
            print("üì° Enviando para reposit√≥rio remoto...")
            subprocess.run(['git', 'push'], check=True)
            
            print("‚úÖ Push realizado com sucesso!")
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Erro no git: {e}")
        except FileNotFoundError:
            print("‚ùå Git n√£o encontrado. Post criado mas n√£o commitado.")

    def load_published_cache(self) -> set:
        """
        Carrega cache de artigos j√° publicados
        """
        try:
            if PUBLISHED_CACHE.exists():
                with open(PUBLISHED_CACHE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('published_ids', []))
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao carregar cache de publicados: {e}")
        
        return set()

    def save_published_cache(self, article_id: str, title: str):
        """
        Salva ID do artigo publicado no cache
        """
        try:
            self.published_articles.add(article_id)
            
            cache_data = {
                'published_ids': list(self.published_articles),
                'last_updated': datetime.now().isoformat()
            }
            
            with open(PUBLISHED_CACHE, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar cache: {e}")

    def publish_news_article(self) -> bool:
        """
        Processo principal: busca not√≠cia e publica artigo
        """
        print("üöÄ Iniciando publica√ß√£o de artigo baseado em not√≠cias reais...")
        
        # Busca not√≠cia n√£o publicada
        news_data = self.get_fresh_news()
        if not news_data:
            return False
        
        # Cria artigo jornal√≠stico
        article_content = self.create_journalistic_article(news_data)
        
        # Cria post Hugo
        filename = self.create_hugo_post(news_data, article_content)
        if not filename:
            return False
        
        # Marca como publicado
        article_id = self.generate_article_id(news_data['title'])
        self.save_published_cache(article_id, news_data['title'])
        
        # Commit e push
        self.commit_and_push(filename, news_data['title'])
        
        print(f"‚úÖ Artigo publicado com sucesso: {news_data['title']}")
        return True


def main():
    """
    Fun√ß√£o principal
    """
    publisher = NewsPublisher()
    
    success = publisher.publish_news_article()
    
    if success:
        print("üéâ Processo conclu√≠do com sucesso!")
    else:
        print("‚ùå N√£o foi poss√≠vel publicar artigo")
        sys.exit(1)


if __name__ == "__main__":
    main()