import os
import sys
import re
import random
import json
import hashlib
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime, timezone, timedelta
import subprocess
from dotenv import load_dotenv
import google.generativeai as genai
from config import *
from trends import *
from news_api_improved import get_current_news, get_news_context
from content_formatting import format_content
from content_cleaner import clean_content_completely, create_simple_structure

# --- Configura√ß√µes ---
POSTS_DIR = Path("content/posts")
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)
TOPICS_CACHE = CACHE_DIR / "topics_cache.json"

def setup_api():
    """Carrega vari√°veis de ambiente e configura a API do Gemini."""
    load_dotenv()
    # Tenta m√∫ltiplas vari√°veis de ambiente para compatibilidade
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_GENERATIVE_AI_API_KEY")
    if not api_key:
        print("‚ùå ERRO: Nenhuma chave de API encontrada.")
        print("Configure uma das seguintes vari√°veis no arquivo .env:")
        print("  - GEMINI_API_KEY=sua_chave_aqui")
        print("  - GOOGLE_API_KEY=sua_chave_aqui")
        print("  - GOOGLE_GENERATIVE_AI_API_KEY=sua_chave_aqui")
        return False
    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        print(f"‚ùå ERRO ao configurar a API do Gemini: {e}")
        return False

def call_gemini_api(prompt: str, safety_settings=None, max_retries=MAX_API_RETRIES, timeout=None) -> str:
    """
    Chama a API do Gemini com fallback autom√°tico para modelos mais simples.
    Retorna a resposta em texto ou lan√ßa uma exce√ß√£o em caso de erro.
    """
    import time
    
    # Lista de modelos em ordem de prefer√™ncia (melhor para pior)
    model_fallback = [
        {
            'name': 'models/gemini-1.5-flash-latest',
            'description': 'Modelo principal (mais completo)',
            'max_tokens': 1500,
            'temperature': 0.7
        },
        {
            'name': 'models/gemini-1.5-flash',
            'description': 'Modelo est√°vel (fallback 1)',
            'max_tokens': 1200,
            'temperature': 0.6
        },
        {
            'name': 'models/gemini-1.5-flash-8b',
            'description': 'Modelo b√°sico (fallback 2)',
            'max_tokens': 1000,
            'temperature': 0.5
        }
    ]
    
    if timeout is None:
        timeout = API_TIMEOUT_SECONDS
    
    # Tenta cada modelo na ordem de fallback
    for model_idx, model_config in enumerate(model_fallback):
        model = genai.GenerativeModel(model_config['name'])
        
        if model_idx > 0:
            print(f"üîÑ Tentando fallback: {model_config['description']}")
        
        for attempt in range(max_retries):
            try:
                if model_idx == 0:
                    print(f"üîÑ API call {attempt + 1}/{max_retries}")
                else:
                    print(f"üîÑ Fallback call {attempt + 1}/{max_retries}")
                
                # Configura timeout baseado no tamanho do prompt
                prompt_size = len(prompt)
                if prompt_size > 5000:
                    current_timeout = timeout * 2
                    print(f"üìè Prompt longo ({prompt_size} chars) - Timeout: {current_timeout}s")
                else:
                    current_timeout = timeout
                    print(f"üìè Prompt: {prompt_size} chars - Timeout: {current_timeout}s")
                
                start_time = time.time()
                
                # Configura√ß√£o otimizada baseada no modelo
                generation_config = genai.types.GenerationConfig(
                    max_output_tokens=model_config['max_tokens'],
                    temperature=model_config['temperature'],
                    top_p=0.9,
                    top_k=40
                )
                
                response = model.generate_content(
                    prompt, 
                    safety_settings=safety_settings,
                    generation_config=generation_config
                )
                
                elapsed_time = time.time() - start_time
                print(f"‚úÖ API respondeu em {elapsed_time:.1f}s")
                
                if response.text:
                    if model_idx > 0:
                        print(f"‚úÖ Sucesso com fallback: {model_config['description']}")
                    return response.text
                else:
                    print(f"‚ö†Ô∏è Tentativa {attempt + 1}: Resposta vazia")
                
            except Exception as e:
                elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
                error_str = str(e).lower()
                
                # Detecta erro de quota - for√ßa fallback para pr√≥ximo modelo
                if "quota" in error_str or "429" in error_str or "exceeded" in error_str:
                    print(f"ÔøΩ Quotia excedida no modelo {model_config['description']}")
                    if model_idx < len(model_fallback) - 1:
                        print(f"üîÑ Tentando pr√≥ximo modelo...")
                        break  # Sai do loop de tentativas e vai para pr√≥ximo modelo
                    else:
                        print(f"‚ùå Todos os modelos esgotaram quota")
                        raise e
                
                # Detecta timeout
                elif "timeout" in error_str or "504" in error_str or elapsed_time > current_timeout:
                    print(f"‚è∞ Timeout detectado ({elapsed_time:.1f}s)")
                    if attempt < max_retries - 1:
                        print("üîÑ Reduzindo prompt para pr√≥xima tentativa...")
                        # Reduz prompt se muito longo
                        if len(prompt) > 3000:
                            prompt = prompt[:2500] + "\n\nIMPORTANTE: Responda de forma concisa e direta."
                
                # Outros erros
                else:
                    print(f"‚ùå Erro: {str(e)[:100]}...")
                
                # Se √© a √∫ltima tentativa deste modelo, tenta pr√≥ximo modelo
                if attempt == max_retries - 1:
                    if model_idx < len(model_fallback) - 1:
                        print(f"üîÑ Modelo {model_config['description']} falhou, tentando pr√≥ximo...")
                        break  # Vai para pr√≥ximo modelo
                    else:
                        raise e
                
                # Espera progressiva apenas se n√£o for erro de quota
                if "quota" not in error_str and "429" not in error_str:
                    wait_time = (attempt + 1) * 2
                    print(f"‚è≥ Aguardando {wait_time}s...")
                    time.sleep(wait_time)
    
    raise Exception("Falha em todas as tentativas de chamada da API")

def load_topics_cache() -> Dict:
    """Carrega o cache de t√≥picos j√° utilizados."""
    if TOPICS_CACHE.exists():
        try:
            with open(TOPICS_CACHE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {"used_topics": [], "last_update": ""}
    return {"used_topics": [], "last_update": ""}

def save_topics_cache(cache_data: Dict):
    """Salva o cache de t√≥picos."""
    with open(TOPICS_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache_data, f, ensure_ascii=False, indent=2)

def is_topic_duplicate(topic: str, used_topics: List[str]) -> bool:
    """Verifica se o t√≥pico √© muito similar aos j√° utilizados."""
    topic_hash = hashlib.md5(topic.lower().encode()).hexdigest()
    for used_topic in used_topics:
        used_hash = hashlib.md5(used_topic.lower().encode()).hexdigest()
        # Verifica similaridade b√°sica
        if topic_hash == used_hash or topic.lower() in used_topic.lower() or used_topic.lower() in topic.lower():
            return True
    return False

def get_current_tech_context() -> str:
    """Gera contexto temporal espec√≠fico para not√≠cias atuais."""
    today = datetime.now()
    current_date = today.strftime("%d de %B de %Y")
    current_month = today.strftime("%B de %Y")
    week_day = today.strftime("%A")
    
    # Contextos espec√≠ficos baseados na data
    contexts = [
        f"Esta semana ({current_date})",
        f"Neste m√™s de {current_month}",
        f"Nos √∫ltimos 7 dias",
        f"Esta {week_day}",
        "Recentemente anunciado",
        "Lan√ßado hoje",
        "Trending agora"
    ]
    
    return random.choice(contexts)

def get_market_trends() -> Dict[str, List[str]]:
    """Retorna tend√™ncias atuais do mercado tech por categoria."""
    return {
        "ai_ml": [
            "GPT-4 Turbo", "Claude 3.5", "Gemini Ultra", "Llama 3", "Midjourney v6",
            "Sora (OpenAI)", "Runway ML", "Anthropic Constitutional AI", "Meta AI Studio",
            "Google AI Studio", "Microsoft Copilot Pro", "GitHub Copilot X"
        ],
        "mobile": [
            "iPhone 16 Pro", "Samsung Galaxy S25", "Google Pixel 9", "OnePlus 13",
            "iOS 18", "Android 15", "One UI 7", "MIUI 15", "ColorOS 15",
            "5G SA", "eSIM", "satellite connectivity", "foldable displays"
        ],
        "software": [
            "Windows 11 24H2", "macOS Sequoia", "Ubuntu 24.04", "Chrome 130",
            "Firefox 131", "VS Code updates", "Docker Desktop", "Kubernetes 1.31",
            "React 19", "Next.js 15", "Vue 3.5", "Angular 18"
        ],
        "security": [
            "zero-day exploits", "ransomware-as-a-service", "supply chain attacks",
            "quantum-resistant encryption", "passwordless authentication", "FIDO2",
            "WebAuthn", "biometric security", "AI-powered threats", "deepfake detection"
        ],
        "cloud": [
            "AWS re:Invent", "Google Cloud Next", "Microsoft Build", "serverless computing",
            "edge computing", "multi-cloud", "hybrid cloud", "container orchestration",
            "microservices", "API-first architecture", "cloud-native security"
        ],
        "hardware": [
            "Apple M4", "Intel Core Ultra", "AMD Ryzen 8000", "NVIDIA RTX 50 series",
            "Qualcomm Snapdragon X", "ARM Cortex-X5", "DDR5 memory", "PCIe 5.0",
            "USB4 v2", "Thunderbolt 5", "Wi-Fi 7", "Bluetooth 6.0"
        ]
    }

def generate_news_technical_analysis() -> str:
    """Gera an√°lise t√©cnica baseada em not√≠cia real do Google News style."""
    print("üì∞ Gerando an√°lise t√©cnica de not√≠cia real...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    try:
        # Obt√©m not√≠cias atuais
        news_articles = get_current_news("technology")
        
        if news_articles:
            selected_news = random.choice(news_articles)
            news_title = selected_news["title"]
            news_source = selected_news["source"]
            
            # Limpa o t√≠tulo da not√≠cia para usar nos templates
            clean_title = news_title.replace('"', '').replace("'", "")
            
            # Templates de an√°lise t√©cnica baseados na not√≠cia
            analysis_templates = [
                f"An√°lise t√©cnica: {clean_title} - impactos na infraestrutura",
                f"Deep dive: por tr√°s de '{clean_title}' - arquitetura e implementa√ß√£o",
                f"Tech breakdown: {clean_title} - o que profissionais precisam saber",
                f"Security review: {clean_title} - vulnerabilidades e mitiga√ß√µes",
                f"Performance analysis: {clean_title} - benchmarks e otimiza√ß√µes", 
                f"DevOps perspective: {clean_title} - deployment e monitoring",
                f"Enterprise impact: {clean_title} - ROI e ado√ß√£o corporativa",
                f"Infrastructure implications: {clean_title} - scaling e recursos",
                f"Implementation guide: li√ß√µes t√©cnicas de '{clean_title}'",
                f"Case study t√©cnico: an√°lise completa de {clean_title}"
            ]
            
            # Define tamanho m√≠nimo flex√≠vel
            min_length = max(30, SEO_TITLE_MIN_LENGTH - 20)  # Mais flex√≠vel
            
            # Testa t√≠tulos at√© encontrar um v√°lido
            for template in analysis_templates:
                original_template = template
                
                # Verifica tamanho mas n√£o trunca automaticamente
                if len(template) > SEO_TITLE_MAX_LENGTH:
                    # Pula este template se muito longo
                    continue
                
                if len(template) >= min_length and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ An√°lise t√©cnica baseada em not√≠cia: {template}")
                    print(f"üì∞ Not√≠cia fonte: {news_source} - {clean_title}")
                    
                    # Atualiza cache com informa√ß√µes da not√≠cia
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": news_source,
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", ""),
                        "analysis_type": "technical"
                    }
                    save_topics_cache(cache_data)
                    
                    return template
            
            # Se nenhum template funcionou, tenta vers√µes mais curtas
            # Se chegou aqui, usa t√≠tulo mais direto sem truncar
            short_templates = [
                f"An√°lise t√©cnica: {clean_title}",
                f"Deep dive: {clean_title}",
                f"Tech breakdown: {clean_title}",
                f"An√°lise: {clean_title}"
            ]
            
            for template in short_templates:
                if len(template) >= min_length and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ An√°lise t√©cnica (vers√£o curta): {template}")
                    print(f"üì∞ Not√≠cia fonte: {news_source} - {clean_title}")
                    
                    # Atualiza cache
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": news_source,
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", ""),
                        "analysis_type": "technical"
                    }
                    save_topics_cache(cache_data)
                    
                    return template
        
        # Se chegou aqui, n√£o conseguiu gerar da not√≠cia
        print("‚ö†Ô∏è N√£o conseguiu gerar an√°lise da not√≠cia, tentando abordagem alternativa...")
        
        # Tenta uma abordagem mais simples
        if news_articles:
            simple_news = random.choice(news_articles)
            simple_title = f"An√°lise t√©cnica: {simple_news['title']}"
            if not is_topic_duplicate(simple_title, used_topics):
                print(f"‚úÖ An√°lise simples: {simple_title}")
                return simple_title
        
        # √öltimo fallback
        print("‚ö†Ô∏è Fallback para t√≥pico t√©cnico...")
        return generate_technical_seo_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar an√°lise t√©cnica: {e}")
        print("‚ö†Ô∏è Fallback para t√≥pico t√©cnico SEO...")
        return generate_technical_seo_topic()

def generate_it_professional_topic() -> str:
    """Gera t√≥pico t√©cnico focado em profissionais de TI."""
    print("üíª Gerando t√≥pico t√©cnico para profissionais de TI...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Obt√©m not√≠cias atuais
    try:
        news_articles = get_current_news("technology")
        
        if news_articles:
            selected_news = random.choice(news_articles)
            news_title = selected_news["title"]
            news_keywords = selected_news.get("keywords", [])
            
            # Templates t√©cnicos espec√≠ficos para IT
            it_templates = [
                f"Technical analysis: {news_title.lower()} - infrastructure implications",
                f"DevOps impact: how {news_title.lower()} affects deployment pipelines", 
                f"Security assessment: {news_title.lower()} vulnerabilities and mitigations",
                f"Performance review: {news_title.lower()} benchmarks and optimization",
                f"Architecture deep dive: {news_title.lower()} system design patterns",
                f"Enterprise perspective: {news_title.lower()} adoption challenges",
                f"Implementation guide: deploying solutions from {news_title.lower()}",
                f"Monitoring and observability: tracking {news_title.lower()} in production"
            ]
            
            # Se h√° palavras-chave t√©cnicas, cria t√≠tulos mais espec√≠ficos
            if news_keywords:
                tech_keyword = news_keywords[0]
                specific_templates = [
                    f"Deep dive: {tech_keyword} architecture revealed by {news_title.lower()}",
                    f"Performance analysis: {tech_keyword} scalability insights from {news_title.lower()}",
                    f"Security review: {tech_keyword} vulnerabilities exposed in {news_title.lower()}",
                    f"DevOps guide: {tech_keyword} deployment lessons from {news_title.lower()}",
                    f"Infrastructure impact: {tech_keyword} requirements after {news_title.lower()}"
                ]
                it_templates.extend(specific_templates)
            
            # Testa t√≠tulos t√©cnicos
            for template in it_templates:
                if len(template) <= SEO_TITLE_MAX_LENGTH and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ T√≠tulo t√©cnico: {template}")
                    print(f"üì∞ Base: {selected_news['source']} - {news_title}")
                    
                    # Atualiza cache
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": selected_news["source"],
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", "")
                    }
                    save_topics_cache(cache_data)
                    
                    return template
        
        # Fallback: gera t√≠tulo t√©cnico sem not√≠cia espec√≠fica
        return generate_technical_seo_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar t√≥pico t√©cnico: {e}")
        return generate_technical_seo_topic()

def generate_technical_seo_topic() -> str:
    """Gera t√≥pico t√©cnico SEO para profissionais de TI."""
    print("üîß Gerando t√≥pico t√©cnico SEO...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Seleciona elementos t√©cnicos
    tech_template = random.choice(IT_PROFESSIONAL_TITLE_TEMPLATES)
    tech_keyword = random.choice(IT_TECHNICAL_KEYWORDS)
    tech_area = random.choice(TRENDING_PRODUCTS + EMERGING_TECH)
    sector = random.choice(APPLICATION_SECTORS)
    
    # Gera varia√ß√µes t√©cnicas
    technical_variations = [
        tech_template.format(tecnologia=tech_keyword, alternativa=random.choice(IT_TECHNICAL_KEYWORDS), setor=sector),
        f"Performance benchmarks: {tech_keyword} vs {random.choice(IT_TECHNICAL_KEYWORDS)}",
        f"Production deployment: {tech_keyword} best practices and pitfalls",
        f"Scalability analysis: {tech_keyword} under high load conditions",
        f"Security hardening: {tech_keyword} configuration and monitoring",
        f"DevOps integration: {tech_keyword} in CI/CD pipelines",
        f"Infrastructure as Code: {tech_keyword} automation strategies",
        f"Monitoring and alerting: {tech_keyword} observability patterns"
    ]
    
    # Seleciona t√≠tulo v√°lido
    for title in technical_variations:
        if SEO_TITLE_MIN_LENGTH <= len(title) <= SEO_TITLE_MAX_LENGTH and not is_topic_duplicate(title, used_topics):
            print(f"‚úÖ T√≠tulo t√©cnico SEO: {title}")
            
            # Atualiza cache
            used_topics.append(title)
            cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
            cache_data["last_update"] = datetime.now().isoformat()
            save_topics_cache(cache_data)
            
            return title
    
    # Fallback final
    return generate_seo_optimized_topic()

def generate_news_based_topic() -> str:
    """Gera t√≥pico baseado em not√≠cias reais atuais."""
    print("üì∞ Gerando t√≥pico baseado em not√≠cias atuais...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Obt√©m not√≠cias atuais
    try:
        news_articles = get_current_news("technology")
        
        if not news_articles:
            print("‚ö†Ô∏è Nenhuma not√≠cia encontrada, usando gera√ß√£o SEO...")
            return generate_seo_optimized_topic()
        
        # Seleciona not√≠cia aleat√≥ria
        selected_news = random.choice(news_articles)
        
        # Gera varia√ß√µes de t√≠tulo baseadas na not√≠cia
        news_title = selected_news["title"]
        news_keywords = selected_news.get("keywords", [])
        
        # Templates para transformar not√≠cia em conte√∫do
        news_templates = [
            f"An√°lise: O que {news_title.lower()} significa para o mercado",
            f"Entendendo: Como {news_title.lower()} impacta empresas brasileiras", 
            f"Contexto: Por que {news_title.lower()} √© importante",
            f"Guia: O que aprender com {news_title.lower()}",
            f"Impacto: Como {news_title.lower()} muda o cen√°rio tech",
            f"An√°lise completa: {news_title} e suas implica√ß√µes"
        ]
        
        # Gera t√≠tulos mais espec√≠ficos se h√° palavras-chave
        if news_keywords:
            keyword = news_keywords[0]
            specific_templates = [
                f"Como {keyword} est√° transformando o mercado ap√≥s {news_title.lower()}",
                f"Guia completo: {keyword} no contexto de {news_title.lower()}",
                f"An√°lise: Impacto de {keyword} revelado por {news_title.lower()}",
                f"O que {news_title.lower()} ensina sobre {keyword}",
                f"Tend√™ncias em {keyword}: li√ß√µes de {news_title.lower()}"
            ]
            news_templates.extend(specific_templates)
        
        # Testa t√≠tulos at√© encontrar um v√°lido
        for template in news_templates:
            # Pula templates muito longos
            if len(template) > SEO_TITLE_MAX_LENGTH:
                continue
            
            if len(template) >= SEO_TITLE_MIN_LENGTH and not is_topic_duplicate(template, used_topics):
                print(f"‚úÖ T√≠tulo baseado em not√≠cia: {template}")
                print(f"üì∞ Not√≠cia fonte: {selected_news['source']} - {news_title}")
                
                # Atualiza cache
                used_topics.append(template)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                cache_data["news_source"] = {
                    "title": news_title,
                    "source": selected_news["source"],
                    "url": selected_news.get("url", ""),
                    "published_at": selected_news.get("published_at", "")
                }
                save_topics_cache(cache_data)
                
                return template
        
        print("‚ö†Ô∏è Nenhum t√≠tulo v√°lido gerado da not√≠cia, usando SEO...")
        return generate_seo_optimized_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao obter not√≠cias: {e}")
        print("‚ö†Ô∏è Fallback para gera√ß√£o SEO...")
        return generate_seo_optimized_topic()

def generate_seo_optimized_topic() -> str:
    """Gera um t√≥pico otimizado para SEO e Google Ads."""
    print("üéØ Gerando t√≥pico SEO-otimizado...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    today = datetime.now()
    current_year = today.year
    
    # Seleciona categoria SEO e palavras-chave
    seo_category = random.choice(list(SEO_KEYWORDS.keys()))
    keywords = SEO_KEYWORDS[seo_category]
    primary_keyword = random.choice(keywords)
    
    # Seleciona template SEO
    template = random.choice(SEO_TITLE_TEMPLATES)
    
    # Preenche o template com dados relevantes
    tech_area = random.choice(TRENDING_PRODUCTS + EMERGING_TECH)
    sector = random.choice(APPLICATION_SECTORS)
    audience = random.choice(["desenvolvedores", "empresas", "iniciantes", "profissionais"])
    number = random.choice(["5", "7", "10", "15"])
    
    # Gera t√≠tulo baseado no template
    title_variations = []
    
    try:
        title = template.format(
            tecnologia=primary_keyword,
            setor=sector,
            p√∫blico=audience,
            n√∫mero=number,
            ano=current_year,
            alternativa=random.choice(keywords),
            contexto=sector
        )
        title_variations.append(title)
    except KeyError:
        pass  # Template n√£o compat√≠vel, pula
    
    # Adiciona varia√ß√µes manuais SEO-friendly
    manual_variations = [
        f"Como usar {primary_keyword} para melhorar {sector}",
        f"Guia completo de {primary_keyword} para {audience}",
        f"{number} dicas de {primary_keyword} que funcionam em {current_year}",
        f"Tutorial: {primary_keyword} na pr√°tica para {sector}",
        f"An√°lise: impacto de {primary_keyword} no Brasil"
    ]
    
    title_variations.extend(manual_variations)
    
    # Seleciona t√≠tulo que n√£o seja duplicata
    for title in title_variations:
        if not is_topic_duplicate(title, used_topics):
            # Valida tamanho SEO
            if SEO_TITLE_MIN_LENGTH <= len(title) <= SEO_TITLE_MAX_LENGTH:
                print(f"‚úÖ T√≠tulo SEO gerado: {title}")
                print(f"üìä Palavra-chave principal: {primary_keyword}")
                print(f"üéØ Categoria: {seo_category}")
                
                # Atualiza cache
                used_topics.append(title)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                save_topics_cache(cache_data)
                
                return title
    
    # Fallback para gera√ß√£o com IA se necess√°rio
    print("‚ö†Ô∏è Nenhum t√≠tulo SEO v√°lido encontrado, usando gera√ß√£o com IA...")
    return generate_new_topic()

def generate_new_topic() -> str:
    """Usa a IA para gerar um novo t√≥pico educativo e anal√≠tico sobre tecnologia."""
    print("üß† Gerando t√≥pico educativo sobre tecnologia...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    today = datetime.now()
    current_date_str = today.strftime("%d de %B de %Y")
    current_year = today.year
    
    # Obt√©m tend√™ncias atuais do mercado
    market_trends = get_market_trends()
    
    # Seleciona uma categoria aleat√≥ria e pega algumas tend√™ncias
    category = random.choice(list(market_trends.keys()))
    category_trends = market_trends[category]
    
    max_attempts = MAX_TOPIC_ATTEMPTS
    for attempt in range(max_attempts):
        # Seleciona 2-3 tend√™ncias da categoria escolhida
        selected_trends = random.sample(category_trends, min(3, len(category_trends)))
        
        # Decide se ser√° conte√∫do puramente educativo ou h√≠brido (70% educativo, 30% h√≠brido)
        is_hybrid = random.random() < 0.3
        
        if is_hybrid:
            # Conte√∫do h√≠brido: educativo + contexto de not√≠cias
            content_type = random.choice(HYBRID_CONTENT_TYPES)
            hybrid_keyword = random.choice(HYBRID_KEYWORDS)
            news_context = random.choice(NEWS_CONTEXTS)
            tech_theme = random.choice(list(TECH_NEWS_THEMES.keys()))
            theme_topics = TECH_NEWS_THEMES[tech_theme]
            news_topic = random.choice(theme_topics)
            print(f"üîÑ Modo h√≠brido: {content_type} sobre {news_topic}")
        else:
            # Conte√∫do puramente educativo
            content_type = random.choice(EDUCATIONAL_CONTENT_TYPES)
            educational_keyword = random.choice(EDUCATIONAL_KEYWORDS)
            print(f"üìö Modo educativo: {content_type}")
        
        tech_area = random.choice(selected_trends)
        application_sector = random.choice(APPLICATION_SECTORS)
        technical_concept = random.choice(TECHNICAL_CONCEPTS)
        
        if is_hybrid:
            # Prompt para conte√∫do h√≠brido (educativo + contexto de not√≠cias)
            prompt = (
                f"Voc√™ √© um analista t√©cnico criando conte√∫do educativo contextualizado para {current_year}.\n\n"
                f"Gere um t√≠tulo que EDUQUE sobre tecnologia usando contexto de tend√™ncias atuais:\n\n"
                f"ELEMENTOS PARA O T√çTULO:\n"
                f"‚Ä¢ Tipo de an√°lise: {content_type}\n"
                f"‚Ä¢ Contexto atual: {news_context} {news_topic}\n"
                f"‚Ä¢ √Årea t√©cnica: {tech_area}\n"
                f"‚Ä¢ Setor de aplica√ß√£o: {application_sector}\n"
                f"‚Ä¢ Conceito t√©cnico: {technical_concept}\n\n"
                f"F√ìRMULAS H√çBRIDAS:\n"
                f"‚Ä¢ '{content_type}: {news_topic} e o impacto em [setor]'\n"
                f"‚Ä¢ 'O que {news_topic} ensina sobre [conceito t√©cnico]'\n"
                f"‚Ä¢ '{hybrid_keyword}: Como {news_topic} afeta [setor]'\n"
                f"‚Ä¢ 'Li√ß√µes de {news_topic} para [aplica√ß√£o pr√°tica]'\n\n"
                f"EXEMPLOS H√çBRIDOS:\n"
                f"‚Ä¢ 'An√°lise: O que os avan√ßos em IA generativa significam para startups'\n"
                f"‚Ä¢ 'Contexto: Por que investimentos em IA est√£o transformando a sa√∫de'\n"
                f"‚Ä¢ 'Entendendo o impacto de novos modelos de linguagem no desenvolvimento'\n"
                f"‚Ä¢ 'Li√ß√µes dos recentes desenvolvimentos em ciberseguran√ßa para PMEs'\n\n"
                f"DIRETRIZES H√çBRIDAS:\n"
                f"‚Ä¢ Use contexto de tend√™ncias SEM inventar fatos espec√≠ficos\n"
                f"‚Ä¢ Foque no APRENDIZADO que o contexto oferece\n"
                f"‚Ä¢ Mantenha tom educativo, n√£o noticioso\n"
                f"‚Ä¢ M√°ximo 100 caracteres\n"
                f"‚Ä¢ Evite datas espec√≠ficas ou eventos inventados\n\n"
                f"EVITE (j√° cobertos): {', '.join(used_topics[-5:]) if used_topics else 'nenhum'}\n\n"
                f"Gere um t√≠tulo que ENSINE usando contexto atual:\n"
                f"APENAS O T√çTULO:"
            )
        else:
            # Prompt para conte√∫do puramente educativo
            prompt = (
                f"Voc√™ √© um especialista t√©cnico criando conte√∫do educativo para {current_year}.\n\n"
                f"Gere um t√≠tulo EDUCATIVO sobre tecnologia usando estes elementos:\n\n"
                f"ELEMENTOS DISPON√çVEIS:\n"
                f"‚Ä¢ Tipo de conte√∫do: {content_type}\n"
                f"‚Ä¢ √Årea t√©cnica: {tech_area}\n"
                f"‚Ä¢ Palavra-chave educativa: {educational_keyword}\n"
                f"‚Ä¢ Setor de aplica√ß√£o: {application_sector}\n"
                f"‚Ä¢ Conceito t√©cnico: {technical_concept}\n\n"
                f"F√ìRMULAS EDUCATIVAS:\n"
                f"‚Ä¢ '{educational_keyword} [tecnologia]: [conceito] para [setor]'\n"
                f"‚Ä¢ '{content_type}: [tecnologia] em [setor] - [conceito]'\n"
                f"‚Ä¢ 'Como [tecnologia] melhora [conceito] no [setor]'\n"
                f"‚Ä¢ '{content_type} de [tecnologia]: [conceito] na pr√°tica'\n\n"
                f"EXEMPLOS DE QUALIDADE:\n"
                f"‚Ä¢ 'Guia completo: Implementando IA generativa em startups'\n"
                f"‚Ä¢ 'An√°lise: Como edge computing melhora performance em sa√∫de'\n"
                f"‚Ä¢ 'Entendendo blockchain: Seguran√ßa de dados no setor financeiro'\n"
                f"‚Ä¢ 'Comparativo: Arquiteturas de software para escalabilidade'\n\n"
                f"DIRETRIZES:\n"
                f"‚Ä¢ Foque em VALOR EDUCATIVO real\n"
                f"‚Ä¢ Use linguagem t√©cnica mas acess√≠vel\n"
                f"‚Ä¢ Seja espec√≠fico sobre aplica√ß√£o pr√°tica\n"
                f"‚Ä¢ M√°ximo 100 caracteres\n"
                f"‚Ä¢ Evite sensacionalismo\n\n"
                f"EVITE (j√° cobertos): {', '.join(used_topics[-5:]) if used_topics else 'nenhum'}\n\n"
                f"Gere UM t√≠tulo educativo que ensine algo valioso:\n"
                f"APENAS O T√çTULO:"
            )
        
        try:
            topic = call_gemini_api(prompt).strip()
            if topic and not is_topic_duplicate(topic, used_topics):
                print(f"‚úÖ T√≥pico gerado (tentativa {attempt + 1}): {topic}")
                
                # Atualiza o cache
                used_topics.append(topic)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                save_topics_cache(cache_data)
                
                return topic
            else:
                print(f"‚ö†Ô∏è T√≥pico duplicado ou inv√°lido (tentativa {attempt + 1})")
        except Exception as e:
            print(f"‚ùå Erro na tentativa {attempt + 1}: {e}")
    
    print("‚ùå N√£o foi poss√≠vel gerar um t√≥pico √∫nico ap√≥s v√°rias tentativas.")
    return ""

def get_educational_context(title: str) -> Dict[str, str]:
    """Gera contexto educativo baseado no t√≠tulo do artigo."""
    today = datetime.now()
    current_year = today.year
    
    # Identifica o tipo de conte√∫do baseado no t√≠tulo
    if any(word in title.lower() for word in ["como", "guia", "entendendo"]):
        content_focus = "explicativo"
    elif any(word in title.lower() for word in ["an√°lise", "comparativo", "vs"]):
        content_focus = "anal√≠tico"
    elif any(word in title.lower() for word in ["futuro", "tend√™ncias", "evolu√ß√£o"]):
        content_focus = "prospectivo"
    else:
        content_focus = "informativo"
    
    return {
        "current_year": str(current_year),
        "content_focus": content_focus,
        "educational_approach": random.choice([
            "did√°tico e acess√≠vel", "t√©cnico mas compreens√≠vel", 
            "pr√°tico e aplicado", "anal√≠tico e detalhado"
        ])
    }

def generate_references(title: str) -> List[str]:
    """Gera fontes de refer√™ncia realistas para o artigo."""
    print("üìö Selecionando fontes cred√≠veis...")
    
    # Seleciona fontes baseadas no tipo de not√≠cia
    references = []
    
    # Sempre inclui uma fonte brasileira
    references.append(random.choice(CREDIBLE_SOURCES["brazilian"]))
    
    # Adiciona fontes internacionais baseadas no t√≠tulo
    if any(company in title.lower() for company in ["apple", "google", "microsoft", "meta", "openai"]):
        references.append(random.choice(CREDIBLE_SOURCES["official"]))
    
    # Adiciona fontes de tech news
    references.extend(random.sample(CREDIBLE_SOURCES["tech_news"], 2))
    
    # Se menciona investimento/neg√≥cios, adiciona fonte business
    if any(word in title.lower() for word in ["bilh√µes", "aquisi√ß√£o", "investimento", "ipo"]):
        references.append(random.choice(CREDIBLE_SOURCES["business"]))
    
    # Remove duplicatas e limita a 5 fontes
    references = list(dict.fromkeys(references))[:5]
    
    print(f"‚úÖ {len(references)} fontes selecionadas: {', '.join(references)}")
    return references

def write_article_chunked(title: str) -> str:
    """Gera artigo em partes menores para evitar timeout."""
    print("üîß Gerando artigo em chunks para evitar timeout...")
    
    # Gera estrutura primeiro
    structure_prompt = (
        f"Crie apenas a ESTRUTURA de um artigo t√©cnico sobre: '{title}'\n\n"
        f"Retorne apenas os t√≠tulos das se√ß√µes em markdown (##), sem conte√∫do.\n"
        f"Exemplo:\n"
        f"## Resumo da Not√≠cia\n"
        f"## An√°lise T√©cnica\n"
        f"## Impactos na Infraestrutura\n"
        f"## Conclus√£o\n\n"
        f"M√°ximo 6 se√ß√µes."
    )
    
    try:
        structure = call_gemini_api(structure_prompt, timeout=15)
        sections = [s.strip() for s in structure.split('\n') if s.strip().startswith('##')]
        
        if not sections:
            print("‚ö†Ô∏è Fallback para gera√ß√£o normal...")
            return write_article(title)
        
        print(f"üìã Estrutura criada: {len(sections)} se√ß√µes")
        
        # Gera cada se√ß√£o separadamente
        full_article = ""
        
        for i, section in enumerate(sections):
            print(f"‚úçÔ∏è Gerando se√ß√£o {i+1}/{len(sections)}: {section}")
            
            section_prompt = (
                f"Escreva APENAS o conte√∫do para a se√ß√£o '{section}' de um artigo sobre: '{title}'\n\n"
                f"Contexto: An√°lise t√©cnica para profissionais de TI.\n"
                f"Tamanho: 150-250 palavras.\n"
                f"Tom: T√©cnico e informativo.\n\n"
                f"Retorne apenas o conte√∫do da se√ß√£o, sem o t√≠tulo."
            )
            
            try:
                section_content = call_gemini_api(section_prompt, timeout=20)
                full_article += f"{section}\n\n{section_content}\n\n"
                print(f"‚úÖ Se√ß√£o {i+1} conclu√≠da")
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na se√ß√£o {i+1}: {e}")
                # Continua com as outras se√ß√µes
                full_article += f"{section}\n\n[Conte√∫do da se√ß√£o em desenvolvimento]\n\n"
        
        return full_article
        
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o chunked: {e}")
        print("‚ö†Ô∏è Fallback para gera√ß√£o normal...")
        return write_article(title)

def write_article(title: str) -> str:
    """Gera o conte√∫do do artigo baseado em not√≠cias reais ou educativo."""
    
    # Detecta se √© conte√∫do baseado em not√≠cias
    is_news_based = any(word in title.lower() for word in [
        "an√°lise", "contexto:", "o que", "li√ß√µes", "por tr√°s", 
        "significam", "impacto de", "entendendo", "como", "ap√≥s",
        "deep dive:", "tech breakdown:", "security review:"
    ])
    
    # Obt√©m contexto de not√≠cia se dispon√≠vel
    news_context = None
    if is_news_based:
        # Primeiro tenta obter do cache (not√≠cia usada para gerar o t√≠tulo)
        cache_data = load_topics_cache()
        cached_news = cache_data.get("news_source")
        
        if cached_news and cached_news.get("title"):
            news_context = cached_news
            print(f"üì∞ Usando not√≠cia do cache: {cached_news['title']}")

        else:
            # Fallback: busca not√≠cia relevante
            title_keywords = []
            for category_keywords in SEO_KEYWORDS.values():
                for keyword in category_keywords:
                    if keyword.lower() in title.lower():
                        title_keywords.append(keyword)
            
            news_context = get_news_context(title_keywords)
    


    print(f"ÔøΩ DebuCg final - is_news_analysis: {is_news_analysis if 'is_news_analysis' in locals() else 'n√£o definido ainda'}")
    
    if news_context:
        print(f'‚úçÔ∏è Escrevendo artigo baseado em not√≠cia real: "{title}"...')
        print(f'üì∞ Contexto: {news_context["source"]} - {news_context["title"]}')
    elif is_news_based:
        print(f'‚úçÔ∏è Escrevendo artigo h√≠brido (educativo + contexto): "{title}"...')
    else:
        print(f'‚úçÔ∏è Escrevendo artigo educativo sobre: "{title}"...')
    
    # Gera as refer√™ncias cred√≠veis e contexto educativo
    references = generate_references(title)
    references_text = ", ".join(references)
    edu_context = get_educational_context(title)
    
    today = datetime.now()
    current_date = today.strftime("%d de %B de %Y")
    
    # Detecta se √© an√°lise t√©cnica de not√≠cia
    is_news_analysis = any(word in title.lower() for word in [
        "an√°lise t√©cnica:", "deep dive:", "tech breakdown:", "security review:",
        "performance analysis:", "devops perspective:", "enterprise impact:",
        "infrastructure implications:", "implementation guide:", "case study t√©cnico:"
    ])
    
    # Detecta se √© conte√∫do t√©cnico geral
    is_technical_content = any(word in title.lower() for word in [
        "technical", "deep dive", "performance", "security", "devops", 
        "architecture", "infrastructure", "deployment", "monitoring", "benchmarks"
    ])
    
    if news_context and is_news_analysis:
        # Prompt para conte√∫do t√©cnico baseado em not√≠cia
        news_title = news_context["title"]
        news_source = news_context["source"]
        news_description = news_context.get("description", "")
        
        prompt = (
            f"AN√ÅLISE EXECUTIVA PARA C-LEVEL - {current_date}\n\n"
            f"CONTEXTO: Voc√™ √© um consultor s√™nior de McKinsey/BCG escrevendo para CEOs, CTOs e executivos C-level sobre: '{news_title}'\n"
            f"ARTIGO: '{title}'\n\n"
            f"NOT√çCIA DE REFER√äNCIA:\n"
            f"- T√≠tulo: {news_title}\n"
            f"- Fonte: {news_source}\n"
            f"- Contexto: {news_description}\n\n"
            f"FONTES EXECUTIVAS: {references_text}\n\n"
            f"P√öBLICO-ALVO: Executivos C-level que precisam de informa√ß√µes PRECISAS e ACION√ÅVEIS para tomada de decis√£o estrat√©gica.\n\n"
            f"ESTRUTURA EXECUTIVA OBRIGAT√ìRIA:\n\n"
            f"## üìä Executive Summary\n"
            f"- Impacto nos neg√≥cios em 2-3 frases diretas\n"
            f"- N√∫meros e m√©tricas espec√≠ficas quando dispon√≠veis\n"
            f"- Recomenda√ß√£o estrat√©gica imediata\n\n"
            f"## üéØ Strategic Context\n"
            f"- Posicionamento competitivo no mercado\n"
            f"- Implica√ß√µes para diferentes setores\n"
            f"- Janela de oportunidade temporal\n\n"
            f"## üíº Business Impact Analysis\n"
            f"- Impacto direto em receita/custos/opera√ß√µes\n"
            f"- Riscos e oportunidades quantificados\n"
            f"- Compara√ß√£o com concorrentes diretos\n\n"
            f"## üîß Technical Implementation\n"
            f"- Requisitos t√©cnicos e de infraestrutura\n"
            f"- Timeline realista de implementa√ß√£o\n"
            f"- Investimento necess√°rio (CAPEX/OPEX)\n\n"
            f"## üìà Market Dynamics\n"
            f"- Tend√™ncias de ado√ß√£o no mercado\n"
            f"- Posi√ß√£o dos principais players\n"
            f"- Previs√µes baseadas em dados hist√≥ricos\n\n"
            f"## ‚ö° Action Items\n"
            f"- Pr√≥ximos passos imediatos (30/60/90 dias)\n"
            f"- Recursos necess√°rios e responsabilidades\n"
            f"- KPIs para monitoramento\n\n"
            f"PADR√ïES DE QUALIDADE EXECUTIVA:\n"
            f"üéØ PRECIS√ÉO ABSOLUTA: Toda informa√ß√£o deve ser verific√°vel e precisa\n"
            f"üéØ DENSIDADE INFORMACIONAL: {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras, zero fluff\n"
            f"üéØ LINGUAGEM EXECUTIVA: Direta, objetiva, sem jarg√µes desnecess√°rios\n"
            f"üéØ DADOS CONCRETOS: N√∫meros, percentuais, datas, vers√µes espec√≠ficas\n"
            f"üéØ AN√ÅLISE CR√çTICA: Pr√≥s, contras, riscos e oportunidades equilibrados\n"
            f"üéØ CONTEXTO COMPETITIVO: Compara√ß√µes com alternativas e concorrentes\n"
            f"üéØ ACIONABILIDADE: Cada se√ß√£o deve gerar insights para decis√£o\n\n"
            f"ELEMENTOS OBRIGAT√ìRIOS PARA C-LEVEL:\n"
            f"‚úÖ Executive Summary com impacto quantificado\n"
            f"‚úÖ An√°lise de ROI e TCO quando aplic√°vel\n"
            f"‚úÖ Timeline de implementa√ß√£o realista\n"
            f"‚úÖ Compara√ß√£o com solu√ß√µes concorrentes\n"
            f"‚úÖ Riscos t√©cnicos e de neg√≥cio identificados\n"
            f"‚úÖ Recomenda√ß√µes estrat√©gicas espec√≠ficas\n"
            f"‚úÖ M√©tricas de sucesso mensur√°veis\n\n"
            f"QUALIDADE EDITORIAL EXECUTIVA:\n"
            f"üìù Cada par√°grafo = um insight acion√°vel\n"
            f"üìù Transi√ß√µes l√≥gicas que constroem o argumento\n"
            f"üìù Linguagem precisa, sem redund√¢ncias\n"
            f"üìù Estrutura de pir√¢mide: conclus√µes primeiro, detalhes depois\n"
            f"üìù Verbos no presente para fatos, futuro para proje√ß√µes\n\n"
            f"PROIBI√á√ïES ABSOLUTAS:\n"
            f"‚ùå Informa√ß√µes imprecisas ou especulativas\n"
            f"‚ùå Linguagem promocional ou sensacionalista\n"
            f"‚ùå Generaliza√ß√µes sem dados de suporte\n"
            f"‚ùå Jarg√µes t√©cnicos sem explica√ß√£o\n"
            f"‚ùå Conclus√µes sem evid√™ncias\n"
            f"‚ùå Redund√¢ncias ou informa√ß√µes irrelevantes\n\n"
            f"INSTRU√á√ïES CR√çTICAS:\n"
            f"‚Ä¢ PRIMEIRO PAR√ÅGRAFO: Impacto nos neg√≥cios em n√∫meros concretos\n"
            f"‚Ä¢ DADOS ESPEC√çFICOS: Vers√µes, datas, percentuais, valores monet√°rios\n"
            f"‚Ä¢ AN√ÅLISE COMPETITIVA: Compare com pelo menos 2 alternativas\n"
            f"‚Ä¢ TIMELINE: Marcos espec√≠ficos de implementa√ß√£o\n"
            f"‚Ä¢ ROI: Quando aplic√°vel, inclua an√°lise de retorno\n"
            f"‚Ä¢ RISCOS: Identifique e quantifique riscos principais\n\n"
            f"Escreva uma AN√ÅLISE EXECUTIVA que um CEO usaria para tomar decis√µes estrat√©gicas!"
        )
    elif news_context:
        # Prompt para conte√∫do baseado em not√≠cia real (menos t√©cnico)
        news_title = news_context["title"]
        news_source = news_context["source"]
        news_description = news_context.get("description", "")
        
        prompt = (
            f"BRIEFING ESTRAT√âGICO PARA LIDERAN√áA T√âCNICA - {current_date}\n\n"
            f"CONTEXTO: Voc√™ √© um Principal Engineer/Architect escrevendo para CTOs, VPs de Engenharia e Tech Leads sobre: '{title}'\n\n"
            f"NOT√çCIA DE REFER√äNCIA:\n"
            f"- T√≠tulo: {news_title}\n"
            f"- Fonte: {news_source}\n"
            f"- Contexto: {news_description}\n\n"
            f"FONTES T√âCNICAS: {references_text}\n\n"
            f"P√öBLICO: L√≠deres t√©cnicos que precisam avaliar impacto estrat√©gico e tomar decis√µes de arquitetura/investimento.\n\n"
            f"ESTRUTURA DE BRIEFING T√âCNICO:\n\n"
            f"## üéØ Technical Summary\n"
            f"- Mudan√ßa t√©cnica principal e seu significado\n"
            f"- Impacto imediato em arquiteturas existentes\n"
            f"- N√≠vel de maturidade da tecnologia\n\n"
            f"## üèóÔ∏è Architecture Impact\n"
            f"- Como afeta stacks e infraestrutura atuais\n"
            f"- Compatibilidade com sistemas legados\n"
            f"- Requisitos de migra√ß√£o e refatora√ß√£o\n\n"
            f"## üë• Team & Skills Impact\n"
            f"- Novas compet√™ncias necess√°rias\n"
            f"- Impacto em processos de desenvolvimento\n"
            f"- Curva de aprendizado e treinamento\n\n"
            f"## üí∞ Investment Analysis\n"
            f"- Custos de implementa√ß√£o (licen√ßas, infraestrutura, pessoas)\n"
            f"- Timeline realista de ado√ß√£o\n"
            f"- ROI esperado e m√©tricas de sucesso\n\n"
            f"## ‚öñÔ∏è Risk Assessment\n"
            f"- Riscos t√©cnicos e de neg√≥cio\n"
            f"- Depend√™ncias externas e vendor lock-in\n"
            f"- Estrat√©gias de mitiga√ß√£o\n\n"
            f"## üöÄ Implementation Strategy\n"
            f"- Abordagem de ado√ß√£o recomendada (pilot, gradual, big bang)\n"
            f"- Marcos e entreg√°veis principais\n"
            f"- Crit√©rios de go/no-go\n\n"
            f"PADR√ïES DE QUALIDADE T√âCNICA:\n"
            f"üîß PRECIS√ÉO T√âCNICA: Informa√ß√µes verific√°veis e atualizadas\n"
            f"üîß DENSIDADE: {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras com alta densidade informacional\n"
            f"üîß LINGUAGEM T√âCNICA: Precisa mas acess√≠vel para lideran√ßa\n"
            f"üîß DADOS CONCRETOS: Benchmarks, vers√µes, especifica√ß√µes\n"
            f"üîß AN√ÅLISE CR√çTICA: Pr√≥s, contras e trade-offs claros\n"
            f"üîß CONTEXTO COMPETITIVO: Compara√ß√£o com alternativas\n"
            f"üîß ACIONABILIDADE: Insights que geram decis√µes\n\n"
            f"ELEMENTOS OBRIGAT√ìRIOS:\n"
            f"‚úÖ An√°lise de impacto em arquitetura existente\n"
            f"‚úÖ Estimativas de esfor√ßo e timeline\n"
            f"‚úÖ Compara√ß√£o t√©cnica com alternativas\n"
            f"‚úÖ Identifica√ß√£o de riscos e depend√™ncias\n"
            f"‚úÖ Recomenda√ß√µes de implementa√ß√£o\n"
            f"‚úÖ M√©tricas t√©cnicas de sucesso\n"
            f"‚úÖ Considera√ß√µes de escalabilidade\n\n"
            f"QUALIDADE EDITORIAL:\n"
            f"üìã Cada se√ß√£o = decis√£o ou insight espec√≠fico\n"
            f"üìã Argumenta√ß√£o l√≥gica e estruturada\n"
            f"üìã Linguagem direta, sem ambiguidades\n"
            f"üìã Dados t√©cnicos espec√≠ficos e verific√°veis\n"
            f"üìã Conclus√µes baseadas em evid√™ncias\n\n"
            f"PROIBI√á√ïES:\n"
            f"‚ùå Especula√ß√µes sem base t√©cnica\n"
            f"‚ùå Hype sem an√°lise cr√≠tica\n"
            f"‚ùå Generaliza√ß√µes sem contexto\n"
            f"‚ùå Informa√ß√µes desatualizadas\n"
            f"‚ùå Recomenda√ß√µes sem justificativa\n\n"
            f"FOCO ESTRAT√âGICO:\n"
            f"‚Ä¢ Impacto em decis√µes de arquitetura\n"
            f"‚Ä¢ Considera√ß√µes de budget e recursos\n"
            f"‚Ä¢ Timeline de implementa√ß√£o realista\n"
            f"‚Ä¢ An√°lise de risco vs benef√≠cio\n"
            f"‚Ä¢ Estrat√©gia de ado√ß√£o gradual\n\n"
            f"Escreva um BRIEFING T√âCNICO que l√≠deres usar√£o para decis√µes estrat√©gicas!"
        )
    elif is_news_based:
        # Prompt para conte√∫do h√≠brido (educativo + contexto de tend√™ncias)
        prompt = (
            f"ARTIGO EDUCATIVO CONTEXTUALIZADO - {current_date}\n\n"
            f"Voc√™ √© um analista t√©cnico escrevendo um artigo EDUCATIVO que usa contexto de tend√™ncias: '{title}'\n\n"
            f"CONTEXTO EDUCATIVO:\n"
            f"- Ano de refer√™ncia: {edu_context['current_year']}\n"
            f"- Foco do conte√∫do: {edu_context['content_focus']}\n"
            f"- Abordagem: {edu_context['educational_approach']}\n\n"
            f"FONTES DE REFER√äNCIA: {references_text}\n\n"
            f"ESTRUTURA H√çBRIDA:\n"
            f"1. INTRODU√á√ÉO: Contextualize a tend√™ncia e sua relev√¢ncia educativa\n"
            f"2. ## Contexto Atual (tend√™ncias gerais, sem fatos espec√≠ficos)\n"
            f"3. ## Conceitos T√©cnicos Envolvidos (explica√ß√£o educativa)\n"
            f"4. ## An√°lise do Impacto (o que isso significa tecnicamente)\n"
            f"5. ## Li√ß√µes e Aprendizados (insights educativos)\n"
            f"6. ## Aplica√ß√µes Pr√°ticas (como aplicar o conhecimento)\n"
            f"7. ## Conclus√£o (s√≠ntese educativa)\n\n"
            f"DIRETRIZES H√çBRIDAS:\n"
            f"- {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras (otimizado para SEO)\n"
            f"- Use contexto de tend√™ncias para EDUCAR, n√£o para noticiar\n"
            f"- Foque no APRENDIZADO que as tend√™ncias oferecem\n"
            f"- Explique conceitos t√©cnicos por tr√°s das tend√™ncias\n"
            f"- Mantenha tom educativo, nunca jornal√≠stico urgente\n"
            f"- Contextualize para profissionais brasileiros\n\n"
            f"PROIBI√á√ïES ABSOLUTAS:\n"
            f"‚ùå N√ÉO invente eventos espec√≠ficos ou datas\n"
            f"‚ùå N√ÉO crie not√≠cias falsas ou fatos espec√≠ficos\n"
            f"‚ùå N√ÉO use linguagem de urg√™ncia jornal√≠stica\n"
            f"‚ùå N√ÉO afirme acontecimentos espec√≠ficos n√£o verific√°veis\n"
            f"‚ùå N√ÉO crie cita√ß√µes ou declara√ß√µes falsas\n\n"
            f"FOQUE EM EDUCA√á√ÉO CONTEXTUALIZADA:\n"
            f"‚úÖ Use tend√™ncias gerais como contexto educativo\n"
            f"‚úÖ Explique conceitos t√©cnicos por tr√°s das tend√™ncias\n"
            f"‚úÖ Analise implica√ß√µes e aprendizados\n"
            f"‚úÖ Forne√ßa insights pr√°ticos e aplic√°veis\n"
            f"‚úÖ Eduque sobre como se preparar para mudan√ßas\n\n"
            f"Escreva um artigo que EDUQUE usando contexto de tend√™ncias atuais!"
        )
    else:
        # Prompt para conte√∫do puramente educativo
        prompt = (
            f"GUIA ESTRAT√âGICO PARA EXECUTIVOS DE TECNOLOGIA - {current_date}\n\n"
            f"CONTEXTO: Voc√™ √© um consultor s√™nior da Gartner/Forrester escrevendo um guia executivo sobre: '{title}'\n\n"
            f"CONTEXTO ESTRAT√âGICO:\n"
            f"- Ano de refer√™ncia: {edu_context['current_year']}\n"
            f"- Foco estrat√©gico: {edu_context['content_focus']}\n"
            f"- Abordagem: {edu_context['educational_approach']}\n\n"
            f"FONTES EXECUTIVAS: {references_text}\n\n"
            f"P√öBLICO: CTOs, CIOs, VPs de Tecnologia e executivos que precisam entender implica√ß√µes estrat√©gicas.\n\n"
            f"ESTRUTURA DE GUIA EXECUTIVO:\n\n"
            f"## üìã Executive Overview\n"
            f"- Defini√ß√£o clara e impacto nos neg√≥cios\n"
            f"- Por que isso importa agora para lideran√ßa\n"
            f"- Principais players e market share\n\n"
            f"## üîç Technology Deep Dive\n"
            f"- Como funciona (explica√ß√£o t√©cnica acess√≠vel)\n"
            f"- Diferenciadores t√©cnicos principais\n"
            f"- Maturidade da tecnologia e roadmap\n\n"
            f"## üíº Business Applications\n"
            f"- Casos de uso por setor/ind√∫stria\n"
            f"- ROI t√≠pico e m√©tricas de sucesso\n"
            f"- Exemplos de implementa√ß√£o bem-sucedida\n\n"
            f"## ‚öñÔ∏è Strategic Analysis\n"
            f"- Vantagens competitivas e limita√ß√µes\n"
            f"- Compara√ß√£o com alternativas dispon√≠veis\n"
            f"- Riscos e considera√ß√µes de compliance\n\n"
            f"## üöÄ Implementation Framework\n"
            f"- Estrat√©gia de ado√ß√£o recomendada\n"
            f"- Investimento necess√°rio e timeline\n"
            f"- Compet√™ncias e recursos requeridos\n\n"
            f"## üìä Market Intelligence\n"
            f"- Tend√™ncias de ado√ß√£o no mercado\n"
            f"- Previs√µes de crescimento e evolu√ß√£o\n"
            f"- Posicionamento competitivo futuro\n\n"
            f"PADR√ïES DE QUALIDADE EXECUTIVA:\n"
            f"üéØ PRECIS√ÉO ESTRAT√âGICA: Informa√ß√µes verific√°veis e atuais\n"
            f"üéØ DENSIDADE EXECUTIVA: {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras, zero redund√¢ncia\n"
            f"üéØ LINGUAGEM EXECUTIVA: Clara, direta, sem jarg√µes desnecess√°rios\n"
            f"üéØ DADOS CONCRETOS: Market share, crescimento, investimentos\n"
            f"üéØ AN√ÅLISE ESTRAT√âGICA: Oportunidades, amea√ßas, posicionamento\n"
            f"üéØ CONTEXTO COMPETITIVO: Benchmarking com alternativas\n"
            f"üéØ ACIONABILIDADE: Insights que direcionam estrat√©gia\n\n"
            f"ELEMENTOS OBRIGAT√ìRIOS:\n"
            f"‚úÖ Defini√ß√£o clara e impacto nos neg√≥cios\n"
            f"‚úÖ An√°lise de ROI e business case\n"
            f"‚úÖ Compara√ß√£o com solu√ß√µes concorrentes\n"
            f"‚úÖ Timeline de implementa√ß√£o realista\n"
            f"‚úÖ Identifica√ß√£o de riscos estrat√©gicos\n"
            f"‚úÖ Recomenda√ß√µes baseadas em dados\n"
            f"‚úÖ M√©tricas de sucesso mensur√°veis\n\n"
            f"QUALIDADE EDITORIAL EXECUTIVA:\n"
            f"üìà Cada se√ß√£o = insight estrat√©gico acion√°vel\n"
            f"üìà Argumenta√ß√£o l√≥gica com dados de suporte\n"
            f"üìà Linguagem precisa e objetiva\n"
            f"üìà Estrutura que facilita tomada de decis√£o\n"
            f"üìà Conclus√µes baseadas em evid√™ncias\n\n"
            f"PROIBI√á√ïES ABSOLUTAS:\n"
            f"‚ùå Especula√ß√µes sem base em dados\n"
            f"‚ùå Linguagem promocional ou tendenciosa\n"
            f"‚ùå Informa√ß√µes t√©cnicas excessivamente detalhadas\n"
            f"‚ùå Generaliza√ß√µes sem contexto espec√≠fico\n"
            f"‚ùå Recomenda√ß√µes sem justificativa estrat√©gica\n"
            f"‚ùå Dados desatualizados ou imprecisos\n\n"
            f"FOCO ESTRAT√âGICO:\n"
            f"‚Ä¢ Impacto em vantagem competitiva\n"
            f"‚Ä¢ Considera√ß√µes de investimento e ROI\n"
            f"‚Ä¢ Riscos estrat√©gicos e mitiga√ß√£o\n"
            f"‚Ä¢ Timeline de ado√ß√£o no mercado\n"
            f"‚Ä¢ Posicionamento vs concorrentes\n"
            f"‚Ä¢ Compet√™ncias organizacionais necess√°rias\n\n"
            f"Escreva um GUIA ESTRAT√âGICO que executivos usar√£o para decis√µes de investimento em tecnologia!"
        )
    
    try:
        safety_settings = {
            'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
            'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
            'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
            'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE',
        }
        
        article = call_gemini_api(prompt, safety_settings=safety_settings)
        
        if article:
            # Aplica limpeza completa e formata√ß√£o
            article = clean_content_completely(article)
            article = create_simple_structure(article, title)
            article = improve_journalistic_language(article)
            article = format_content(article)
            
            # Adiciona se√ß√£o de refer√™ncias formatada
            article += "\n\n---\n\n## üìö Fontes e Refer√™ncias\n\n"
            for i, ref in enumerate(references, 1):
                article += f"{i}. **{ref}**\n"
            
            # CTA engajante j√° foi aplicado pela fun√ß√£o add_engaging_cta
            
            print("‚úÖ Artigo gerado e formatado com sucesso.")
            return article
        else:
            print("‚ùå A IA n√£o retornou um artigo v√°lido.")
            return ""
    except Exception as e:
        print(f"‚ùå Erro ao gerar o artigo: {e}")
        return ""

def generate_seo_description(title: str, content: str) -> str:
    """Gera meta description otimizada para SEO."""
    print("üìù Gerando meta description SEO...")
    
    # Extrai primeira frase do conte√∫do
    first_paragraph = content.split('\n')[0:3]
    clean_text = ' '.join(first_paragraph).replace('#', '').strip()
    
    # Identifica palavra-chave principal do t√≠tulo
    title_lower = title.lower()
    primary_keyword = ""
    
    for category, keywords in SEO_KEYWORDS.items():
        for keyword in keywords:
            if keyword in title_lower:
                primary_keyword = keyword
                break
        if primary_keyword:
            break
    
    # Templates de meta description SEO
    templates = [
        f"Descubra como {primary_keyword} pode transformar seu neg√≥cio. Guia completo com dicas pr√°ticas e exemplos reais.",
        f"Tudo sobre {primary_keyword}: conceitos, implementa√ß√£o e melhores pr√°ticas. Leia nosso guia completo.",
        f"Aprenda {primary_keyword} do zero ao avan√ßado. Tutorial completo com exemplos pr√°ticos e dicas de especialistas.",
        f"Guia definitivo de {primary_keyword}: como implementar, vantagens e casos de sucesso no Brasil.",
        f"{primary_keyword} explicado: conceitos, aplica√ß√µes e como come√ßar. Guia pr√°tico para iniciantes e profissionais."
    ]
    
    if primary_keyword:
        description = random.choice(templates)
    else:
        # Fallback baseado no conte√∫do
        description = clean_text[:SEO_DESCRIPTION_MAX_LENGTH-3] + "..."
    
    # Ajusta tamanho para SEO
    if len(description) > SEO_DESCRIPTION_MAX_LENGTH:
        description = description[:SEO_DESCRIPTION_MAX_LENGTH-3] + "..."
    elif len(description) < SEO_DESCRIPTION_MIN_LENGTH:
        description += f" Leia mais sobre {primary_keyword} e suas aplica√ß√µes pr√°ticas."
    
    print(f"‚úÖ Meta description gerada ({len(description)} chars)")
    return description

def extract_seo_keywords(title: str, content: str) -> List[str]:
    """Extrai palavras-chave SEO do t√≠tulo e conte√∫do com valida√ß√£o de consist√™ncia."""
    keywords = []
    title_lower = title.lower()
    content_lower = content.lower()
    combined_text = f"{title_lower} {content_lower}"
    
    # Mapeamento de contexto para valida√ß√£o
    context_validation = {
        "aws": ["amazon", "graviton", "ec2", "s3", "lambda", "cloud"],
        "google": ["android", "pixel", "chrome", "youtube", "search", "gemini"],
        "apple": ["iphone", "ipad", "mac", "ios", "safari", "app store"],
        "microsoft": ["windows", "azure", "office", "teams", "xbox", "surface"],
        "meta": ["facebook", "instagram", "whatsapp", "oculus", "threads"],
        "openai": ["chatgpt", "gpt", "dall-e", "whisper", "codex"],
        "anthropic": ["claude", "constitutional ai", "safety"],
        "nvidia": ["gpu", "cuda", "geforce", "rtx", "tensor", "ai"],
        "tesla": ["model", "autopilot", "supercharger", "cybertruck", "fsd"],
        "spacex": ["falcon", "dragon", "starship", "starlink", "mars"]
    }
    
    # Identifica palavras-chave principais com valida√ß√£o de contexto
    for category, keyword_list in SEO_KEYWORDS.items():
        for keyword in keyword_list:
            if keyword in combined_text:
                # Valida√ß√£o de contexto para evitar inconsist√™ncias
                is_valid = True
                
                # Se a keyword √© uma empresa, valida se o contexto faz sentido
                if keyword in context_validation:
                    context_words = context_validation[keyword]
                    has_context = any(word in combined_text for word in context_words)
                    
                    if not has_context:
                        print(f"‚ö†Ô∏è Keyword '{keyword}' removida - sem contexto v√°lido")
                        is_valid = False
                
                # Valida√ß√£o adicional: evita keywords conflitantes
                conflicting_keywords = {
                    "google": ["aws", "amazon", "microsoft azure"],
                    "aws": ["google cloud", "azure", "microsoft"],
                    "apple": ["android", "google pixel", "samsung"],
                    "android": ["ios", "iphone", "apple"],
                    "ios": ["android", "google", "samsung"]
                }
                
                if keyword in conflicting_keywords:
                    conflicts = conflicting_keywords[keyword]
                    has_conflict = any(conflict in combined_text for conflict in conflicts)
                    
                    # Se h√° conflito, verifica qual √© mais relevante
                    if has_conflict:
                        keyword_count = combined_text.count(keyword)
                        conflict_counts = [combined_text.count(conflict) for conflict in conflicts]
                        max_conflict_count = max(conflict_counts) if conflict_counts else 0
                        
                        if keyword_count < max_conflict_count:
                            print(f"‚ö†Ô∏è Keyword '{keyword}' removida - conflito com termo mais relevante")
                            is_valid = False
                
                if is_valid:
                    keywords.append(keyword)
    
    # Remove duplicatas e limita
    keywords = list(dict.fromkeys(keywords))[:SEO_KEYWORDS_PER_POST]
    
    # Se n√£o encontrou keywords v√°lidas, extrai do conte√∫do principal
    if not keywords:
        # Extrai palavras mais frequentes do t√≠tulo e conte√∫do
        import re
        words = re.findall(r'\b\w{4,}\b', combined_text)
        word_freq = {}
        
        for word in words:
            if word not in ['para', 'como', 'mais', 'sobre', 'pela', 'pelo', 'esta', 'este', 'essa', 'esse']:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # Pega as 3 palavras mais frequentes
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:3]
        keywords = [word for word, count in top_words if count > 1]
    
    print(f"‚úÖ Keywords SEO validadas: {', '.join(keywords)}")
    return keywords

def generate_tags(title: str, content: str) -> List[str]:
    """Gera tags relevantes e espec√≠ficas para o post baseado no t√≠tulo e conte√∫do."""
    print("üè∑Ô∏è Gerando tags espec√≠ficas para o post...")
    
    # An√°lise inteligente do t√≠tulo e conte√∫do para tags espec√≠ficas
    title_lower = title.lower()
    content_lower = content.lower()
    
    # Mapeamento de palavras-chave para tags espec√≠ficas
    keyword_to_tags = {
        # IA e Machine Learning
        "intelig√™ncia artificial": ["inteligencia-artificial", "machine-learning", "automacao"],
        "chatgpt": ["inteligencia-artificial", "openai", "chatbots"],
        "gemini": ["inteligencia-artificial", "google", "llm"],
        "claude": ["inteligencia-artificial", "anthropic", "assistentes-ia"],
        "machine learning": ["machine-learning", "algoritmos", "dados"],
        "deep learning": ["deep-learning", "redes-neurais", "ia-avancada"],
        "llm": ["modelos-linguagem", "inteligencia-artificial", "nlp"],
        
        # Empresas e Big Tech
        "google": ["google", "big-tech", "android"],
        "apple": ["apple", "big-tech", "ios"],
        "microsoft": ["microsoft", "big-tech", "azure"],
        "meta": ["meta", "big-tech", "realidade-virtual"],
        "amazon": ["amazon", "big-tech", "aws"],
        "openai": ["openai", "inteligencia-artificial", "startups"],
        "nvidia": ["nvidia", "hardware", "gpu"],
        "tesla": ["tesla", "veiculos-eletricos", "autonomos"],
        
        # Tecnologias Espec√≠ficas
        "blockchain": ["blockchain", "criptomoedas", "web3"],
        "kubernetes": ["kubernetes", "devops", "containers"],
        "docker": ["docker", "containers", "devops"],
        "react": ["react", "javascript", "frontend"],
        "python": ["python", "programacao", "desenvolvimento"],
        "javascript": ["javascript", "web", "programacao"],
        "cloud": ["cloud-computing", "nuvem", "infraestrutura"],
        "aws": ["aws", "cloud-computing", "amazon"],
        "azure": ["azure", "cloud-computing", "microsoft"],
        
        # Seguran√ßa
        "ciberseguran√ßa": ["ciberseguranca", "seguranca-digital", "privacidade"],
        "seguran√ßa": ["seguranca", "protecao-dados", "privacidade"],
        "vulnerabilidade": ["vulnerabilidades", "seguranca", "exploits"],
        "ransomware": ["ransomware", "malware", "ciberseguranca"],
        
        # √Åreas Emergentes
        "quantum": ["computacao-quantica", "qubits", "tecnologia-emergente"],
        "biotecnologia": ["biotecnologia", "bioinformatica", "saude-digital"],
        "neuralink": ["neuralink", "interface-cerebral", "neurociencia"],
        "spacex": ["spacex", "tecnologia-espacial", "foguetes"],
        "starship": ["spacex", "exploracao-espacial", "marte"],
        
        # Mobile e Dispositivos
        "iphone": ["iphone", "apple", "mobile"],
        "android": ["android", "google", "mobile"],
        "samsung": ["samsung", "smartphones", "mobile"],
        "pixel": ["google-pixel", "android", "smartphones"],
        
        # Desenvolvimento e DevOps
        "devops": ["devops", "ci-cd", "automacao"],
        "api": ["apis", "desenvolvimento", "integracao"],
        "microservices": ["microservicos", "arquitetura", "cloud"],
        "serverless": ["serverless", "cloud", "funcoes"],
        
        # An√°lise e Dados
        "big data": ["big-data", "analytics", "dados"],
        "analytics": ["analytics", "dados", "business-intelligence"],
        "data science": ["data-science", "ciencia-dados", "machine-learning"],
        
        # Startups e Neg√≥cios
        "startup": ["startups", "empreendedorismo", "inovacao"],
        "unic√≥rnio": ["unicornios", "startups", "investimentos"],
        "venture capital": ["venture-capital", "investimentos", "startups"],
        "ipo": ["ipo", "mercado-financeiro", "startups"],
        
        # Tend√™ncias Tecnol√≥gicas
        "metaverso": ["metaverso", "realidade-virtual", "web3"],
        "nft": ["nfts", "blockchain", "arte-digital"],
        "web3": ["web3", "blockchain", "descentralizacao"],
        "iot": ["internet-das-coisas", "iot", "dispositivos-conectados"],
        "5g": ["5g", "conectividade", "telecomunicacoes"],
        "edge computing": ["edge-computing", "computacao-borda", "latencia"],
        
        # An√°lise T√©cnica
        "performance": ["performance", "otimizacao", "benchmarks"],
        "scalability": ["escalabilidade", "arquitetura", "performance"],
        "architecture": ["arquitetura-software", "design-sistemas", "engenharia"],
        "security": ["seguranca", "protecao", "vulnerabilidades"],
        "infrastructure": ["infraestrutura", "sistemas", "operacoes"],
        "monitoring": ["monitoramento", "observabilidade", "devops"],
        "deployment": ["deployment", "implantacao", "devops"],
        "automation": ["automacao", "ci-cd", "devops"],
        
        # Ve√≠culos e Transporte
        "aut√¥nomo": ["veiculos-autonomos", "ia-automotiva", "transporte"],
        "el√©trico": ["veiculos-eletricos", "sustentabilidade", "energia"],
        "fsd": ["full-self-driving", "tesla", "autonomia"],
        
        # Materiais e Ci√™ncia
        "supercondutores": ["supercondutores", "novos-materiais", "fisica"],
        "grafeno": ["grafeno", "nanotecnologia", "materiais"],
        "nanotecnologia": ["nanotecnologia", "materiais-avancados", "ciencia"]
    }
    
    # Detecta tags baseadas no conte√∫do com valida√ß√£o de consist√™ncia
    detected_tags = set()
    
    # Analisa t√≠tulo e conte√∫do
    text_to_analyze = f"{title_lower} {content_lower}"
    
    # Valida√ß√£o de contexto para empresas
    company_context = {
        "aws": ["amazon", "graviton", "ec2", "s3", "lambda", "cloud computing"],
        "google": ["android", "pixel", "chrome", "search", "gemini", "alphabet"],
        "apple": ["iphone", "ipad", "mac", "ios", "safari", "app store"],
        "microsoft": ["windows", "azure", "office", "teams", "xbox"],
        "meta": ["facebook", "instagram", "whatsapp", "oculus"],
        "openai": ["chatgpt", "gpt", "dall-e", "whisper"],
        "anthropic": ["claude", "constitutional ai"],
        "nvidia": ["gpu", "cuda", "geforce", "rtx", "tensor"],
        "tesla": ["model", "autopilot", "supercharger", "cybertruck"]
    }
    
    for keyword, tags in keyword_to_tags.items():
        if keyword in text_to_analyze:
            # Valida√ß√£o de contexto para evitar tags inconsistentes
            is_valid = True
            
            # Para empresas, verifica se h√° contexto adequado
            for tag in tags:
                if tag in company_context:
                    context_words = company_context[tag]
                    has_context = any(word in text_to_analyze for word in context_words)
                    
                    if not has_context:
                        print(f"‚ö†Ô∏è Tag '{tag}' removida - sem contexto v√°lido para {keyword}")
                        is_valid = False
                        break
            
            if is_valid:
                detected_tags.update(tags[:2])  # M√°ximo 2 tags por palavra-chave
    
    # Se n√£o detectou tags espec√≠ficas, usa an√°lise por IA mais direcionada
    if len(detected_tags) < 2:
        prompt = (
            f"AN√ÅLISE DE TAGS ESPEC√çFICAS\n\n"
            f"T√≠tulo: {title}\n"
            f"Conte√∫do: {content[:500]}...\n\n"
            f"Baseado no conte√∫do acima, identifique as 4-6 tags MAIS ESPEC√çFICAS poss√≠veis.\n\n"
            f"TAGS DISPON√çVEIS POR CATEGORIA:\n"
            f"‚Ä¢ IA: inteligencia-artificial, machine-learning, chatgpt, openai, anthropic, llm, automacao\n"
            f"‚Ä¢ Big Tech: google, apple, microsoft, meta, amazon, nvidia, tesla, spacex\n"
            f"‚Ä¢ Desenvolvimento: python, javascript, react, nodejs, api, devops, kubernetes, docker\n"
            f"‚Ä¢ Seguran√ßa: ciberseguranca, vulnerabilidades, ransomware, protecao-dados, privacidade\n"
            f"‚Ä¢ Mobile: iphone, android, samsung, smartphones, aplicativos\n"
            f"‚Ä¢ Cloud: aws, azure, google-cloud, serverless, microservicos, containers\n"
            f"‚Ä¢ Emergentes: blockchain, web3, metaverso, computacao-quantica, biotecnologia\n"
            f"‚Ä¢ Neg√≥cios: startups, unicornios, investimentos, venture-capital, inovacao\n"
            f"‚Ä¢ An√°lise: performance, escalabilidade, arquitetura, benchmarks, otimizacao\n\n"
            f"INSTRU√á√ïES:\n"
            f"1. Escolha tags que REALMENTE descrevem o conte√∫do espec√≠fico\n"
            f"2. Evite tags gen√©ricas como 'tecnologia' ou 'inovacao'\n"
            f"3. Priorize tags t√©cnicas e espec√≠ficas\n"
            f"4. Use h√≠fens no lugar de espa√ßos\n"
            f"5. Retorne apenas as tags separadas por v√≠rgula\n\n"
            f"Exemplo: inteligencia-artificial, openai, chatgpt, automacao\n\n"
            f"Tags espec√≠ficas:"
        )
        
        try:
            tags_text = call_gemini_api(prompt).strip()
            ai_tags = [tag.strip().lower().replace(' ', '-') for tag in tags_text.split(',')]
            detected_tags.update([tag for tag in ai_tags if tag and len(tag) > 2])
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na an√°lise IA de tags: {e}")
    
    # Converte para lista e limita
    final_tags = list(detected_tags)[:MAX_TAGS]
    
    # Fallback inteligente se ainda n√£o tem tags suficientes
    if len(final_tags) < 2:
        fallback_tags = []
        
        # An√°lise por palavras-chave do t√≠tulo
        if "an√°lise" in title_lower:
            fallback_tags.append("analise-tecnica")
        if "deep dive" in title_lower:
            fallback_tags.append("analise-profunda")
        if "security" in title_lower or "seguran√ßa" in title_lower:
            fallback_tags.append("ciberseguranca")
        if "performance" in title_lower:
            fallback_tags.append("performance")
        if "devops" in title_lower:
            fallback_tags.append("devops")
        if "cloud" in title_lower or "nuvem" in title_lower:
            fallback_tags.append("cloud-computing")
        
        # Adiciona tags de fallback
        final_tags.extend(fallback_tags)
        
        # Se ainda n√£o tem tags, usa as mais relevantes do contexto
        if len(final_tags) < 2:
            final_tags.extend(["tecnologia-empresarial", "inovacao-digital"])
    
    # Remove duplicatas e limita
    final_tags = list(dict.fromkeys(final_tags))[:MAX_TAGS]
    
    print(f"‚úÖ Tags geradas: {', '.join(final_tags)}")
    return final_tags

def create_hugo_post(title: str, content: str) -> Optional[Path]:
    """Cria e salva o arquivo .md para o Hugo com otimiza√ß√µes SEO completas."""
    print("üìù Formatando e salvando o post SEO-otimizado...")
    try:
        now = datetime.now()
        tz_offset = timezone(timedelta(hours=TIMEZONE_OFFSET))
        iso_timestamp = now.astimezone(tz_offset).isoformat()
        
        # Gera elementos SEO
        tags = generate_tags(title, content)
        seo_description = generate_seo_description(title, content)
        seo_keywords = extract_seo_keywords(title, content)
        
        # Calcula reading time (palavras / 200 palavras por minuto)
        word_count = len(content.split())
        reading_time = max(1, round(word_count / 200))
        
        # Limpa o t√≠tulo para usar no nome do arquivo
        slug = re.sub(r'[^\w\s-]', '', title.lower()).strip()
        slug = re.sub(r'[\s_]+', '-', slug)
        filename = POSTS_DIR / f"{now.strftime('%Y-%m-%d')}-{slug[:80]}.md"

        # Escapa caracteres especiais
        escaped_title = title.replace('"', '\\"')
        escaped_description = seo_description.replace('"', '\\"')
        
        # Formata arrays YAML
        tags_yaml = '\n  - '.join([''] + tags)
        keywords_yaml = '\n  - '.join([''] + seo_keywords) if seo_keywords else ''
        
        # Frontmatter SEO-otimizado
        frontmatter = f"""---
title: "{escaped_title}"
date: {iso_timestamp}
draft: false
description: "{escaped_description}"
summary: "{escaped_description}"
tags:{tags_yaml}
keywords:{keywords_yaml}
categories:
  - {HUGO_CATEGORY}
author: "{HUGO_AUTHOR}"
readingTime: {reading_time}
wordCount: {word_count}
seo:
  title: "{escaped_title}"
  description: "{escaped_description}"
  canonical: ""
  noindex: false
---

"""

        # Adiciona CTA engajante e estrutura SEO ao conte√∫do
        content_with_cta = add_engaging_cta(content, title)
        seo_content = add_seo_structure(content_with_cta, seo_keywords)
        
        filename.write_text(frontmatter + seo_content, encoding="utf-8")
        
        print(f"‚úÖ Post SEO salvo em: {filename}")
        print(f"üìä Tags: {', '.join(tags)}")
        print(f"üéØ Keywords SEO: {', '.join(seo_keywords)}")
        print(f"üìñ Tempo de leitura: {reading_time} min")
        print(f"üìù Palavras: {word_count}")
        
        return filename
    except Exception as e:
        print(f"‚ùå Erro ao criar o arquivo do post: {e}")
        return None

def add_storytelling_elements(content: str) -> str:
    """Adiciona elementos de storytelling para melhor engajamento."""
    
    # Adiciona hook de abertura se n√£o existir
    lines = content.split('\n')
    first_paragraph = lines[0] if lines else ""
    
    # Remove hooks n√£o-jornal√≠sticos - o lead deve ser direto e informativo
    # Em jornalismo t√©cnico, a abertura deve ser factual, n√£o especulativa
    pass
    
    # Adiciona transi√ß√µes jornal√≠sticas profissionais entre se√ß√µes
    sections = content.split('##')
    if len(sections) > 2:
        transitions = [
            "\n\nPara compreender o impacto completo, √© necess√°rio analisar:\n\n",
            "\n\nOs dados revelam aspectos importantes:\n\n", 
            "\n\nA an√°lise t√©cnica mostra que:\n\n",
            "\n\nEspecialistas do setor apontam:\n\n",
            "\n\nAs implica√ß√µes pr√°ticas incluem:\n\n"
        ]
        
        for i in range(1, min(len(sections), 4)):
            if i < len(transitions):
                sections[i] = transitions[i-1] + "##" + sections[i]
        
        content = "##".join(sections)
    
    return content


def improve_journalistic_language(content: str) -> str:
    """Melhora a linguagem para padr√µes jornal√≠sticos profissionais."""
    
    # Substitui linguagem marketeira por jornal√≠stica
    replacements = [
        # Remove linguagem especulativa
        (r'Imagine que', 'Considere que'),
        (r'E se eu te dissesse', 'Os dados indicam'),
        (r'Voc√™ j√° se perguntou', 'Analistas questionam'),
        (r'incr√≠vel', 'significativo'),
        (r'fant√°stico', 'not√°vel'),
        (r'revolucion√°rio', 'inovador'),
        
        # Melhora conectores
        (r'Mas isso n√£o √© tudo', 'Al√©m disso'),
        (r'E tem mais', 'Adicionalmente'),
        (r'Aqui est√° o ponto', 'O aspecto central √©'),
        
        # Linguagem mais precisa
        (r'muitas empresas', 'diversas organiza√ß√µes'),
        (r'a maioria dos', 'grande parte dos'),
        (r'praticamente todos', 'a maior parte dos'),
        
        # Remove exageros
        (r'extremamente', 'altamente'),
        (r'incrivelmente', 'notavelmente'),
        (r'absolutamente', 'completamente'),
    ]
    
    for pattern, replacement in replacements:
        content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
    
    # Melhora estrutura de frases
    # Evita frases muito longas
    sentences = re.split(r'(?<=[.!?])\s+', content)
    improved_sentences = []
    
    for sentence in sentences:
        words = sentence.split()
        # Se a frase tem mais de 25 palavras, sugere quebra
        if len(words) > 25 and ',' in sentence:
            # Tenta quebrar na primeira v√≠rgula ap√≥s a 15¬™ palavra
            comma_positions = [i for i, word in enumerate(words) if ',' in word]
            if comma_positions and comma_positions[0] > 10:
                break_point = comma_positions[0] + 1
                first_part = ' '.join(words[:break_point]).rstrip(',') + '.'
                second_part = ' '.join(words[break_point:])
                improved_sentences.extend([first_part, second_part])
            else:
                improved_sentences.append(sentence)
        else:
            improved_sentences.append(sentence)
    
    return ' '.join(improved_sentences)


def improve_headings_structure(content: str) -> str:
    """Melhora a estrutura dos subt√≠tulos com emojis consistentes."""
    
    # Mapeia palavras-chave para emojis apropriados
    emoji_map = {
        'an√°lise': 'üîç',
        't√©cnica': '‚öôÔ∏è', 
        'seguran√ßa': 'üõ°Ô∏è',
        'performance': '‚ö°',
        'implementa√ß√£o': 'üöÄ',
        'arquitetura': 'üèóÔ∏è',
        'infraestrutura': 'üè¢',
        'desenvolvimento': 'üíª',
        'devops': 'üîÑ',
        'cloud': '‚òÅÔ∏è',
        'dados': 'üìä',
        'api': 'üîå',
        'mobile': 'üì±',
        'web': 'üåê',
        'ia': 'ü§ñ',
        'machine learning': 'üß†',
        'blockchain': '‚õìÔ∏è',
        'conclus√£o': 'üéØ',
        'pr√≥ximos passos': '‚û°Ô∏è',
        'recursos': 'üìö'
    }
    
    lines = content.split('\n')
    improved_lines = []
    
    for line in lines:
        if line.startswith('## ') and not line.startswith('### '):
            # Remove emojis existentes
            clean_line = re.sub(r'[^\w\s\-:]', '', line[3:]).strip()
            
            # Encontra emoji apropriado
            emoji = 'üìã'  # emoji padr√£o
            for keyword, emoji_char in emoji_map.items():
                if keyword.lower() in clean_line.lower():
                    emoji = emoji_char
                    break
            
            # Reconstr√≥i o t√≠tulo
            improved_line = f"## {emoji} {clean_line}"
            improved_lines.append(improved_line)
        else:
            improved_lines.append(line)
    
    return '\n'.join(improved_lines)


def add_visual_elements(content: str) -> str:
    """Adiciona elementos visuais para melhorar a experi√™ncia de leitura."""
    
    # Adiciona separadores visuais entre se√ß√µes principais
    content = re.sub(r'\n(## [^#])', r'\n---\n\n\1', content)
    
    # Destaca informa√ß√µes importantes com callouts
    important_patterns = [
        (r'(√â importante notar que|Vale destacar que|Importante:|Aten√ß√£o:)', r'> **üí° Destaque:** \1'),
        (r'(Cuidado|Aten√ß√£o|Aviso)', r'> **‚ö†Ô∏è Aten√ß√£o:** \1'),
        (r'(Dica|Pro tip|Sugest√£o)', r'> **üí° Dica:** \1'),
        (r'(Exemplo|Por exemplo)', r'> **üìù Exemplo:** \1')
    ]
    
    for pattern, replacement in important_patterns:
        content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
    
    # Adiciona √≠cones para listas quando apropriado
    content = re.sub(r'^- (Vantagem|Benef√≠cio)', r'‚úÖ \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Desvantagem|Limita√ß√£o|Problema)', r'‚ùå \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Requisito|Necess√°rio)', r'üìã \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Ferramenta|Tool)', r'üõ†Ô∏è \1', content, flags=re.MULTILINE)
    
    return content


def add_engaging_cta(content: str, title: str) -> str:
    """Adiciona call-to-actions mais engajantes ao final do conte√∫do."""
    
    # Remove CTAs gen√©ricos existentes
    content = re.sub(r'\*\*Gostou do conte√∫do\?\*\*.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    content = re.sub(r'### üí¨ Discuss√£o.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    content = re.sub(r'## Conclus√£o\n\nEste guia oferece.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    
    # CTAs espec√≠ficos baseados no tipo de conte√∫do
    if any(word in title.lower() for word in ['an√°lise', 'deep dive', 'breakdown']):
        cta = """
## üí¨ Vamos Continuar a Conversa

**Qual sua experi√™ncia com essa tecnologia?** Compartilhe nos coment√°rios:
- J√° implementou algo similar na sua empresa?
- Quais desafios enfrentou durante a ado√ß√£o?
- Que outras an√°lises t√©cnicas gostaria de ver?

**üìß Quer receber mais conte√∫do t√©cnico como este?** 
Conecte-se comigo no LinkedIn para discuss√µes sobre arquitetura, DevOps e inova√ß√£o.

**üîÑ Achou √∫til?** Compartilhe com sua equipe - conhecimento t√©cnico √© melhor quando compartilhado!
"""
    elif any(word in title.lower() for word in ['security', 'seguran√ßa', 'vulnerabilidade']):
        cta = """
## üõ°Ô∏è Sua Infraestrutura Est√° Preparada?

**Avalie sua postura de seguran√ßa:**
- Sua equipe conhece essas vulnerabilidades?
- Seus sistemas est√£o atualizados com as √∫ltimas pr√°ticas?
- Tem um plano de resposta a incidentes?

**üí° Precisa de uma segunda opini√£o?** 
Compartilhe este artigo com seu time de seguran√ßa e discutam as implica√ß√µes.

**üöÄ Pr√≥ximo passo:** Implemente pelo menos uma das recomenda√ß√µes desta semana.
"""
    else:
        cta = """
## üöÄ Pr√≥ximos Passos

**Para implementar essas ideias:**
1. Discuta com sua equipe os pontos mais relevantes
2. Identifique quick wins que podem ser implementados rapidamente  
3. Planeje um piloto para testar os conceitos

**üí≠ Sua opini√£o importa:** Que outros t√≥picos t√©cnicos gostaria de ver explorados?

**üîó Mantenha-se atualizado:** Siga para mais an√°lises t√©cnicas e insights do mercado.
"""
    
    content += cta
    return content


def add_seo_structure(content: str, keywords: List[str]) -> str:
    """Adiciona estrutura SEO ao conte√∫do do artigo."""
    
    # Adiciona √≠ndice se o artigo for longo
    lines = content.split('\n')
    headers = [line for line in lines if line.startswith('##')]
    
    if len(headers) >= 3:
        toc = "\n## √çndice\n\n"
        for header in headers:
            clean_header = header.replace('##', '').strip()
            anchor = clean_header.lower().replace(' ', '-').replace(',', '').replace(':', '')
            toc += f"- [{clean_header}](#{anchor})\n"
        
        # Insere √≠ndice ap√≥s a introdu√ß√£o
        intro_end = content.find('\n##')
        if intro_end > 0:
            content = content[:intro_end] + toc + content[intro_end:]
    
    # Adiciona FAQ section se houver palavras-chave
    if keywords:
        faq_section = f"\n\n## Perguntas Frequentes\n\n"
        
        for keyword in keywords[:3]:  # M√°ximo 3 FAQs
            faq_section += f"### O que √© {keyword}?\n\n"
            faq_section += f"{keyword.capitalize()} √© uma tecnologia/conceito importante que permite [explica√ß√£o breve baseada no contexto do artigo].\n\n"
        
        content += faq_section
    
    # CTA engajante j√° foi aplicado anteriormente
    
    return content

def commit_new_post(file_path: Path, title: str):
    """Adiciona, commita e faz push do novo post no Git."""
    print("üöÄ Fazendo commit do novo post...")
    try:
        # Adiciona o arquivo ao stage
        subprocess.run(["git", "add", str(file_path)], check=True)
        
        # Cria a mensagem de commit
        commit_message = f'feat: Add post "{title[:100]}"'
        
        # Faz o commit
        subprocess.run(["git", "commit", "-m", commit_message], check=True)
        print("‚úÖ Commit local realizado com sucesso!")

        # Faz o push para o reposit√≥rio remoto
        print("üì° Enviando para o reposit√≥rio remoto (git push)...")
        subprocess.run(["git", "push"], check=True)
        print("‚úÖ Push realizado com sucesso!")
        
        print(f"\nResumo:\n  {commit_message}")

    except subprocess.CalledProcessError as e:
        print(f"‚ùå ERRO ao executar comando git: {e}")
        print("Verifique se o git est√° instalado, configurado (user.name, user.email) e se suas credenciais para o GitHub est√£o corretas (ex: via Personal Access Token).")
    except FileNotFoundError:
        print("‚ùå ERRO: O comando 'git' n√£o foi encontrado. O arquivo foi criado mas n√£o commitado.")

def validate_journalistic_quality(title: str, content: str) -> bool:
    """Valida se o conte√∫do atende aos padr√µes de qualidade jornal√≠stica."""
    
    issues = []
    
    # Verifica se tem lead jornal√≠stico (primeiros 2 par√°grafos)
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip() and not p.startswith('#')]
    if len(paragraphs) >= 2:
        first_two = ' '.join(paragraphs[:2]).lower()
        # Verifica se responde aos 5 W's b√°sicos (mais flex√≠vel)
        has_what = any(word in first_two for word in ['anunciou', 'lan√ßou', 'revelou', 'apresentou', 'desenvolveu', 'criou', 'introduziu', 'implementou', 'oferece', 'disponibiliza'])
        has_who = any(word in first_two for word in ['empresa', 'companhia', 'organiza√ß√£o', 'equipe', 'google', 'microsoft', 'amazon', 'meta', 'nvidia', 'apple', 'tecnologia', 'plataforma'])
        
        # Relaxa crit√©rio - s√≥ precisa de O QUE e QUEM
        if not (has_what or has_who):
            issues.append("Lead precisa ser mais informativo sobre o que aconteceu e quem est√° envolvido")
    
    # Verifica densidade de dados espec√≠ficos
    data_indicators = len(re.findall(r'\d+[%\w]*', content))  # n√∫meros, percentuais
    word_count = len(content.split())
    data_density = data_indicators / word_count if word_count > 0 else 0
    
    if data_density < 0.01:  # Menos de 1% de dados espec√≠ficos
        issues.append("Baixa densidade de dados espec√≠ficos (n√∫meros, percentuais)")
    
    # Verifica se tem par√°grafos muito longos (mais flex√≠vel)
    long_paragraphs = [p for p in paragraphs if len(p.split()) > 150]
    if len(long_paragraphs) > 3:
        issues.append("Par√°grafos excessivamente longos (>150 palavras)")
    
    # Verifica redund√¢ncias comuns
    redundant_phrases = [
        '√© importante notar que', 'vale destacar que', 'cabe ressaltar que',
        'como mencionado anteriormente', 'conforme j√° dito'
    ]
    redundancy_count = sum(content.lower().count(phrase) for phrase in redundant_phrases)
    if redundancy_count > 3:
        issues.append("Muitas frases redundantes ou clich√™s")
    
    # Verifica se tem conectores l√≥gicos (mais abrangente)
    logical_connectors = ['portanto', 'consequentemente', 'assim', 'dessa forma', 'logo', 'al√©m disso', 'por outro lado', 'entretanto', 'contudo', 'no entanto', 'adicionalmente', 'por sua vez', 'desta forma']
    connector_count = sum(1 for connector in logical_connectors if connector in content.lower())
    if connector_count < 2:
        issues.append("Poucos conectores l√≥gicos para melhor fluxo textual")
    
    if issues:
        print(f"‚ùå Problemas de qualidade jornal√≠stica encontrados:")
        for issue in issues:
            print(f"   ‚Ä¢ {issue}")
        return False
    
    print("‚úÖ Conte√∫do aprovado na valida√ß√£o de qualidade jornal√≠stica")
    return True


def validate_ethical_guidelines(title: str, content: str) -> bool:
    """Valida se o conte√∫do segue as diretrizes √©ticas."""
    
    # Palavras proibidas (sensacionalistas)
    forbidden_words = [
        "breaking", "exclusivo", "confirmado", "vazou", "oficial",
        "acabou de", "nesta manh√£", "hoje cedo", "h√° poucas horas"
    ]
    
    title_lower = title.lower()
    content_lower = content.lower()
    
    # Verifica palavras proibidas no t√≠tulo
    for word in forbidden_words:
        if word in title_lower:
            print(f"‚ùå T√≠tulo cont√©m palavra sensacionalista: '{word}'")
            return False
    
    # Verifica se √© educativo ou h√≠brido v√°lido
    educational_indicators = [
        "como", "guia", "an√°lise", "comparativo", "entendendo",
        "explicado", "fundamentos", "conceitos", "pr√°ticas"
    ]
    
    hybrid_indicators = [
        "an√°lise:", "contexto:", "o que", "li√ß√µes", "por tr√°s",
        "significam", "impacto de", "implica√ß√µes"
    ]
    
    has_educational_indicator = any(word in title_lower for word in educational_indicators)
    has_hybrid_indicator = any(word in title_lower for word in hybrid_indicators)
    
    if not (has_educational_indicator or has_hybrid_indicator):
        print("‚ùå T√≠tulo n√£o parece educativo nem h√≠brido v√°lido")
        return False
    
    # Verifica timestamps espec√≠ficos no conte√∫do
    temporal_flags = [
        "hoje", "ontem", "esta manh√£", "nesta tarde", "h√° poucas horas",
        "acabou de ser anunciado", "confirmou hoje", "nesta semana"
    ]
    
    for flag in temporal_flags:
        if flag in content_lower:
            print(f"‚ùå Conte√∫do cont√©m timestamp espec√≠fico: '{flag}'")
            return False
    
    return True

def validate_seo_quality(title: str, content: str) -> bool:
    """Valida qualidade SEO do post gerado."""
    
    # Valida√ß√£o de t√≠tulo SEO
    if len(title) < SEO_TITLE_MIN_LENGTH:
        print(f"‚ùå T√≠tulo muito curto para SEO ({len(title)} < {SEO_TITLE_MIN_LENGTH})")
        return False
    
    if len(title) > SEO_TITLE_MAX_LENGTH:
        print(f"‚ùå T√≠tulo muito longo para SEO ({len(title)} > {SEO_TITLE_MAX_LENGTH})")
        return False
    
    # Valida√ß√£o de conte√∫do SEO
    word_count = len(content.split())
    if word_count < SEO_ARTICLE_MIN_WORDS:
        print(f"‚ùå Artigo muito curto para SEO ({word_count} < {SEO_ARTICLE_MIN_WORDS} palavras)")
        return False
    
    if word_count > SEO_ARTICLE_MAX_WORDS:
        print(f"‚ö†Ô∏è Artigo muito longo ({word_count} > {SEO_ARTICLE_MAX_WORDS} palavras), mas continuando...")
    
    # Valida√ß√£o de estrutura SEO
    headers = content.count('##')
    if headers < 3:
        print(f"‚ö†Ô∏è Poucos subt√≠tulos para SEO ({headers} < 3), mas continuando...")
    
    # Verifica presen√ßa de palavras-chave SEO
    has_seo_keywords = False
    title_lower = title.lower()
    content_lower = content.lower()
    
    for keywords in SEO_KEYWORDS.values():
        for keyword in keywords:
            if keyword in title_lower or keyword in content_lower:
                has_seo_keywords = True
                break
        if has_seo_keywords:
            break
    
    if not has_seo_keywords:
        print("‚ö†Ô∏è Nenhuma palavra-chave SEO identificada, mas continuando...")
    
    print(f"‚úÖ Post aprovado na valida√ß√£o SEO ({word_count} palavras, {headers} subt√≠tulos)")
    return True

def validate_content_consistency(title: str, content: str, tags: List[str], keywords: List[str]) -> bool:
    """Valida a consist√™ncia entre t√≠tulo, conte√∫do, tags e keywords."""
    print("üîç Validando consist√™ncia do conte√∫do...")
    
    title_lower = title.lower()
    content_lower = content.lower()
    combined_text = f"{title_lower} {content_lower}"
    
    # Valida√ß√µes de consist√™ncia cr√≠ticas
    inconsistencies = []
    
    # 1. Verifica se tags fazem sentido com o conte√∫do
    for tag in tags:
        tag_clean = tag.replace('-', ' ')
        
        # Tags de empresas devem ter contexto
        company_tags = {
            'aws': ['amazon', 'graviton', 'ec2', 's3', 'lambda'],
            'google': ['android', 'pixel', 'chrome', 'search', 'gemini'],
            'apple': ['iphone', 'ipad', 'mac', 'ios', 'safari'],
            'microsoft': ['windows', 'azure', 'office', 'teams'],
            'meta': ['facebook', 'instagram', 'whatsapp', 'oculus'],
            'openai': ['chatgpt', 'gpt', 'dall-e'],
            'anthropic': ['claude'],
            'nvidia': ['gpu', 'cuda', 'geforce', 'rtx'],
            'tesla': ['model', 'autopilot', 'cybertruck']
        }
        
        if tag in company_tags:
            context_words = company_tags[tag]
            has_context = any(word in combined_text for word in context_words)
            
            if not has_context:
                inconsistencies.append(f"Tag '{tag}' sem contexto v√°lido no conte√∫do")
    
    # 2. Verifica conflitos entre tags
    conflicting_tags = [
        (['aws', 'amazon'], ['google', 'microsoft', 'azure']),
        (['google'], ['apple', 'ios', 'iphone']),
        (['apple', 'ios'], ['android', 'google']),
        (['openai'], ['anthropic', 'claude']),
        (['aws'], ['azure', 'google-cloud'])
    ]
    
    for primary_tags, conflicting in conflicting_tags:
        has_primary = any(tag in tags for tag in primary_tags)
        has_conflict = any(tag in tags for tag in conflicting)
        
        if has_primary and has_conflict:
            inconsistencies.append(f"Tags conflitantes: {primary_tags} vs {conflicting}")
    
    # 3. Verifica se keywords fazem sentido
    for keyword in keywords:
        if keyword not in combined_text:
            inconsistencies.append(f"Keyword '{keyword}' n√£o encontrada no conte√∫do")
    
    # 4. Verifica se o t√≠tulo √© consistente com o conte√∫do
    title_companies = []
    content_companies = []
    
    companies = ['aws', 'amazon', 'google', 'apple', 'microsoft', 'meta', 'openai', 'anthropic', 'nvidia', 'tesla']
    
    for company in companies:
        if company in title_lower:
            title_companies.append(company)
        if company in content_lower:
            content_companies.append(company)
    
    # Se o t√≠tulo menciona uma empresa, o conte√∫do deve focar nela
    if title_companies:
        main_company = title_companies[0]
        company_mentions = combined_text.count(main_company)
        
        # Verifica se outras empresas t√™m mais men√ß√µes
        for other_company in companies:
            if other_company != main_company:
                other_mentions = combined_text.count(other_company)
                if other_mentions > company_mentions:
                    inconsistencies.append(f"T√≠tulo foca em '{main_company}' mas conte√∫do foca mais em '{other_company}'")
    
    # Reporta inconsist√™ncias
    if inconsistencies:
        print("‚ùå Inconsist√™ncias encontradas:")
        for inconsistency in inconsistencies:
            print(f"   ‚Ä¢ {inconsistency}")
        return False
    
    print("‚úÖ Conte√∫do consistente")
    return True

def validate_executive_quality(title: str, content: str) -> bool:
    """Valida se o conte√∫do atende aos padr√µes de qualidade para executivos C-level."""
    print("üëî Validando qualidade executiva...")
    
    content_lower = content.lower()
    
    # Verifica densidade informacional
    word_count = len(content.split())
    if word_count < SEO_ARTICLE_MIN_WORDS:
        print(f"‚ùå Conte√∫do muito curto: {word_count} palavras (m√≠nimo: {SEO_ARTICLE_MIN_WORDS})")
        return False
    
    # Verifica presen√ßa de dados concretos
    has_numbers = bool(re.search(r'\d+%|\d+\.\d+%|\$\d+|\d+ milh√µes?|\d+ bilh√µes?', content))
    has_metrics = any(word in content_lower for word in [
        'roi', 'receita', 'custo', 'investimento', 'economia', 'efici√™ncia',
        'produtividade', 'market share', 'crescimento', 'redu√ß√£o'
    ])
    
    if not (has_numbers or has_metrics):
        print("‚ùå Falta dados concretos e m√©tricas executivas")
        return False
    
    # Verifica an√°lise estrat√©gica
    strategic_elements = [
        'impacto', 'estrat√©gia', 'competitiv', 'vantagem', 'oportunidade',
        'risco', 'implementa√ß√£o', 'ado√ß√£o', 'timeline', 'roadmap'
    ]
    
    strategic_count = sum(1 for element in strategic_elements if element in content_lower)
    if strategic_count < 3:
        print(f"‚ùå Falta elementos estrat√©gicos: {strategic_count}/3 m√≠nimo")
        return False
    
    # Verifica estrutura executiva
    has_sections = content.count('##') >= 4  # M√≠nimo 4 se√ß√µes
    
    if not has_sections:
        print("‚ùå Estrutura inadequada: menos de 4 se√ß√µes")
        return False
    
    # Verifica linguagem executiva (evita jarg√µes excessivos)
    jargon_count = sum(1 for word in [
        'disruptivo', 'revolucion√°rio', 'game-changer', 'breakthrough',
        'cutting-edge', 'state-of-the-art', 'next-generation'
    ] if word in content_lower)
    
    if jargon_count > 2:
        print(f"‚ùå Excesso de jarg√µes promocionais: {jargon_count}")
        return False
    
    # Verifica presen√ßa de an√°lise comparativa
    has_comparison = any(word in content_lower for word in [
        'comparado', 'versus', 'alternativa', 'concorrente', 'diferen√ßa',
        'vantagem sobre', 'desvantagem', 'melhor que', 'superior'
    ])
    
    if not has_comparison:
        print("‚ùå Falta an√°lise comparativa")
        return False
    
    print("‚úÖ Conte√∫do aprovado para padr√µes executivos")
    return True

def validate_post_quality(title: str, content: str) -> bool:
    """Valida a qualidade b√°sica, √©tica, SEO, executiva e consist√™ncia do post gerado."""
    
    # Gera tags e keywords para valida√ß√£o de consist√™ncia
    tags = generate_tags(title, content)
    keywords = extract_seo_keywords(title, content)
    
    # Valida√ß√£o de consist√™ncia (CR√çTICA - deve ser primeira)
    if not validate_content_consistency(title, content, tags, keywords):
        print("‚ùå Post tem inconsist√™ncias cr√≠ticas, regenerando...")
        return False
    
    # Valida√ß√£o de qualidade jornal√≠stica
    if not validate_journalistic_quality(title, content):
        print("‚ùå Post n√£o atende aos padr√µes de qualidade jornal√≠stica, regenerando...")
        return False
    
    # Valida√ß√£o √©tica
    if not validate_ethical_guidelines(title, content):
        print("‚ùå Post n√£o atende √†s diretrizes √©ticas, regenerando...")
        return False
    
    # Valida√ß√£o SEO
    if not validate_seo_quality(title, content):
        print("‚ùå Post n√£o atende aos crit√©rios SEO, regenerando...")
        return False
    
    # Valida√ß√£o executiva
    if not validate_executive_quality(title, content):
        print("‚ùå Post n√£o atende aos padr√µes executivos, regenerando...")
        return False
    
    print("‚úÖ Post aprovado em todas as valida√ß√µes (consist√™ncia + jornal√≠stica + √©tica + SEO + executiva)")
    return True

def load_ethical_guidelines() -> bool:
    """Carrega e valida se as diretrizes √©ticas est√£o dispon√≠veis."""
    guidelines_file = Path("ethical_guidelines.md")
    if guidelines_file.exists():
        print("‚úÖ Diretrizes √©ticas carregadas")
        return True
    else:
        print("‚ö†Ô∏è Arquivo de diretrizes √©ticas n√£o encontrado")
        return False

def show_progress(step: int, total: int, description: str):
    """Mostra indicador de progresso."""
    if PROGRESS_INDICATORS:
        percentage = (step / total) * 100
        bar_length = 20
        filled_length = int(bar_length * step // total)
        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
        print(f"üìä [{bar}] {percentage:.0f}% - {description}")

def main():
    """Fun√ß√£o principal que orquestra todo o processo de an√°lise t√©cnica."""
    total_steps = 6
    current_step = 0
    
    print("üì∞ Iniciando gera√ß√£o de an√°lise t√©cnica de not√≠cias...")
    print(f"üìÖ Data/hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print("üéØ Foco: 80% an√°lise de not√≠cias, 15% t√©cnico SEO, 5% t√©cnico geral")
    print("‚ö° Otimizado para evitar timeouts")
    print()
    
    current_step += 1
    show_progress(current_step, total_steps, "Configurando API...")
    
    if not setup_api():
        sys.exit(1)

    current_step += 1
    show_progress(current_step, total_steps, "Gerando t√≥pico...")
    
    # Decide o tipo de gera√ß√£o focado em an√°lise t√©cnica de not√≠cias
    rand = random.random()
    
    print(f"üé≤ Sorteio: {rand:.2f}")
    
    if rand < 0.8:
        print("üì∞ Selecionado: An√°lise t√©cnica de not√≠cia")
        topic = generate_news_technical_analysis()
    elif rand < 0.95:
        print("üîß Selecionado: Conte√∫do t√©cnico SEO")
        topic = generate_technical_seo_topic()
    else:
        print("üíª Selecionado: Conte√∫do t√©cnico geral")
        topic = generate_it_professional_topic()
    
    if not topic:
        print("‚ùå Falha ao gerar t√≥pico √∫nico.")
        sys.exit(1)
    
    current_step += 1
    show_progress(current_step, total_steps, f"T√≥pico: {topic}")

    current_step += 1
    show_progress(current_step, total_steps, "Gerando artigo...")
    
    # Gera artigo com timeout otimizado
    max_article_attempts = MAX_ARTICLE_ATTEMPTS
    article = ""
    
    for attempt in range(max_article_attempts):
        print(f"üìù Tentativa {attempt + 1}/{max_article_attempts} - Gerando artigo...")
        try:
            article = write_article(topic)
            
            if article and validate_post_quality(topic, article):
                print(f"‚úÖ Artigo gerado com sucesso ({len(article)} chars)")
                break
            elif attempt < max_article_attempts - 1:
                print("üîÑ Regenerando artigo...")
        except Exception as e:
            if "timeout" in str(e).lower() or "504" in str(e):
                print(f"‚è∞ Timeout na gera√ß√£o do artigo (tentativa {attempt + 1})")
                if attempt < max_article_attempts - 1:
                    print("üîÑ Tentando com prompt mais simples...")
            else:
                print(f"‚ùå Erro na gera√ß√£o: {str(e)[:100]}...")
    
    if not article:
        print("‚ùå Falha ao gerar artigo de qualidade.")
        sys.exit(1)
    
    current_step += 1
    show_progress(current_step, total_steps, f"Artigo: {len(article)} caracteres")

    current_step += 1
    show_progress(current_step, total_steps, "Criando post Hugo...")
    
    # Cria o post com metadados aprimorados
    post_path = create_hugo_post(topic, article)
    if not post_path:
        sys.exit(1)

    current_step += 1
    show_progress(current_step, total_steps, "Fazendo commit...")
    
    # Commit e push
    commit_new_post(post_path, topic)

    show_progress(total_steps, total_steps, "Processo conclu√≠do!")
    
    print(f"\n‚ú® An√°lise t√©cnica '{topic}' publicada com sucesso! ‚ú®")
    print(f"ÔøΩ TArquivo: {post_path.name}")
    print(f"ÔøΩ  Tamanho: {len(article)} caracteres")
    print(f"üì∞ Tipo: An√°lise t√©cnica de not√≠cia")
    print(f"üïí Processo conclu√≠do em: {datetime.now().strftime('%H:%M:%S')}")
    print(f"‚ö° Sem timeouts detectados!")

if __name__ == "__main__":
    # Verifica diretrizes √©ticas antes de executar
    guidelines_file = Path("ethical_guidelines.md")
    if guidelines_file.exists():
        print("‚úÖ Diretrizes √©ticas carregadas")
    else:
        print("‚ö†Ô∏è Arquivo de diretrizes √©ticas n√£o encontrado")
    
    main()