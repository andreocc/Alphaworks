import os
import sys
import re
import random
import json
import hashlib
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime, timezone, timedelta
import subprocess
from dotenv import load_dotenv
import google.generativeai as genai
from config import *
from trends import *
from news_api_improved import get_current_news, get_news_context
from content_formatting import format_content
from content_cleaner import clean_content_completely, create_simple_structure

# --- Configura√ß√µes ---
POSTS_DIR = Path("content/posts")
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)
TOPICS_CACHE = CACHE_DIR / "topics_cache.json"

def setup_api():
    """Carrega vari√°veis de ambiente e configura a API do Gemini."""
    load_dotenv()
    # Tenta m√∫ltiplas vari√°veis de ambiente para compatibilidade
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_GENERATIVE_AI_API_KEY")
    if not api_key:
        print("‚ùå ERRO: Nenhuma chave de API encontrada.")
        print("Configure uma das seguintes vari√°veis no arquivo .env:")
        print("  - GEMINI_API_KEY=sua_chave_aqui")
        print("  - GOOGLE_API_KEY=sua_chave_aqui")
        print("  - GOOGLE_GENERATIVE_AI_API_KEY=sua_chave_aqui")
        return False
    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        print(f"‚ùå ERRO ao configurar a API do Gemini: {e}")
        return False

def call_gemini_api(prompt: str, safety_settings=None, max_retries=MAX_API_RETRIES, timeout=None) -> str:
    """
    Chama a API do Gemini com fallback autom√°tico para modelos mais simples.
    Retorna a resposta em texto ou lan√ßa uma exce√ß√£o em caso de erro.
    """
    import time
    
    # Lista de modelos em ordem de prefer√™ncia (melhor para pior)
    model_fallback = [
        {
            'name': 'models/gemini-1.5-flash-latest',
            'description': 'Modelo principal (mais completo)',
            'max_tokens': 1500,
            'temperature': 0.7
        },
        {
            'name': 'models/gemini-1.5-flash',
            'description': 'Modelo est√°vel (fallback 1)',
            'max_tokens': 1200,
            'temperature': 0.6
        },
        {
            'name': 'models/gemini-1.5-flash-8b',
            'description': 'Modelo b√°sico (fallback 2)',
            'max_tokens': 1000,
            'temperature': 0.5
        }
    ]
    
    if timeout is None:
        timeout = API_TIMEOUT_SECONDS
    
    # Tenta cada modelo na ordem de fallback
    for model_idx, model_config in enumerate(model_fallback):
        model = genai.GenerativeModel(model_config['name'])
        
        if model_idx > 0:
            print(f"üîÑ Tentando fallback: {model_config['description']}")
        
        for attempt in range(max_retries):
            try:
                if model_idx == 0:
                    print(f"üîÑ API call {attempt + 1}/{max_retries}")
                else:
                    print(f"üîÑ Fallback call {attempt + 1}/{max_retries}")
                
                # Configura timeout baseado no tamanho do prompt
                prompt_size = len(prompt)
                if prompt_size > 5000:
                    current_timeout = timeout * 2
                    print(f"üìè Prompt longo ({prompt_size} chars) - Timeout: {current_timeout}s")
                else:
                    current_timeout = timeout
                    print(f"üìè Prompt: {prompt_size} chars - Timeout: {current_timeout}s")
                
                start_time = time.time()
                
                # Configura√ß√£o otimizada baseada no modelo
                generation_config = genai.types.GenerationConfig(
                    max_output_tokens=model_config['max_tokens'],
                    temperature=model_config['temperature'],
                    top_p=0.9,
                    top_k=40
                )
                
                response = model.generate_content(
                    prompt, 
                    safety_settings=safety_settings,
                    generation_config=generation_config
                )
                
                elapsed_time = time.time() - start_time
                print(f"‚úÖ API respondeu em {elapsed_time:.1f}s")
                
                if response.text:
                    if model_idx > 0:
                        print(f"‚úÖ Sucesso com fallback: {model_config['description']}")
                    return response.text
                else:
                    print(f"‚ö†Ô∏è Tentativa {attempt + 1}: Resposta vazia")
                
            except Exception as e:
                elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
                error_str = str(e).lower()
                
                # Detecta erro de quota - for√ßa fallback para pr√≥ximo modelo
                if "quota" in error_str or "429" in error_str or "exceeded" in error_str:
                    print(f"ÔøΩ Quotia excedida no modelo {model_config['description']}")
                    if model_idx < len(model_fallback) - 1:
                        print(f"üîÑ Tentando pr√≥ximo modelo...")
                        break  # Sai do loop de tentativas e vai para pr√≥ximo modelo
                    else:
                        print(f"‚ùå Todos os modelos esgotaram quota")
                        raise e
                
                # Detecta timeout
                elif "timeout" in error_str or "504" in error_str or elapsed_time > current_timeout:
                    print(f"‚è∞ Timeout detectado ({elapsed_time:.1f}s)")
                    if attempt < max_retries - 1:
                        print("üîÑ Reduzindo prompt para pr√≥xima tentativa...")
                        # Reduz prompt se muito longo
                        if len(prompt) > 3000:
                            prompt = prompt[:2500] + "\n\nIMPORTANTE: Responda de forma concisa e direta."
                
                # Outros erros
                else:
                    print(f"‚ùå Erro: {str(e)[:100]}...")
                
                # Se √© a √∫ltima tentativa deste modelo, tenta pr√≥ximo modelo
                if attempt == max_retries - 1:
                    if model_idx < len(model_fallback) - 1:
                        print(f"üîÑ Modelo {model_config['description']} falhou, tentando pr√≥ximo...")
                        break  # Vai para pr√≥ximo modelo
                    else:
                        raise e
                
                # Espera progressiva apenas se n√£o for erro de quota
                if "quota" not in error_str and "429" not in error_str:
                    wait_time = (attempt + 1) * 2
                    print(f"‚è≥ Aguardando {wait_time}s...")
                    time.sleep(wait_time)
    
    raise Exception("Falha em todas as tentativas de chamada da API")

def load_topics_cache() -> Dict:
    """Carrega o cache de t√≥picos j√° utilizados."""
    if TOPICS_CACHE.exists():
        try:
            with open(TOPICS_CACHE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {"used_topics": [], "last_update": ""}
    return {"used_topics": [], "last_update": ""}

def save_topics_cache(cache_data: Dict):
    """Salva o cache de t√≥picos."""
    with open(TOPICS_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache_data, f, ensure_ascii=False, indent=2)

def is_topic_duplicate(topic: str, used_topics: List[str]) -> bool:
    """Verifica se o t√≥pico √© muito similar aos j√° utilizados."""
    topic_hash = hashlib.md5(topic.lower().encode()).hexdigest()
    for used_topic in used_topics:
        used_hash = hashlib.md5(used_topic.lower().encode()).hexdigest()
        # Verifica similaridade b√°sica
        if topic_hash == used_hash or topic.lower() in used_topic.lower() or used_topic.lower() in topic.lower():
            return True
    return False

def get_current_tech_context() -> str:
    """Gera contexto temporal espec√≠fico para not√≠cias atuais."""
    today = datetime.now()
    current_date = today.strftime("%d de %B de %Y")
    current_month = today.strftime("%B de %Y")
    week_day = today.strftime("%A")
    
    # Contextos espec√≠ficos baseados na data
    contexts = [
        f"Esta semana ({current_date})",
        f"Neste m√™s de {current_month}",
        f"Nos √∫ltimos 7 dias",
        f"Esta {week_day}",
        "Recentemente anunciado",
        "Lan√ßado hoje",
        "Trending agora"
    ]
    
    return random.choice(contexts)

def get_market_trends() -> Dict[str, List[str]]:
    """Retorna tend√™ncias atuais do mercado tech por categoria."""
    return {
        "ai_ml": [
            "GPT-4 Turbo", "Claude 3.5", "Gemini Ultra", "Llama 3", "Midjourney v6",
            "Sora (OpenAI)", "Runway ML", "Anthropic Constitutional AI", "Meta AI Studio",
            "Google AI Studio", "Microsoft Copilot Pro", "GitHub Copilot X"
        ],
        "mobile": [
            "iPhone 16 Pro", "Samsung Galaxy S25", "Google Pixel 9", "OnePlus 13",
            "iOS 18", "Android 15", "One UI 7", "MIUI 15", "ColorOS 15",
            "5G SA", "eSIM", "satellite connectivity", "foldable displays"
        ],
        "software": [
            "Windows 11 24H2", "macOS Sequoia", "Ubuntu 24.04", "Chrome 130",
            "Firefox 131", "VS Code updates", "Docker Desktop", "Kubernetes 1.31",
            "React 19", "Next.js 15", "Vue 3.5", "Angular 18"
        ],
        "security": [
            "zero-day exploits", "ransomware-as-a-service", "supply chain attacks",
            "quantum-resistant encryption", "passwordless authentication", "FIDO2",
            "WebAuthn", "biometric security", "AI-powered threats", "deepfake detection"
        ],
        "cloud": [
            "AWS re:Invent", "Google Cloud Next", "Microsoft Build", "serverless computing",
            "edge computing", "multi-cloud", "hybrid cloud", "container orchestration",
            "microservices", "API-first architecture", "cloud-native security"
        ],
        "hardware": [
            "Apple M4", "Intel Core Ultra", "AMD Ryzen 8000", "NVIDIA RTX 50 series",
            "Qualcomm Snapdragon X", "ARM Cortex-X5", "DDR5 memory", "PCIe 5.0",
            "USB4 v2", "Thunderbolt 5", "Wi-Fi 7", "Bluetooth 6.0"
        ]
    }

def generate_news_technical_analysis() -> str:
    """Gera an√°lise t√©cnica baseada em not√≠cia real do Google News style."""
    print("üì∞ Gerando an√°lise t√©cnica de not√≠cia real...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    try:
        # Obt√©m not√≠cias atuais
        news_articles = get_current_news("technology")
        
        if news_articles:
            selected_news = random.choice(news_articles)
            news_title = selected_news["title"]
            news_source = selected_news["source"]
            
            # Limpa o t√≠tulo da not√≠cia para usar nos templates
            clean_title = news_title.replace('"', '').replace("'", "")
            
            # Templates de an√°lise t√©cnica baseados na not√≠cia
            analysis_templates = [
                f"An√°lise t√©cnica: {clean_title} - impactos na infraestrutura",
                f"Deep dive: por tr√°s de '{clean_title}' - arquitetura e implementa√ß√£o",
                f"Tech breakdown: {clean_title} - o que profissionais precisam saber",
                f"Security review: {clean_title} - vulnerabilidades e mitiga√ß√µes",
                f"Performance analysis: {clean_title} - benchmarks e otimiza√ß√µes", 
                f"DevOps perspective: {clean_title} - deployment e monitoring",
                f"Enterprise impact: {clean_title} - ROI e ado√ß√£o corporativa",
                f"Infrastructure implications: {clean_title} - scaling e recursos",
                f"Implementation guide: li√ß√µes t√©cnicas de '{clean_title}'",
                f"Case study t√©cnico: an√°lise completa de {clean_title}"
            ]
            
            # Define tamanho m√≠nimo flex√≠vel
            min_length = max(30, SEO_TITLE_MIN_LENGTH - 20)  # Mais flex√≠vel
            
            # Testa t√≠tulos at√© encontrar um v√°lido
            for template in analysis_templates:
                original_template = template
                
                # Verifica tamanho mas n√£o trunca automaticamente
                if len(template) > SEO_TITLE_MAX_LENGTH:
                    # Pula este template se muito longo
                    continue
                
                if len(template) >= min_length and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ An√°lise t√©cnica baseada em not√≠cia: {template}")
                    print(f"üì∞ Not√≠cia fonte: {news_source} - {clean_title}")
                    
                    # Atualiza cache com informa√ß√µes da not√≠cia
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": news_source,
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", ""),
                        "analysis_type": "technical"
                    }
                    save_topics_cache(cache_data)
                    
                    return template
            
            # Se nenhum template funcionou, tenta vers√µes mais curtas
            # Se chegou aqui, usa t√≠tulo mais direto sem truncar
            short_templates = [
                f"An√°lise t√©cnica: {clean_title}",
                f"Deep dive: {clean_title}",
                f"Tech breakdown: {clean_title}",
                f"An√°lise: {clean_title}"
            ]
            
            for template in short_templates:
                if len(template) >= min_length and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ An√°lise t√©cnica (vers√£o curta): {template}")
                    print(f"üì∞ Not√≠cia fonte: {news_source} - {clean_title}")
                    
                    # Atualiza cache
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": news_source,
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", ""),
                        "analysis_type": "technical"
                    }
                    save_topics_cache(cache_data)
                    
                    return template
        
        # Se chegou aqui, n√£o conseguiu gerar da not√≠cia
        print("‚ö†Ô∏è N√£o conseguiu gerar an√°lise da not√≠cia, tentando abordagem alternativa...")
        
        # Tenta uma abordagem mais simples
        if news_articles:
            simple_news = random.choice(news_articles)
            simple_title = f"An√°lise t√©cnica: {simple_news['title']}"
            if not is_topic_duplicate(simple_title, used_topics):
                print(f"‚úÖ An√°lise simples: {simple_title}")
                return simple_title
        
        # √öltimo fallback
        print("‚ö†Ô∏è Fallback para t√≥pico t√©cnico...")
        return generate_technical_seo_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar an√°lise t√©cnica: {e}")
        print("‚ö†Ô∏è Fallback para t√≥pico t√©cnico SEO...")
        return generate_technical_seo_topic()

def generate_it_professional_topic() -> str:
    """Gera t√≥pico t√©cnico focado em profissionais de TI."""
    print("üíª Gerando t√≥pico t√©cnico para profissionais de TI...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Obt√©m not√≠cias atuais
    try:
        news_articles = get_current_news("technology")
        
        if news_articles:
            selected_news = random.choice(news_articles)
            news_title = selected_news["title"]
            news_keywords = selected_news.get("keywords", [])
            
            # Templates t√©cnicos espec√≠ficos para IT
            it_templates = [
                f"Technical analysis: {news_title.lower()} - infrastructure implications",
                f"DevOps impact: how {news_title.lower()} affects deployment pipelines", 
                f"Security assessment: {news_title.lower()} vulnerabilities and mitigations",
                f"Performance review: {news_title.lower()} benchmarks and optimization",
                f"Architecture deep dive: {news_title.lower()} system design patterns",
                f"Enterprise perspective: {news_title.lower()} adoption challenges",
                f"Implementation guide: deploying solutions from {news_title.lower()}",
                f"Monitoring and observability: tracking {news_title.lower()} in production"
            ]
            
            # Se h√° palavras-chave t√©cnicas, cria t√≠tulos mais espec√≠ficos
            if news_keywords:
                tech_keyword = news_keywords[0]
                specific_templates = [
                    f"Deep dive: {tech_keyword} architecture revealed by {news_title.lower()}",
                    f"Performance analysis: {tech_keyword} scalability insights from {news_title.lower()}",
                    f"Security review: {tech_keyword} vulnerabilities exposed in {news_title.lower()}",
                    f"DevOps guide: {tech_keyword} deployment lessons from {news_title.lower()}",
                    f"Infrastructure impact: {tech_keyword} requirements after {news_title.lower()}"
                ]
                it_templates.extend(specific_templates)
            
            # Testa t√≠tulos t√©cnicos
            for template in it_templates:
                if len(template) <= SEO_TITLE_MAX_LENGTH and not is_topic_duplicate(template, used_topics):
                    print(f"‚úÖ T√≠tulo t√©cnico: {template}")
                    print(f"üì∞ Base: {selected_news['source']} - {news_title}")
                    
                    # Atualiza cache
                    used_topics.append(template)
                    cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                    cache_data["last_update"] = datetime.now().isoformat()
                    cache_data["news_source"] = {
                        "title": news_title,
                        "source": selected_news["source"],
                        "url": selected_news.get("url", ""),
                        "published_at": selected_news.get("published_at", "")
                    }
                    save_topics_cache(cache_data)
                    
                    return template
        
        # Fallback: gera t√≠tulo t√©cnico sem not√≠cia espec√≠fica
        return generate_technical_seo_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar t√≥pico t√©cnico: {e}")
        return generate_technical_seo_topic()

def generate_technical_seo_topic() -> str:
    """Gera t√≥pico t√©cnico SEO para profissionais de TI."""
    print("üîß Gerando t√≥pico t√©cnico SEO...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Seleciona elementos t√©cnicos
    tech_template = random.choice(IT_PROFESSIONAL_TITLE_TEMPLATES)
    tech_keyword = random.choice(IT_TECHNICAL_KEYWORDS)
    tech_area = random.choice(TRENDING_PRODUCTS + EMERGING_TECH)
    sector = random.choice(APPLICATION_SECTORS)
    
    # Gera varia√ß√µes t√©cnicas
    technical_variations = [
        tech_template.format(tecnologia=tech_keyword, alternativa=random.choice(IT_TECHNICAL_KEYWORDS), setor=sector),
        f"Performance benchmarks: {tech_keyword} vs {random.choice(IT_TECHNICAL_KEYWORDS)}",
        f"Production deployment: {tech_keyword} best practices and pitfalls",
        f"Scalability analysis: {tech_keyword} under high load conditions",
        f"Security hardening: {tech_keyword} configuration and monitoring",
        f"DevOps integration: {tech_keyword} in CI/CD pipelines",
        f"Infrastructure as Code: {tech_keyword} automation strategies",
        f"Monitoring and alerting: {tech_keyword} observability patterns"
    ]
    
    # Seleciona t√≠tulo v√°lido
    for title in technical_variations:
        if SEO_TITLE_MIN_LENGTH <= len(title) <= SEO_TITLE_MAX_LENGTH and not is_topic_duplicate(title, used_topics):
            print(f"‚úÖ T√≠tulo t√©cnico SEO: {title}")
            
            # Atualiza cache
            used_topics.append(title)
            cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
            cache_data["last_update"] = datetime.now().isoformat()
            save_topics_cache(cache_data)
            
            return title
    
    # Fallback final
    return generate_seo_optimized_topic()

def generate_news_based_topic() -> str:
    """Gera t√≥pico baseado em not√≠cias reais atuais."""
    print("üì∞ Gerando t√≥pico baseado em not√≠cias atuais...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    # Obt√©m not√≠cias atuais
    try:
        news_articles = get_current_news("technology")
        
        if not news_articles:
            print("‚ö†Ô∏è Nenhuma not√≠cia encontrada, usando gera√ß√£o SEO...")
            return generate_seo_optimized_topic()
        
        # Seleciona not√≠cia aleat√≥ria
        selected_news = random.choice(news_articles)
        
        # Gera varia√ß√µes de t√≠tulo baseadas na not√≠cia
        news_title = selected_news["title"]
        news_keywords = selected_news.get("keywords", [])
        
        # Templates para transformar not√≠cia em conte√∫do
        news_templates = [
            f"An√°lise: O que {news_title.lower()} significa para o mercado",
            f"Entendendo: Como {news_title.lower()} impacta empresas brasileiras", 
            f"Contexto: Por que {news_title.lower()} √© importante",
            f"Guia: O que aprender com {news_title.lower()}",
            f"Impacto: Como {news_title.lower()} muda o cen√°rio tech",
            f"An√°lise completa: {news_title} e suas implica√ß√µes"
        ]
        
        # Gera t√≠tulos mais espec√≠ficos se h√° palavras-chave
        if news_keywords:
            keyword = news_keywords[0]
            specific_templates = [
                f"Como {keyword} est√° transformando o mercado ap√≥s {news_title.lower()}",
                f"Guia completo: {keyword} no contexto de {news_title.lower()}",
                f"An√°lise: Impacto de {keyword} revelado por {news_title.lower()}",
                f"O que {news_title.lower()} ensina sobre {keyword}",
                f"Tend√™ncias em {keyword}: li√ß√µes de {news_title.lower()}"
            ]
            news_templates.extend(specific_templates)
        
        # Testa t√≠tulos at√© encontrar um v√°lido
        for template in news_templates:
            # Pula templates muito longos
            if len(template) > SEO_TITLE_MAX_LENGTH:
                continue
            
            if len(template) >= SEO_TITLE_MIN_LENGTH and not is_topic_duplicate(template, used_topics):
                print(f"‚úÖ T√≠tulo baseado em not√≠cia: {template}")
                print(f"üì∞ Not√≠cia fonte: {selected_news['source']} - {news_title}")
                
                # Atualiza cache
                used_topics.append(template)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                cache_data["news_source"] = {
                    "title": news_title,
                    "source": selected_news["source"],
                    "url": selected_news.get("url", ""),
                    "published_at": selected_news.get("published_at", "")
                }
                save_topics_cache(cache_data)
                
                return template
        
        print("‚ö†Ô∏è Nenhum t√≠tulo v√°lido gerado da not√≠cia, usando SEO...")
        return generate_seo_optimized_topic()
        
    except Exception as e:
        print(f"‚ùå Erro ao obter not√≠cias: {e}")
        print("‚ö†Ô∏è Fallback para gera√ß√£o SEO...")
        return generate_seo_optimized_topic()

def generate_seo_optimized_topic() -> str:
    """Gera um t√≥pico otimizado para SEO e Google Ads."""
    print("üéØ Gerando t√≥pico SEO-otimizado...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    today = datetime.now()
    current_year = today.year
    
    # Seleciona categoria SEO e palavras-chave
    seo_category = random.choice(list(SEO_KEYWORDS.keys()))
    keywords = SEO_KEYWORDS[seo_category]
    primary_keyword = random.choice(keywords)
    
    # Seleciona template SEO
    template = random.choice(SEO_TITLE_TEMPLATES)
    
    # Preenche o template com dados relevantes
    tech_area = random.choice(TRENDING_PRODUCTS + EMERGING_TECH)
    sector = random.choice(APPLICATION_SECTORS)
    audience = random.choice(["desenvolvedores", "empresas", "iniciantes", "profissionais"])
    number = random.choice(["5", "7", "10", "15"])
    
    # Gera t√≠tulo baseado no template
    title_variations = []
    
    try:
        title = template.format(
            tecnologia=primary_keyword,
            setor=sector,
            p√∫blico=audience,
            n√∫mero=number,
            ano=current_year,
            alternativa=random.choice(keywords),
            contexto=sector
        )
        title_variations.append(title)
    except KeyError:
        pass  # Template n√£o compat√≠vel, pula
    
    # Adiciona varia√ß√µes manuais SEO-friendly
    manual_variations = [
        f"Como usar {primary_keyword} para melhorar {sector}",
        f"Guia completo de {primary_keyword} para {audience}",
        f"{number} dicas de {primary_keyword} que funcionam em {current_year}",
        f"Tutorial: {primary_keyword} na pr√°tica para {sector}",
        f"An√°lise: impacto de {primary_keyword} no Brasil"
    ]
    
    title_variations.extend(manual_variations)
    
    # Seleciona t√≠tulo que n√£o seja duplicata
    for title in title_variations:
        if not is_topic_duplicate(title, used_topics):
            # Valida tamanho SEO
            if SEO_TITLE_MIN_LENGTH <= len(title) <= SEO_TITLE_MAX_LENGTH:
                print(f"‚úÖ T√≠tulo SEO gerado: {title}")
                print(f"üìä Palavra-chave principal: {primary_keyword}")
                print(f"üéØ Categoria: {seo_category}")
                
                # Atualiza cache
                used_topics.append(title)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                save_topics_cache(cache_data)
                
                return title
    
    # Fallback para gera√ß√£o com IA se necess√°rio
    print("‚ö†Ô∏è Nenhum t√≠tulo SEO v√°lido encontrado, usando gera√ß√£o com IA...")
    return generate_new_topic()

def generate_new_topic() -> str:
    """Usa a IA para gerar um novo t√≥pico educativo e anal√≠tico sobre tecnologia."""
    print("üß† Gerando t√≥pico educativo sobre tecnologia...")
    
    cache_data = load_topics_cache()
    used_topics = cache_data.get("used_topics", [])
    
    today = datetime.now()
    current_date_str = today.strftime("%d de %B de %Y")
    current_year = today.year
    
    # Obt√©m tend√™ncias atuais do mercado
    market_trends = get_market_trends()
    
    # Seleciona uma categoria aleat√≥ria e pega algumas tend√™ncias
    category = random.choice(list(market_trends.keys()))
    category_trends = market_trends[category]
    
    max_attempts = MAX_TOPIC_ATTEMPTS
    for attempt in range(max_attempts):
        # Seleciona 2-3 tend√™ncias da categoria escolhida
        selected_trends = random.sample(category_trends, min(3, len(category_trends)))
        
        # Decide se ser√° conte√∫do puramente educativo ou h√≠brido (70% educativo, 30% h√≠brido)
        is_hybrid = random.random() < 0.3
        
        if is_hybrid:
            # Conte√∫do h√≠brido: educativo + contexto de not√≠cias
            content_type = random.choice(HYBRID_CONTENT_TYPES)
            hybrid_keyword = random.choice(HYBRID_KEYWORDS)
            news_context = random.choice(NEWS_CONTEXTS)
            tech_theme = random.choice(list(TECH_NEWS_THEMES.keys()))
            theme_topics = TECH_NEWS_THEMES[tech_theme]
            news_topic = random.choice(theme_topics)
            print(f"üîÑ Modo h√≠brido: {content_type} sobre {news_topic}")
        else:
            # Conte√∫do puramente educativo
            content_type = random.choice(EDUCATIONAL_CONTENT_TYPES)
            educational_keyword = random.choice(EDUCATIONAL_KEYWORDS)
            print(f"üìö Modo educativo: {content_type}")
        
        tech_area = random.choice(selected_trends)
        application_sector = random.choice(APPLICATION_SECTORS)
        technical_concept = random.choice(TECHNICAL_CONCEPTS)
        
        if is_hybrid:
            # Prompt para conte√∫do h√≠brido (educativo + contexto de not√≠cias)
            prompt = (
                f"Voc√™ √© um analista t√©cnico criando conte√∫do educativo contextualizado para {current_year}.\n\n"
                f"Gere um t√≠tulo que EDUQUE sobre tecnologia usando contexto de tend√™ncias atuais:\n\n"
                f"ELEMENTOS PARA O T√çTULO:\n"
                f"‚Ä¢ Tipo de an√°lise: {content_type}\n"
                f"‚Ä¢ Contexto atual: {news_context} {news_topic}\n"
                f"‚Ä¢ √Årea t√©cnica: {tech_area}\n"
                f"‚Ä¢ Setor de aplica√ß√£o: {application_sector}\n"
                f"‚Ä¢ Conceito t√©cnico: {technical_concept}\n\n"
                f"F√ìRMULAS H√çBRIDAS:\n"
                f"‚Ä¢ '{content_type}: {news_topic} e o impacto em [setor]'\n"
                f"‚Ä¢ 'O que {news_topic} ensina sobre [conceito t√©cnico]'\n"
                f"‚Ä¢ '{hybrid_keyword}: Como {news_topic} afeta [setor]'\n"
                f"‚Ä¢ 'Li√ß√µes de {news_topic} para [aplica√ß√£o pr√°tica]'\n\n"
                f"EXEMPLOS H√çBRIDOS:\n"
                f"‚Ä¢ 'An√°lise: O que os avan√ßos em IA generativa significam para startups'\n"
                f"‚Ä¢ 'Contexto: Por que investimentos em IA est√£o transformando a sa√∫de'\n"
                f"‚Ä¢ 'Entendendo o impacto de novos modelos de linguagem no desenvolvimento'\n"
                f"‚Ä¢ 'Li√ß√µes dos recentes desenvolvimentos em ciberseguran√ßa para PMEs'\n\n"
                f"DIRETRIZES H√çBRIDAS:\n"
                f"‚Ä¢ Use contexto de tend√™ncias SEM inventar fatos espec√≠ficos\n"
                f"‚Ä¢ Foque no APRENDIZADO que o contexto oferece\n"
                f"‚Ä¢ Mantenha tom educativo, n√£o noticioso\n"
                f"‚Ä¢ M√°ximo 100 caracteres\n"
                f"‚Ä¢ Evite datas espec√≠ficas ou eventos inventados\n\n"
                f"EVITE (j√° cobertos): {', '.join(used_topics[-5:]) if used_topics else 'nenhum'}\n\n"
                f"Gere um t√≠tulo que ENSINE usando contexto atual:\n"
                f"APENAS O T√çTULO:"
            )
        else:
            # Prompt para conte√∫do puramente educativo
            prompt = (
                f"Voc√™ √© um especialista t√©cnico criando conte√∫do educativo para {current_year}.\n\n"
                f"Gere um t√≠tulo EDUCATIVO sobre tecnologia usando estes elementos:\n\n"
                f"ELEMENTOS DISPON√çVEIS:\n"
                f"‚Ä¢ Tipo de conte√∫do: {content_type}\n"
                f"‚Ä¢ √Årea t√©cnica: {tech_area}\n"
                f"‚Ä¢ Palavra-chave educativa: {educational_keyword}\n"
                f"‚Ä¢ Setor de aplica√ß√£o: {application_sector}\n"
                f"‚Ä¢ Conceito t√©cnico: {technical_concept}\n\n"
                f"F√ìRMULAS EDUCATIVAS:\n"
                f"‚Ä¢ '{educational_keyword} [tecnologia]: [conceito] para [setor]'\n"
                f"‚Ä¢ '{content_type}: [tecnologia] em [setor] - [conceito]'\n"
                f"‚Ä¢ 'Como [tecnologia] melhora [conceito] no [setor]'\n"
                f"‚Ä¢ '{content_type} de [tecnologia]: [conceito] na pr√°tica'\n\n"
                f"EXEMPLOS DE QUALIDADE:\n"
                f"‚Ä¢ 'Guia completo: Implementando IA generativa em startups'\n"
                f"‚Ä¢ 'An√°lise: Como edge computing melhora performance em sa√∫de'\n"
                f"‚Ä¢ 'Entendendo blockchain: Seguran√ßa de dados no setor financeiro'\n"
                f"‚Ä¢ 'Comparativo: Arquiteturas de software para escalabilidade'\n\n"
                f"DIRETRIZES:\n"
                f"‚Ä¢ Foque em VALOR EDUCATIVO real\n"
                f"‚Ä¢ Use linguagem t√©cnica mas acess√≠vel\n"
                f"‚Ä¢ Seja espec√≠fico sobre aplica√ß√£o pr√°tica\n"
                f"‚Ä¢ M√°ximo 100 caracteres\n"
                f"‚Ä¢ Evite sensacionalismo\n\n"
                f"EVITE (j√° cobertos): {', '.join(used_topics[-5:]) if used_topics else 'nenhum'}\n\n"
                f"Gere UM t√≠tulo educativo que ensine algo valioso:\n"
                f"APENAS O T√çTULO:"
            )
        
        try:
            topic = call_gemini_api(prompt).strip()
            if topic and not is_topic_duplicate(topic, used_topics):
                print(f"‚úÖ T√≥pico gerado (tentativa {attempt + 1}): {topic}")
                
                # Atualiza o cache
                used_topics.append(topic)
                cache_data["used_topics"] = used_topics[-MAX_CACHED_TOPICS:]
                cache_data["last_update"] = datetime.now().isoformat()
                save_topics_cache(cache_data)
                
                return topic
            else:
                print(f"‚ö†Ô∏è T√≥pico duplicado ou inv√°lido (tentativa {attempt + 1})")
        except Exception as e:
            print(f"‚ùå Erro na tentativa {attempt + 1}: {e}")
    
    print("‚ùå N√£o foi poss√≠vel gerar um t√≥pico √∫nico ap√≥s v√°rias tentativas.")
    return ""

def get_educational_context(title: str) -> Dict[str, str]:
    """Gera contexto educativo baseado no t√≠tulo do artigo."""
    today = datetime.now()
    current_year = today.year
    
    # Identifica o tipo de conte√∫do baseado no t√≠tulo
    if any(word in title.lower() for word in ["como", "guia", "entendendo"]):
        content_focus = "explicativo"
    elif any(word in title.lower() for word in ["an√°lise", "comparativo", "vs"]):
        content_focus = "anal√≠tico"
    elif any(word in title.lower() for word in ["futuro", "tend√™ncias", "evolu√ß√£o"]):
        content_focus = "prospectivo"
    else:
        content_focus = "informativo"
    
    return {
        "current_year": str(current_year),
        "content_focus": content_focus,
        "educational_approach": random.choice([
            "did√°tico e acess√≠vel", "t√©cnico mas compreens√≠vel", 
            "pr√°tico e aplicado", "anal√≠tico e detalhado"
        ])
    }

def generate_references(title: str) -> List[str]:
    """Gera fontes de refer√™ncia realistas para o artigo."""
    print("üìö Selecionando fontes cred√≠veis...")
    
    # Seleciona fontes baseadas no tipo de not√≠cia
    references = []
    
    # Sempre inclui uma fonte brasileira
    references.append(random.choice(CREDIBLE_SOURCES["brazilian"]))
    
    # Adiciona fontes internacionais baseadas no t√≠tulo
    if any(company in title.lower() for company in ["apple", "google", "microsoft", "meta", "openai"]):
        references.append(random.choice(CREDIBLE_SOURCES["official"]))
    
    # Adiciona fontes de tech news
    references.extend(random.sample(CREDIBLE_SOURCES["tech_news"], 2))
    
    # Se menciona investimento/neg√≥cios, adiciona fonte business
    if any(word in title.lower() for word in ["bilh√µes", "aquisi√ß√£o", "investimento", "ipo"]):
        references.append(random.choice(CREDIBLE_SOURCES["business"]))
    
    # Remove duplicatas e limita a 5 fontes
    references = list(dict.fromkeys(references))[:5]
    
    print(f"‚úÖ {len(references)} fontes selecionadas: {', '.join(references)}")
    return references

def write_article_chunked(title: str) -> str:
    """Gera artigo em partes menores para evitar timeout."""
    print("üîß Gerando artigo em chunks para evitar timeout...")
    
    # Gera estrutura primeiro
    structure_prompt = (
        f"Crie apenas a ESTRUTURA de um artigo t√©cnico sobre: '{title}'\n\n"
        f"Retorne apenas os t√≠tulos das se√ß√µes em markdown (##), sem conte√∫do.\n"
        f"Exemplo:\n"
        f"## Resumo da Not√≠cia\n"
        f"## An√°lise T√©cnica\n"
        f"## Impactos na Infraestrutura\n"
        f"## Conclus√£o\n\n"
        f"M√°ximo 6 se√ß√µes."
    )
    
    try:
        structure = call_gemini_api(structure_prompt, timeout=15)
        sections = [s.strip() for s in structure.split('\n') if s.strip().startswith('##')]
        
        if not sections:
            print("‚ö†Ô∏è Fallback para gera√ß√£o normal...")
            return write_article(title)
        
        print(f"üìã Estrutura criada: {len(sections)} se√ß√µes")
        
        # Gera cada se√ß√£o separadamente
        full_article = ""
        
        for i, section in enumerate(sections):
            print(f"‚úçÔ∏è Gerando se√ß√£o {i+1}/{len(sections)}: {section}")
            
            section_prompt = (
                f"Escreva APENAS o conte√∫do para a se√ß√£o '{section}' de um artigo sobre: '{title}'\n\n"
                f"Contexto: An√°lise t√©cnica para profissionais de TI.\n"
                f"Tamanho: 150-250 palavras.\n"
                f"Tom: T√©cnico e informativo.\n\n"
                f"Retorne apenas o conte√∫do da se√ß√£o, sem o t√≠tulo."
            )
            
            try:
                section_content = call_gemini_api(section_prompt, timeout=20)
                full_article += f"{section}\n\n{section_content}\n\n"
                print(f"‚úÖ Se√ß√£o {i+1} conclu√≠da")
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na se√ß√£o {i+1}: {e}")
                # Continua com as outras se√ß√µes
                full_article += f"{section}\n\n[Conte√∫do da se√ß√£o em desenvolvimento]\n\n"
        
        return full_article
        
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o chunked: {e}")
        print("‚ö†Ô∏è Fallback para gera√ß√£o normal...")
        return write_article(title)

def write_article(title: str) -> str:
    """Gera o conte√∫do do artigo baseado em not√≠cias reais ou educativo."""
    
    # Detecta se √© conte√∫do baseado em not√≠cias
    is_news_based = any(word in title.lower() for word in [
        "an√°lise", "contexto:", "o que", "li√ß√µes", "por tr√°s", 
        "significam", "impacto de", "entendendo", "como", "ap√≥s",
        "deep dive:", "tech breakdown:", "security review:"
    ])
    
    # Obt√©m contexto de not√≠cia se dispon√≠vel
    news_context = None
    if is_news_based:
        # Primeiro tenta obter do cache (not√≠cia usada para gerar o t√≠tulo)
        cache_data = load_topics_cache()
        cached_news = cache_data.get("news_source")
        
        if cached_news and cached_news.get("title"):
            news_context = cached_news
            print(f"üì∞ Usando not√≠cia do cache: {cached_news['title']}")

        else:
            # Fallback: busca not√≠cia relevante
            title_keywords = []
            for category_keywords in SEO_KEYWORDS.values():
                for keyword in category_keywords:
                    if keyword.lower() in title.lower():
                        title_keywords.append(keyword)
            
            news_context = get_news_context(title_keywords)
    


    print(f"ÔøΩ DebuCg final - is_news_analysis: {is_news_analysis if 'is_news_analysis' in locals() else 'n√£o definido ainda'}")
    
    if news_context:
        print(f'‚úçÔ∏è Escrevendo artigo baseado em not√≠cia real: "{title}"...')
        print(f'üì∞ Contexto: {news_context["source"]} - {news_context["title"]}')
    elif is_news_based:
        print(f'‚úçÔ∏è Escrevendo artigo h√≠brido (educativo + contexto): "{title}"...')
    else:
        print(f'‚úçÔ∏è Escrevendo artigo educativo sobre: "{title}"...')
    
    # Gera as refer√™ncias cred√≠veis e contexto educativo
    references = generate_references(title)
    references_text = ", ".join(references)
    edu_context = get_educational_context(title)
    
    today = datetime.now()
    current_date = today.strftime("%d de %B de %Y")
    
    # Detecta se √© an√°lise t√©cnica de not√≠cia
    is_news_analysis = any(word in title.lower() for word in [
        "an√°lise t√©cnica:", "deep dive:", "tech breakdown:", "security review:",
        "performance analysis:", "devops perspective:", "enterprise impact:",
        "infrastructure implications:", "implementation guide:", "case study t√©cnico:"
    ])
    
    # Detecta se √© conte√∫do t√©cnico geral
    is_technical_content = any(word in title.lower() for word in [
        "technical", "deep dive", "performance", "security", "devops", 
        "architecture", "infrastructure", "deployment", "monitoring", "benchmarks"
    ])
    
    if news_context and is_news_analysis:
        # Prompt para conte√∫do t√©cnico baseado em not√≠cia
        news_title = news_context["title"]
        news_source = news_context["source"]
        news_description = news_context.get("description", "")
        
        prompt = (
            f"AN√ÅLISE T√âCNICA DE NOT√çCIA REAL - {current_date}\n\n"
            f"Voc√™ √© um tech lead s√™nior fazendo uma an√°lise t√©cnica profunda da not√≠cia: '{news_title}'\n"
            f"Seu artigo tem o t√≠tulo: '{title}'\n\n"
            f"NOT√çCIA ORIGINAL:\n"
            f"- T√≠tulo: {news_title}\n"
            f"- Fonte: {news_source}\n"
            f"- Contexto: {news_description}\n\n"
            f"FONTES T√âCNICAS ADICIONAIS: {references_text}\n\n"
            f"OBJETIVO: Fazer um 'refactoring' t√©cnico da not√≠cia, explicando:\n"
            f"- O que realmente aconteceu tecnicamente\n"
            f"- Por que isso importa para profissionais de TI\n"
            f"- Quais s√£o as implica√ß√µes pr√°ticas\n"
            f"- Como isso afeta infraestrutura e opera√ß√µes\n\n"
            f"ESTRUTURA JORNAL√çSTICA PROFISSIONAL:\n"
            f"1. ## Lead Jornal√≠stico\n"
            f"   - Par√°grafo de abertura com os 5 W's (O que, Quem, Quando, Onde, Por que)\n"
            f"   - Impacto imediato e relev√¢ncia para o leitor\n"
            f"   - Dados quantitativos quando dispon√≠veis\n\n"
            f"2. ## Contexto e Background\n"
            f"   - Hist√≥rico da tecnologia/empresa/situa√ß√£o\n"
            f"   - Desenvolvimentos anteriores relevantes\n"
            f"   - Posicionamento no mercado atual\n\n"
            f"3. ## An√°lise T√©cnica Aprofundada\n"
            f"   - Especifica√ß√µes t√©cnicas detalhadas\n"
            f"   - Compara√ß√£o com concorrentes/alternativas\n"
            f"   - Arquitetura e componentes envolvidos\n\n"
            f"4. ## Impactos e Implica√ß√µes\n"
            f"   - Efeitos na ind√∫stria e mercado\n"
            f"   - Mudan√ßas para desenvolvedores e empresas\n"
            f"   - Considera√ß√µes de ado√ß√£o e migra√ß√£o\n\n"
            f"5. ## Perspectiva de Especialistas\n"
            f"   - An√°lise de tend√™ncias do setor\n"
            f"   - Desafios e oportunidades identificados\n"
            f"   - Previs√µes baseadas em dados\n\n"
            f"6. ## Implementa√ß√£o Pr√°tica\n"
            f"   - Guia passo-a-passo para ado√ß√£o\n"
            f"   - Custos, recursos e timeline realistas\n"
            f"   - M√©tricas de sucesso e KPIs\n\n"
            f"7. ## Conclus√£o Editorial\n"
            f"   - S√≠ntese dos pontos principais\n"
            f"   - Recomenda√ß√µes baseadas na an√°lise\n"
            f"   - Pr√≥ximos desenvolvimentos a acompanhar\n\n"
            f"PADR√ïES DE QUALIDADE JORNAL√çSTICA:\n"
            f"- {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras com densidade informacional alta\n"
            f"- LEAD jornal√≠stico: responda O QUE, QUEM, QUANDO, ONDE, POR QUE nos primeiros par√°grafos\n"
            f"- Estrutura de pir√¢mide invertida: informa√ß√µes mais importantes primeiro\n"
            f"- Fontes cred√≠veis e cita√ß√µes espec√≠ficas (n√£o gen√©ricas)\n"
            f"- Dados concretos, estat√≠sticas e n√∫meros verific√°veis\n"
            f"- Contexto hist√≥rico e compara√ß√µes relevantes\n"
            f"- Linguagem precisa, objetiva e sem redund√¢ncias\n"
            f"- Transi√ß√µes l√≥gicas entre par√°grafos\n"
            f"- Evite clich√™s e frases feitas\n"
            f"- Cada par√°grafo deve ter uma ideia central clara\n"
            f"- Conclus√µes baseadas em evid√™ncias apresentadas\n\n"
            f"ELEMENTOS OBRIGAT√ìRIOS:\n"
            f"‚úÖ Lead jornal√≠stico com os 5 W's nos primeiros par√°grafos\n"
            f"‚úÖ Dados espec√≠ficos: n√∫meros, percentuais, vers√µes, datas\n"
            f"‚úÖ Cita√ß√µes de fontes cred√≠veis e especialistas\n"
            f"‚úÖ An√°lise t√©cnica que vai al√©m da not√≠cia superficial\n"
            f"‚úÖ Compara√ß√µes com concorrentes e alternativas\n"
            f"‚úÖ Contexto hist√≥rico e posicionamento no mercado\n"
            f"‚úÖ Impactos pr√°ticos para desenvolvedores e empresas\n"
            f"‚úÖ Conclus√µes baseadas em evid√™ncias apresentadas\n\n"
            f"QUALIDADE EDITORIAL OBRIGAT√ìRIA:\n"
            f"üéØ Cada par√°grafo = uma ideia central (3-5 frases)\n"
            f"üéØ Transi√ß√µes l√≥gicas entre par√°grafos e se√ß√µes\n"
            f"üéØ Linguagem precisa, sem redund√¢ncias ou clich√™s\n"
            f"üéØ Verbos no tempo correto (presente/passado)\n"
            f"üéØ Estrutura de pir√¢mide invertida (mais importante primeiro)\n\n"
            f"INSTRU√á√ïES CR√çTICAS PARA QUALIDADE JORNAL√çSTICA:\n"
            f"‚Ä¢ PRIMEIRO PAR√ÅGRAFO deve responder: O QUE aconteceu, QUEM est√° envolvido, QUANDO\n"
            f"‚Ä¢ Use conectores l√≥gicos: 'Al√©m disso', 'Por outro lado', 'Consequentemente'\n"
            f"‚Ä¢ Par√°grafos de 3-5 frases cada, m√°ximo 100 palavras\n"
            f"‚Ä¢ Dados espec√≠ficos: n√∫meros, percentuais, vers√µes, datas\n"
            f"‚Ä¢ Linguagem precisa e objetiva, sem exageros ou clich√™s\n"
            f"‚Ä¢ Estrutura de pir√¢mide invertida: mais importante primeiro\n\n"
            f"Escreva uma AN√ÅLISE JORNAL√çSTICA T√âCNICA que profissionais de TI respeitar√£o!"
        )
    elif news_context:
        # Prompt para conte√∫do baseado em not√≠cia real (menos t√©cnico)
        news_title = news_context["title"]
        news_source = news_context["source"]
        news_description = news_context.get("description", "")
        
        prompt = (
            f"AN√ÅLISE INFORMATIVA PARA PROFISSIONAIS DE TI - {current_date}\n\n"
            f"Voc√™ √© um tech lead experiente escrevendo para profissionais de TI sobre: '{title}'\n\n"
            f"NOT√çCIA DE REFER√äNCIA:\n"
            f"- T√≠tulo: {news_title}\n"
            f"- Fonte: {news_source}\n"
            f"- Contexto: {news_description}\n\n"
            f"FONTES ADICIONAIS: {references_text}\n\n"
            f"ESTRUTURA INFORMATIVA:\n"
            f"1. RESUMO EXECUTIVO: Key takeaways para profissionais ocupados\n"
            f"2. ## Contexto T√©cnico (o que mudou e por que importa)\n"
            f"3. ## An√°lise de Impacto (como afeta stacks e workflows atuais)\n"
            f"4. ## Implica√ß√µes para Equipes (skills, processos, ferramentas)\n"
            f"5. ## Considera√ß√µes de Ado√ß√£o (quando e como implementar)\n"
            f"6. ## Competitive Landscape (alternativas e compara√ß√µes)\n"
            f"7. ## Roadmap e Pr√≥ximos Passos (planejamento estrat√©gico)\n\n"
            f"DIRETRIZES PROFISSIONAIS:\n"
            f"- {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras\n"
            f"- Tom profissional, direto ao ponto\n"
            f"- Foque em implica√ß√µes pr√°ticas para o dia a dia\n"
            f"- Inclua considera√ß√µes de budget, timeline, recursos\n"
            f"- Aborde riscos e benef√≠cios de forma equilibrada\n"
            f"- Contextualize para realidade de empresas brasileiras\n\n"
            f"IMPORTANTE:\n"
            f"‚úÖ Informa√ß√£o acion√°vel para tomada de decis√£o\n"
            f"‚úÖ An√°lise cr√≠tica, n√£o apenas hype\n"
            f"‚úÖ Considera√ß√µes pr√°ticas de implementa√ß√£o\n"
            f"‚úÖ Impacto em workflows e processos existentes\n"
            f"‚ùå N√ÉO seja apenas descritivo\n"
            f"‚ùå N√ÉO ignore limita√ß√µes e desafios\n\n"
            f"Escreva para PROFISSIONAIS que precisam tomar DECIS√ïES T√âCNICAS!"
        )
    elif is_news_based:
        # Prompt para conte√∫do h√≠brido (educativo + contexto de tend√™ncias)
        prompt = (
            f"ARTIGO EDUCATIVO CONTEXTUALIZADO - {current_date}\n\n"
            f"Voc√™ √© um analista t√©cnico escrevendo um artigo EDUCATIVO que usa contexto de tend√™ncias: '{title}'\n\n"
            f"CONTEXTO EDUCATIVO:\n"
            f"- Ano de refer√™ncia: {edu_context['current_year']}\n"
            f"- Foco do conte√∫do: {edu_context['content_focus']}\n"
            f"- Abordagem: {edu_context['educational_approach']}\n\n"
            f"FONTES DE REFER√äNCIA: {references_text}\n\n"
            f"ESTRUTURA H√çBRIDA:\n"
            f"1. INTRODU√á√ÉO: Contextualize a tend√™ncia e sua relev√¢ncia educativa\n"
            f"2. ## Contexto Atual (tend√™ncias gerais, sem fatos espec√≠ficos)\n"
            f"3. ## Conceitos T√©cnicos Envolvidos (explica√ß√£o educativa)\n"
            f"4. ## An√°lise do Impacto (o que isso significa tecnicamente)\n"
            f"5. ## Li√ß√µes e Aprendizados (insights educativos)\n"
            f"6. ## Aplica√ß√µes Pr√°ticas (como aplicar o conhecimento)\n"
            f"7. ## Conclus√£o (s√≠ntese educativa)\n\n"
            f"DIRETRIZES H√çBRIDAS:\n"
            f"- {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras (otimizado para SEO)\n"
            f"- Use contexto de tend√™ncias para EDUCAR, n√£o para noticiar\n"
            f"- Foque no APRENDIZADO que as tend√™ncias oferecem\n"
            f"- Explique conceitos t√©cnicos por tr√°s das tend√™ncias\n"
            f"- Mantenha tom educativo, nunca jornal√≠stico urgente\n"
            f"- Contextualize para profissionais brasileiros\n\n"
            f"PROIBI√á√ïES ABSOLUTAS:\n"
            f"‚ùå N√ÉO invente eventos espec√≠ficos ou datas\n"
            f"‚ùå N√ÉO crie not√≠cias falsas ou fatos espec√≠ficos\n"
            f"‚ùå N√ÉO use linguagem de urg√™ncia jornal√≠stica\n"
            f"‚ùå N√ÉO afirme acontecimentos espec√≠ficos n√£o verific√°veis\n"
            f"‚ùå N√ÉO crie cita√ß√µes ou declara√ß√µes falsas\n\n"
            f"FOQUE EM EDUCA√á√ÉO CONTEXTUALIZADA:\n"
            f"‚úÖ Use tend√™ncias gerais como contexto educativo\n"
            f"‚úÖ Explique conceitos t√©cnicos por tr√°s das tend√™ncias\n"
            f"‚úÖ Analise implica√ß√µes e aprendizados\n"
            f"‚úÖ Forne√ßa insights pr√°ticos e aplic√°veis\n"
            f"‚úÖ Eduque sobre como se preparar para mudan√ßas\n\n"
            f"Escreva um artigo que EDUQUE usando contexto de tend√™ncias atuais!"
        )
    else:
        # Prompt para conte√∫do puramente educativo
        prompt = (
            f"ARTIGO T√âCNICO EDUCATIVO - {current_date}\n\n"
            f"Voc√™ √© um especialista t√©cnico escrevendo um artigo EDUCATIVO sobre: '{title}'\n\n"
            f"CONTEXTO EDUCATIVO:\n"
            f"- Ano de refer√™ncia: {edu_context['current_year']}\n"
            f"- Foco do conte√∫do: {edu_context['content_focus']}\n"
            f"- Abordagem: {edu_context['educational_approach']}\n\n"
            f"FONTES DE REFER√äNCIA: {references_text}\n\n"
            f"ESTRUTURA EDUCATIVA:\n"
            f"1. INTRODU√á√ÉO: Apresente o tema e sua relev√¢ncia\n"
            f"2. ## Conceitos e Defini√ß√µes (fundamentos t√©cnicos)\n"
            f"3. ## Como Funciona (aspectos t√©cnicos explicados)\n"
            f"4. ## Aplica√ß√µes e Casos de Uso (exemplos reais)\n"
            f"5. ## Vantagens e Desvantagens (an√°lise equilibrada)\n"
            f"6. ## Considera√ß√µes para Implementa√ß√£o (aspectos pr√°ticos)\n"
            f"7. ## Conclus√£o (s√≠ntese e recomenda√ß√µes)\n\n"
            f"DIRETRIZES RIGOROSAS:\n"
            f"- {SEO_ARTICLE_MIN_WORDS}-{SEO_ARTICLE_MAX_WORDS} palavras (otimizado para SEO)\n"
            f"- Tom EDUCATIVO e T√âCNICO, nunca sensacionalista\n"
            f"- Base-se em conhecimento geral estabelecido\n"
            f"- Explique conceitos complexos de forma clara\n"
            f"- Use exemplos pr√°ticos e aplic√°veis\n"
            f"- Seja honesto sobre limita√ß√µes e desafios\n"
            f"- Contextualize para desenvolvedores/profissionais brasileiros\n\n"
            f"PROIBI√á√ïES ABSOLUTAS:\n"
            f"‚ùå N√ÉO invente not√≠cias, lan√ßamentos ou eventos espec√≠ficos\n"
            f"‚ùå N√ÉO use linguagem de urg√™ncia ('breaking', 'exclusivo')\n"
            f"‚ùå N√ÉO crie cita√ß√µes ou declara√ß√µes falsas\n"
            f"‚ùå N√ÉO afirme fatos espec√≠ficos n√£o verific√°veis\n"
            f"‚ùå N√ÉO use datas espec√≠ficas recentes ('ontem', 'esta semana')\n"
            f"‚ùå N√ÉO invente n√∫meros ou estat√≠sticas\n\n"
            f"FOQUE EM VALOR EDUCATIVO:\n"
            f"‚úÖ Explique conceitos e funcionamento\n"
            f"‚úÖ Analise pr√≥s e contras de forma equilibrada\n"
            f"‚úÖ Forne√ßa orienta√ß√µes pr√°ticas\n"
            f"‚úÖ Compare diferentes abordagens/tecnologias\n"
            f"‚úÖ Eduque sobre melhores pr√°ticas\n"
            f"‚úÖ Contextualize tend√™ncias gerais do setor\n\n"
            f"Escreva um artigo que seja uma REFER√äNCIA T√âCNICA confi√°vel e educativa!"
        )
    
    try:
        safety_settings = {
            'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
            'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
            'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
            'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE',
        }
        
        article = call_gemini_api(prompt, safety_settings=safety_settings)
        
        if article:
            # Aplica limpeza completa e formata√ß√£o
            article = clean_content_completely(article)
            article = create_simple_structure(article, title)
            article = improve_journalistic_language(article)
            article = format_content(article)
            
            # Adiciona se√ß√£o de refer√™ncias formatada
            article += "\n\n---\n\n## üìö Fontes e Refer√™ncias\n\n"
            for i, ref in enumerate(references, 1):
                article += f"{i}. **{ref}**\n"
            
            # CTA engajante j√° foi aplicado pela fun√ß√£o add_engaging_cta
            
            print("‚úÖ Artigo gerado e formatado com sucesso.")
            return article
        else:
            print("‚ùå A IA n√£o retornou um artigo v√°lido.")
            return ""
    except Exception as e:
        print(f"‚ùå Erro ao gerar o artigo: {e}")
        return ""

def generate_seo_description(title: str, content: str) -> str:
    """Gera meta description otimizada para SEO."""
    print("üìù Gerando meta description SEO...")
    
    # Extrai primeira frase do conte√∫do
    first_paragraph = content.split('\n')[0:3]
    clean_text = ' '.join(first_paragraph).replace('#', '').strip()
    
    # Identifica palavra-chave principal do t√≠tulo
    title_lower = title.lower()
    primary_keyword = ""
    
    for category, keywords in SEO_KEYWORDS.items():
        for keyword in keywords:
            if keyword in title_lower:
                primary_keyword = keyword
                break
        if primary_keyword:
            break
    
    # Templates de meta description SEO
    templates = [
        f"Descubra como {primary_keyword} pode transformar seu neg√≥cio. Guia completo com dicas pr√°ticas e exemplos reais.",
        f"Tudo sobre {primary_keyword}: conceitos, implementa√ß√£o e melhores pr√°ticas. Leia nosso guia completo.",
        f"Aprenda {primary_keyword} do zero ao avan√ßado. Tutorial completo com exemplos pr√°ticos e dicas de especialistas.",
        f"Guia definitivo de {primary_keyword}: como implementar, vantagens e casos de sucesso no Brasil.",
        f"{primary_keyword} explicado: conceitos, aplica√ß√µes e como come√ßar. Guia pr√°tico para iniciantes e profissionais."
    ]
    
    if primary_keyword:
        description = random.choice(templates)
    else:
        # Fallback baseado no conte√∫do
        description = clean_text[:SEO_DESCRIPTION_MAX_LENGTH-3] + "..."
    
    # Ajusta tamanho para SEO
    if len(description) > SEO_DESCRIPTION_MAX_LENGTH:
        description = description[:SEO_DESCRIPTION_MAX_LENGTH-3] + "..."
    elif len(description) < SEO_DESCRIPTION_MIN_LENGTH:
        description += f" Leia mais sobre {primary_keyword} e suas aplica√ß√µes pr√°ticas."
    
    print(f"‚úÖ Meta description gerada ({len(description)} chars)")
    return description

def extract_seo_keywords(title: str, content: str) -> List[str]:
    """Extrai palavras-chave SEO do t√≠tulo e conte√∫do."""
    keywords = []
    title_lower = title.lower()
    content_lower = content.lower()
    
    # Identifica palavras-chave principais
    for category, keyword_list in SEO_KEYWORDS.items():
        for keyword in keyword_list:
            if keyword in title_lower or keyword in content_lower:
                keywords.append(keyword)
    
    # Remove duplicatas e limita
    keywords = list(dict.fromkeys(keywords))[:SEO_KEYWORDS_PER_POST]
    
    return keywords

def generate_tags(title: str, content: str) -> List[str]:
    """Gera tags relevantes para o post baseado no t√≠tulo e conte√∫do."""
    print("üè∑Ô∏è Gerando tags para o post...")
    
    prompt = (
        f"Baseado no t√≠tulo '{title}' e no conte√∫do do artigo, gere 3-6 tags relevantes em portugu√™s. "
        "Use tags comuns de tecnologia como: inteligencia-artificial, startups, ciberseguranca, "
        "inovacao, big-tech, software, hardware, mobile, web, dados, etc. "
        "Retorne apenas as tags separadas por v√≠rgula, em min√∫sculas e com h√≠fens no lugar de espa√ßos."
    )
    
    try:
        tags_text = call_gemini_api(prompt).strip()
        tags = [tag.strip().lower().replace(' ', '-') for tag in tags_text.split(',')]
        return [tag for tag in tags if tag and len(tag) > 2][:MAX_TAGS]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao gerar tags: {e}")
        return ["tecnologia", "inovacao"]

def create_hugo_post(title: str, content: str) -> Optional[Path]:
    """Cria e salva o arquivo .md para o Hugo com otimiza√ß√µes SEO completas."""
    print("üìù Formatando e salvando o post SEO-otimizado...")
    try:
        now = datetime.now()
        tz_offset = timezone(timedelta(hours=TIMEZONE_OFFSET))
        iso_timestamp = now.astimezone(tz_offset).isoformat()
        
        # Gera elementos SEO
        tags = generate_tags(title, content)
        seo_description = generate_seo_description(title, content)
        seo_keywords = extract_seo_keywords(title, content)
        
        # Calcula reading time (palavras / 200 palavras por minuto)
        word_count = len(content.split())
        reading_time = max(1, round(word_count / 200))
        
        # Limpa o t√≠tulo para usar no nome do arquivo
        slug = re.sub(r'[^\w\s-]', '', title.lower()).strip()
        slug = re.sub(r'[\s_]+', '-', slug)
        filename = POSTS_DIR / f"{now.strftime('%Y-%m-%d')}-{slug[:80]}.md"

        # Escapa caracteres especiais
        escaped_title = title.replace('"', '\\"')
        escaped_description = seo_description.replace('"', '\\"')
        
        # Formata arrays YAML
        tags_yaml = '\n  - '.join([''] + tags)
        keywords_yaml = '\n  - '.join([''] + seo_keywords) if seo_keywords else ''
        
        # Frontmatter SEO-otimizado
        frontmatter = f"""---
title: "{escaped_title}"
date: {iso_timestamp}
draft: false
description: "{escaped_description}"
summary: "{escaped_description}"
tags:{tags_yaml}
keywords:{keywords_yaml}
categories:
  - {HUGO_CATEGORY}
author: "{HUGO_AUTHOR}"
readingTime: {reading_time}
wordCount: {word_count}
seo:
  title: "{escaped_title}"
  description: "{escaped_description}"
  canonical: ""
  noindex: false
---

"""

        # Adiciona CTA engajante e estrutura SEO ao conte√∫do
        content_with_cta = add_engaging_cta(content, title)
        seo_content = add_seo_structure(content_with_cta, seo_keywords)
        
        filename.write_text(frontmatter + seo_content, encoding="utf-8")
        
        print(f"‚úÖ Post SEO salvo em: {filename}")
        print(f"üìä Tags: {', '.join(tags)}")
        print(f"üéØ Keywords SEO: {', '.join(seo_keywords)}")
        print(f"üìñ Tempo de leitura: {reading_time} min")
        print(f"üìù Palavras: {word_count}")
        
        return filename
    except Exception as e:
        print(f"‚ùå Erro ao criar o arquivo do post: {e}")
        return None

def add_storytelling_elements(content: str) -> str:
    """Adiciona elementos de storytelling para melhor engajamento."""
    
    # Adiciona hook de abertura se n√£o existir
    lines = content.split('\n')
    first_paragraph = lines[0] if lines else ""
    
    # Remove hooks n√£o-jornal√≠sticos - o lead deve ser direto e informativo
    # Em jornalismo t√©cnico, a abertura deve ser factual, n√£o especulativa
    pass
    
    # Adiciona transi√ß√µes jornal√≠sticas profissionais entre se√ß√µes
    sections = content.split('##')
    if len(sections) > 2:
        transitions = [
            "\n\nPara compreender o impacto completo, √© necess√°rio analisar:\n\n",
            "\n\nOs dados revelam aspectos importantes:\n\n", 
            "\n\nA an√°lise t√©cnica mostra que:\n\n",
            "\n\nEspecialistas do setor apontam:\n\n",
            "\n\nAs implica√ß√µes pr√°ticas incluem:\n\n"
        ]
        
        for i in range(1, min(len(sections), 4)):
            if i < len(transitions):
                sections[i] = transitions[i-1] + "##" + sections[i]
        
        content = "##".join(sections)
    
    return content


def improve_journalistic_language(content: str) -> str:
    """Melhora a linguagem para padr√µes jornal√≠sticos profissionais."""
    
    # Substitui linguagem marketeira por jornal√≠stica
    replacements = [
        # Remove linguagem especulativa
        (r'Imagine que', 'Considere que'),
        (r'E se eu te dissesse', 'Os dados indicam'),
        (r'Voc√™ j√° se perguntou', 'Analistas questionam'),
        (r'incr√≠vel', 'significativo'),
        (r'fant√°stico', 'not√°vel'),
        (r'revolucion√°rio', 'inovador'),
        
        # Melhora conectores
        (r'Mas isso n√£o √© tudo', 'Al√©m disso'),
        (r'E tem mais', 'Adicionalmente'),
        (r'Aqui est√° o ponto', 'O aspecto central √©'),
        
        # Linguagem mais precisa
        (r'muitas empresas', 'diversas organiza√ß√µes'),
        (r'a maioria dos', 'grande parte dos'),
        (r'praticamente todos', 'a maior parte dos'),
        
        # Remove exageros
        (r'extremamente', 'altamente'),
        (r'incrivelmente', 'notavelmente'),
        (r'absolutamente', 'completamente'),
    ]
    
    for pattern, replacement in replacements:
        content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
    
    # Melhora estrutura de frases
    # Evita frases muito longas
    sentences = re.split(r'(?<=[.!?])\s+', content)
    improved_sentences = []
    
    for sentence in sentences:
        words = sentence.split()
        # Se a frase tem mais de 25 palavras, sugere quebra
        if len(words) > 25 and ',' in sentence:
            # Tenta quebrar na primeira v√≠rgula ap√≥s a 15¬™ palavra
            comma_positions = [i for i, word in enumerate(words) if ',' in word]
            if comma_positions and comma_positions[0] > 10:
                break_point = comma_positions[0] + 1
                first_part = ' '.join(words[:break_point]).rstrip(',') + '.'
                second_part = ' '.join(words[break_point:])
                improved_sentences.extend([first_part, second_part])
            else:
                improved_sentences.append(sentence)
        else:
            improved_sentences.append(sentence)
    
    return ' '.join(improved_sentences)


def improve_headings_structure(content: str) -> str:
    """Melhora a estrutura dos subt√≠tulos com emojis consistentes."""
    
    # Mapeia palavras-chave para emojis apropriados
    emoji_map = {
        'an√°lise': 'üîç',
        't√©cnica': '‚öôÔ∏è', 
        'seguran√ßa': 'üõ°Ô∏è',
        'performance': '‚ö°',
        'implementa√ß√£o': 'üöÄ',
        'arquitetura': 'üèóÔ∏è',
        'infraestrutura': 'üè¢',
        'desenvolvimento': 'üíª',
        'devops': 'üîÑ',
        'cloud': '‚òÅÔ∏è',
        'dados': 'üìä',
        'api': 'üîå',
        'mobile': 'üì±',
        'web': 'üåê',
        'ia': 'ü§ñ',
        'machine learning': 'üß†',
        'blockchain': '‚õìÔ∏è',
        'conclus√£o': 'üéØ',
        'pr√≥ximos passos': '‚û°Ô∏è',
        'recursos': 'üìö'
    }
    
    lines = content.split('\n')
    improved_lines = []
    
    for line in lines:
        if line.startswith('## ') and not line.startswith('### '):
            # Remove emojis existentes
            clean_line = re.sub(r'[^\w\s\-:]', '', line[3:]).strip()
            
            # Encontra emoji apropriado
            emoji = 'üìã'  # emoji padr√£o
            for keyword, emoji_char in emoji_map.items():
                if keyword.lower() in clean_line.lower():
                    emoji = emoji_char
                    break
            
            # Reconstr√≥i o t√≠tulo
            improved_line = f"## {emoji} {clean_line}"
            improved_lines.append(improved_line)
        else:
            improved_lines.append(line)
    
    return '\n'.join(improved_lines)


def add_visual_elements(content: str) -> str:
    """Adiciona elementos visuais para melhorar a experi√™ncia de leitura."""
    
    # Adiciona separadores visuais entre se√ß√µes principais
    content = re.sub(r'\n(## [^#])', r'\n---\n\n\1', content)
    
    # Destaca informa√ß√µes importantes com callouts
    important_patterns = [
        (r'(√â importante notar que|Vale destacar que|Importante:|Aten√ß√£o:)', r'> **üí° Destaque:** \1'),
        (r'(Cuidado|Aten√ß√£o|Aviso)', r'> **‚ö†Ô∏è Aten√ß√£o:** \1'),
        (r'(Dica|Pro tip|Sugest√£o)', r'> **üí° Dica:** \1'),
        (r'(Exemplo|Por exemplo)', r'> **üìù Exemplo:** \1')
    ]
    
    for pattern, replacement in important_patterns:
        content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
    
    # Adiciona √≠cones para listas quando apropriado
    content = re.sub(r'^- (Vantagem|Benef√≠cio)', r'‚úÖ \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Desvantagem|Limita√ß√£o|Problema)', r'‚ùå \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Requisito|Necess√°rio)', r'üìã \1', content, flags=re.MULTILINE)
    content = re.sub(r'^- (Ferramenta|Tool)', r'üõ†Ô∏è \1', content, flags=re.MULTILINE)
    
    return content


def add_engaging_cta(content: str, title: str) -> str:
    """Adiciona call-to-actions mais engajantes ao final do conte√∫do."""
    
    # Remove CTAs gen√©ricos existentes
    content = re.sub(r'\*\*Gostou do conte√∫do\?\*\*.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    content = re.sub(r'### üí¨ Discuss√£o.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    content = re.sub(r'## Conclus√£o\n\nEste guia oferece.*?$', '', content, flags=re.MULTILINE | re.DOTALL)
    
    # CTAs espec√≠ficos baseados no tipo de conte√∫do
    if any(word in title.lower() for word in ['an√°lise', 'deep dive', 'breakdown']):
        cta = """
## üí¨ Vamos Continuar a Conversa

**Qual sua experi√™ncia com essa tecnologia?** Compartilhe nos coment√°rios:
- J√° implementou algo similar na sua empresa?
- Quais desafios enfrentou durante a ado√ß√£o?
- Que outras an√°lises t√©cnicas gostaria de ver?

**üìß Quer receber mais conte√∫do t√©cnico como este?** 
Conecte-se comigo no LinkedIn para discuss√µes sobre arquitetura, DevOps e inova√ß√£o.

**üîÑ Achou √∫til?** Compartilhe com sua equipe - conhecimento t√©cnico √© melhor quando compartilhado!
"""
    elif any(word in title.lower() for word in ['security', 'seguran√ßa', 'vulnerabilidade']):
        cta = """
## üõ°Ô∏è Sua Infraestrutura Est√° Preparada?

**Avalie sua postura de seguran√ßa:**
- Sua equipe conhece essas vulnerabilidades?
- Seus sistemas est√£o atualizados com as √∫ltimas pr√°ticas?
- Tem um plano de resposta a incidentes?

**üí° Precisa de uma segunda opini√£o?** 
Compartilhe este artigo com seu time de seguran√ßa e discutam as implica√ß√µes.

**üöÄ Pr√≥ximo passo:** Implemente pelo menos uma das recomenda√ß√µes desta semana.
"""
    else:
        cta = """
## üöÄ Pr√≥ximos Passos

**Para implementar essas ideias:**
1. Discuta com sua equipe os pontos mais relevantes
2. Identifique quick wins que podem ser implementados rapidamente  
3. Planeje um piloto para testar os conceitos

**üí≠ Sua opini√£o importa:** Que outros t√≥picos t√©cnicos gostaria de ver explorados?

**üîó Mantenha-se atualizado:** Siga para mais an√°lises t√©cnicas e insights do mercado.
"""
    
    content += cta
    return content


def add_seo_structure(content: str, keywords: List[str]) -> str:
    """Adiciona estrutura SEO ao conte√∫do do artigo."""
    
    # Adiciona √≠ndice se o artigo for longo
    lines = content.split('\n')
    headers = [line for line in lines if line.startswith('##')]
    
    if len(headers) >= 3:
        toc = "\n## √çndice\n\n"
        for header in headers:
            clean_header = header.replace('##', '').strip()
            anchor = clean_header.lower().replace(' ', '-').replace(',', '').replace(':', '')
            toc += f"- [{clean_header}](#{anchor})\n"
        
        # Insere √≠ndice ap√≥s a introdu√ß√£o
        intro_end = content.find('\n##')
        if intro_end > 0:
            content = content[:intro_end] + toc + content[intro_end:]
    
    # Adiciona FAQ section se houver palavras-chave
    if keywords:
        faq_section = f"\n\n## Perguntas Frequentes\n\n"
        
        for keyword in keywords[:3]:  # M√°ximo 3 FAQs
            faq_section += f"### O que √© {keyword}?\n\n"
            faq_section += f"{keyword.capitalize()} √© uma tecnologia/conceito importante que permite [explica√ß√£o breve baseada no contexto do artigo].\n\n"
        
        content += faq_section
    
    # CTA engajante j√° foi aplicado anteriormente
    
    return content

def commit_new_post(file_path: Path, title: str):
    """Adiciona, commita e faz push do novo post no Git."""
    print("üöÄ Fazendo commit do novo post...")
    try:
        # Adiciona o arquivo ao stage
        subprocess.run(["git", "add", str(file_path)], check=True)
        
        # Cria a mensagem de commit
        commit_message = f'feat: Add post "{title[:100]}"'
        
        # Faz o commit
        subprocess.run(["git", "commit", "-m", commit_message], check=True)
        print("‚úÖ Commit local realizado com sucesso!")

        # Faz o push para o reposit√≥rio remoto
        print("üì° Enviando para o reposit√≥rio remoto (git push)...")
        subprocess.run(["git", "push"], check=True)
        print("‚úÖ Push realizado com sucesso!")
        
        print(f"\nResumo:\n  {commit_message}")

    except subprocess.CalledProcessError as e:
        print(f"‚ùå ERRO ao executar comando git: {e}")
        print("Verifique se o git est√° instalado, configurado (user.name, user.email) e se suas credenciais para o GitHub est√£o corretas (ex: via Personal Access Token).")
    except FileNotFoundError:
        print("‚ùå ERRO: O comando 'git' n√£o foi encontrado. O arquivo foi criado mas n√£o commitado.")

def validate_journalistic_quality(title: str, content: str) -> bool:
    """Valida se o conte√∫do atende aos padr√µes de qualidade jornal√≠stica."""
    
    issues = []
    
    # Verifica se tem lead jornal√≠stico (primeiros 2 par√°grafos)
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip() and not p.startswith('#')]
    if len(paragraphs) >= 2:
        first_two = ' '.join(paragraphs[:2]).lower()
        # Verifica se responde aos 5 W's b√°sicos (mais flex√≠vel)
        has_what = any(word in first_two for word in ['anunciou', 'lan√ßou', 'revelou', 'apresentou', 'desenvolveu', 'criou', 'introduziu', 'implementou', 'oferece', 'disponibiliza'])
        has_who = any(word in first_two for word in ['empresa', 'companhia', 'organiza√ß√£o', 'equipe', 'google', 'microsoft', 'amazon', 'meta', 'nvidia', 'apple', 'tecnologia', 'plataforma'])
        
        # Relaxa crit√©rio - s√≥ precisa de O QUE e QUEM
        if not (has_what or has_who):
            issues.append("Lead precisa ser mais informativo sobre o que aconteceu e quem est√° envolvido")
    
    # Verifica densidade de dados espec√≠ficos
    data_indicators = len(re.findall(r'\d+[%\w]*', content))  # n√∫meros, percentuais
    word_count = len(content.split())
    data_density = data_indicators / word_count if word_count > 0 else 0
    
    if data_density < 0.01:  # Menos de 1% de dados espec√≠ficos
        issues.append("Baixa densidade de dados espec√≠ficos (n√∫meros, percentuais)")
    
    # Verifica se tem par√°grafos muito longos (mais flex√≠vel)
    long_paragraphs = [p for p in paragraphs if len(p.split()) > 150]
    if len(long_paragraphs) > 3:
        issues.append("Par√°grafos excessivamente longos (>150 palavras)")
    
    # Verifica redund√¢ncias comuns
    redundant_phrases = [
        '√© importante notar que', 'vale destacar que', 'cabe ressaltar que',
        'como mencionado anteriormente', 'conforme j√° dito'
    ]
    redundancy_count = sum(content.lower().count(phrase) for phrase in redundant_phrases)
    if redundancy_count > 3:
        issues.append("Muitas frases redundantes ou clich√™s")
    
    # Verifica se tem conectores l√≥gicos (mais abrangente)
    logical_connectors = ['portanto', 'consequentemente', 'assim', 'dessa forma', 'logo', 'al√©m disso', 'por outro lado', 'entretanto', 'contudo', 'no entanto', 'adicionalmente', 'por sua vez', 'desta forma']
    connector_count = sum(1 for connector in logical_connectors if connector in content.lower())
    if connector_count < 2:
        issues.append("Poucos conectores l√≥gicos para melhor fluxo textual")
    
    if issues:
        print(f"‚ùå Problemas de qualidade jornal√≠stica encontrados:")
        for issue in issues:
            print(f"   ‚Ä¢ {issue}")
        return False
    
    print("‚úÖ Conte√∫do aprovado na valida√ß√£o de qualidade jornal√≠stica")
    return True


def validate_ethical_guidelines(title: str, content: str) -> bool:
    """Valida se o conte√∫do segue as diretrizes √©ticas."""
    
    # Palavras proibidas (sensacionalistas)
    forbidden_words = [
        "breaking", "exclusivo", "confirmado", "vazou", "oficial",
        "acabou de", "nesta manh√£", "hoje cedo", "h√° poucas horas"
    ]
    
    title_lower = title.lower()
    content_lower = content.lower()
    
    # Verifica palavras proibidas no t√≠tulo
    for word in forbidden_words:
        if word in title_lower:
            print(f"‚ùå T√≠tulo cont√©m palavra sensacionalista: '{word}'")
            return False
    
    # Verifica se √© educativo ou h√≠brido v√°lido
    educational_indicators = [
        "como", "guia", "an√°lise", "comparativo", "entendendo",
        "explicado", "fundamentos", "conceitos", "pr√°ticas"
    ]
    
    hybrid_indicators = [
        "an√°lise:", "contexto:", "o que", "li√ß√µes", "por tr√°s",
        "significam", "impacto de", "implica√ß√µes"
    ]
    
    has_educational_indicator = any(word in title_lower for word in educational_indicators)
    has_hybrid_indicator = any(word in title_lower for word in hybrid_indicators)
    
    if not (has_educational_indicator or has_hybrid_indicator):
        print("‚ùå T√≠tulo n√£o parece educativo nem h√≠brido v√°lido")
        return False
    
    # Verifica timestamps espec√≠ficos no conte√∫do
    temporal_flags = [
        "hoje", "ontem", "esta manh√£", "nesta tarde", "h√° poucas horas",
        "acabou de ser anunciado", "confirmou hoje", "nesta semana"
    ]
    
    for flag in temporal_flags:
        if flag in content_lower:
            print(f"‚ùå Conte√∫do cont√©m timestamp espec√≠fico: '{flag}'")
            return False
    
    return True

def validate_seo_quality(title: str, content: str) -> bool:
    """Valida qualidade SEO do post gerado."""
    
    # Valida√ß√£o de t√≠tulo SEO
    if len(title) < SEO_TITLE_MIN_LENGTH:
        print(f"‚ùå T√≠tulo muito curto para SEO ({len(title)} < {SEO_TITLE_MIN_LENGTH})")
        return False
    
    if len(title) > SEO_TITLE_MAX_LENGTH:
        print(f"‚ùå T√≠tulo muito longo para SEO ({len(title)} > {SEO_TITLE_MAX_LENGTH})")
        return False
    
    # Valida√ß√£o de conte√∫do SEO
    word_count = len(content.split())
    if word_count < SEO_ARTICLE_MIN_WORDS:
        print(f"‚ùå Artigo muito curto para SEO ({word_count} < {SEO_ARTICLE_MIN_WORDS} palavras)")
        return False
    
    if word_count > SEO_ARTICLE_MAX_WORDS:
        print(f"‚ö†Ô∏è Artigo muito longo ({word_count} > {SEO_ARTICLE_MAX_WORDS} palavras), mas continuando...")
    
    # Valida√ß√£o de estrutura SEO
    headers = content.count('##')
    if headers < 3:
        print(f"‚ö†Ô∏è Poucos subt√≠tulos para SEO ({headers} < 3), mas continuando...")
    
    # Verifica presen√ßa de palavras-chave SEO
    has_seo_keywords = False
    title_lower = title.lower()
    content_lower = content.lower()
    
    for keywords in SEO_KEYWORDS.values():
        for keyword in keywords:
            if keyword in title_lower or keyword in content_lower:
                has_seo_keywords = True
                break
        if has_seo_keywords:
            break
    
    if not has_seo_keywords:
        print("‚ö†Ô∏è Nenhuma palavra-chave SEO identificada, mas continuando...")
    
    print(f"‚úÖ Post aprovado na valida√ß√£o SEO ({word_count} palavras, {headers} subt√≠tulos)")
    return True

def validate_post_quality(title: str, content: str) -> bool:
    """Valida a qualidade b√°sica, √©tica e SEO do post gerado."""
    
    # Valida√ß√£o de qualidade jornal√≠stica
    if not validate_journalistic_quality(title, content):
        print("‚ùå Post n√£o atende aos padr√µes de qualidade jornal√≠stica, regenerando...")
        return False
    
    # Valida√ß√£o √©tica
    if not validate_ethical_guidelines(title, content):
        print("‚ùå Post n√£o atende √†s diretrizes √©ticas, regenerando...")
        return False
    
    # Valida√ß√£o SEO
    if not validate_seo_quality(title, content):
        print("‚ùå Post n√£o atende aos crit√©rios SEO, regenerando...")
        return False
    
    print("‚úÖ Post aprovado em todas as valida√ß√µes (√©tica + SEO)")
    return True

def load_ethical_guidelines() -> bool:
    """Carrega e valida se as diretrizes √©ticas est√£o dispon√≠veis."""
    guidelines_file = Path("ethical_guidelines.md")
    if guidelines_file.exists():
        print("‚úÖ Diretrizes √©ticas carregadas")
        return True
    else:
        print("‚ö†Ô∏è Arquivo de diretrizes √©ticas n√£o encontrado")
        return False

def show_progress(step: int, total: int, description: str):
    """Mostra indicador de progresso."""
    if PROGRESS_INDICATORS:
        percentage = (step / total) * 100
        bar_length = 20
        filled_length = int(bar_length * step // total)
        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
        print(f"üìä [{bar}] {percentage:.0f}% - {description}")

def main():
    """Fun√ß√£o principal que orquestra todo o processo de an√°lise t√©cnica."""
    total_steps = 6
    current_step = 0
    
    print("üì∞ Iniciando gera√ß√£o de an√°lise t√©cnica de not√≠cias...")
    print(f"üìÖ Data/hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print("üéØ Foco: 80% an√°lise de not√≠cias, 15% t√©cnico SEO, 5% t√©cnico geral")
    print("‚ö° Otimizado para evitar timeouts")
    print()
    
    current_step += 1
    show_progress(current_step, total_steps, "Configurando API...")
    
    if not setup_api():
        sys.exit(1)

    current_step += 1
    show_progress(current_step, total_steps, "Gerando t√≥pico...")
    
    # Decide o tipo de gera√ß√£o focado em an√°lise t√©cnica de not√≠cias
    rand = random.random()
    
    print(f"üé≤ Sorteio: {rand:.2f}")
    
    if rand < 0.8:
        print("üì∞ Selecionado: An√°lise t√©cnica de not√≠cia")
        topic = generate_news_technical_analysis()
    elif rand < 0.95:
        print("üîß Selecionado: Conte√∫do t√©cnico SEO")
        topic = generate_technical_seo_topic()
    else:
        print("üíª Selecionado: Conte√∫do t√©cnico geral")
        topic = generate_it_professional_topic()
    
    if not topic:
        print("‚ùå Falha ao gerar t√≥pico √∫nico.")
        sys.exit(1)
    
    current_step += 1
    show_progress(current_step, total_steps, f"T√≥pico: {topic}")

    current_step += 1
    show_progress(current_step, total_steps, "Gerando artigo...")
    
    # Gera artigo com timeout otimizado
    max_article_attempts = MAX_ARTICLE_ATTEMPTS
    article = ""
    
    for attempt in range(max_article_attempts):
        print(f"üìù Tentativa {attempt + 1}/{max_article_attempts} - Gerando artigo...")
        try:
            article = write_article(topic)
            
            if article and validate_post_quality(topic, article):
                print(f"‚úÖ Artigo gerado com sucesso ({len(article)} chars)")
                break
            elif attempt < max_article_attempts - 1:
                print("üîÑ Regenerando artigo...")
        except Exception as e:
            if "timeout" in str(e).lower() or "504" in str(e):
                print(f"‚è∞ Timeout na gera√ß√£o do artigo (tentativa {attempt + 1})")
                if attempt < max_article_attempts - 1:
                    print("üîÑ Tentando com prompt mais simples...")
            else:
                print(f"‚ùå Erro na gera√ß√£o: {str(e)[:100]}...")
    
    if not article:
        print("‚ùå Falha ao gerar artigo de qualidade.")
        sys.exit(1)
    
    current_step += 1
    show_progress(current_step, total_steps, f"Artigo: {len(article)} caracteres")

    current_step += 1
    show_progress(current_step, total_steps, "Criando post Hugo...")
    
    # Cria o post com metadados aprimorados
    post_path = create_hugo_post(topic, article)
    if not post_path:
        sys.exit(1)

    current_step += 1
    show_progress(current_step, total_steps, "Fazendo commit...")
    
    # Commit e push
    commit_new_post(post_path, topic)

    show_progress(total_steps, total_steps, "Processo conclu√≠do!")
    
    print(f"\n‚ú® An√°lise t√©cnica '{topic}' publicada com sucesso! ‚ú®")
    print(f"ÔøΩ TArquivo: {post_path.name}")
    print(f"ÔøΩ  Tamanho: {len(article)} caracteres")
    print(f"üì∞ Tipo: An√°lise t√©cnica de not√≠cia")
    print(f"üïí Processo conclu√≠do em: {datetime.now().strftime('%H:%M:%S')}")
    print(f"‚ö° Sem timeouts detectados!")

if __name__ == "__main__":
    # Verifica diretrizes √©ticas antes de executar
    guidelines_file = Path("ethical_guidelines.md")
    if guidelines_file.exists():
        print("‚úÖ Diretrizes √©ticas carregadas")
    else:
        print("‚ö†Ô∏è Arquivo de diretrizes √©ticas n√£o encontrado")
    
    main()